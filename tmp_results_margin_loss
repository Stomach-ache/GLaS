using gpu
Num of threads :  20
train_GlasXC.py:138: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  input_enc_cfg = yaml.load(open(args.input_encoder_cfg))
train_GlasXC.py:139: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  input_dec_cfg = yaml.load(open(args.input_decoder_cfg))
train_GlasXC.py:140: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  output_enc_cfg = yaml.load(open(args.output_encoder_cfg))
train_GlasXC.py:141: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  output_dec_cfg = yaml.load(open(args.output_decoder_cfg))
train_GlasXC.py:142: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  regress_cfg = yaml.load(open(args.regressor_cfg))
train_GlasXC.py:151: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  opt_options = yaml.load(open(args.optimizer_cfg))
train_GlasXC.py:161: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.
  dset_opts = yaml.load(open(args.dataset_info))
0 / 500 :: 640 / 15539 - CLASS_LOSS : 0.46844
0 / 500 :: 1280 / 15539 - CLASS_LOSS : 0.49336
0 / 500 :: 1920 / 15539 - CLASS_LOSS : 0.47675
0 / 500 :: 2560 / 15539 - CLASS_LOSS : 0.51494
0 / 500 :: 3200 / 15539 - CLASS_LOSS : 0.572
0 / 500 :: 3840 / 15539 - CLASS_LOSS : 0.41741
0 / 500 :: 4480 / 15539 - CLASS_LOSS : 0.43027
0 / 500 :: 5120 / 15539 - CLASS_LOSS : 0.57816
0 / 500 :: 5760 / 15539 - CLASS_LOSS : 0.38261
0 / 500 :: 6400 / 15539 - CLASS_LOSS : 0.36835
0 / 500 :: 7040 / 15539 - CLASS_LOSS : 0.36603
0 / 500 :: 7680 / 15539 - CLASS_LOSS : 0.54287
0 / 500 :: 8320 / 15539 - CLASS_LOSS : 0.4392
0 / 500 :: 8960 / 15539 - CLASS_LOSS : 0.49088
0 / 500 :: 9600 / 15539 - CLASS_LOSS : 0.29407
0 / 500 :: 10240 / 15539 - CLASS_LOSS : 0.53529
0 / 500 :: 10880 / 15539 - CLASS_LOSS : 0.29483
0 / 500 :: 11520 / 15539 - CLASS_LOSS : 0.53975
0 / 500 :: 12160 / 15539 - CLASS_LOSS : 0.30646
0 / 500 :: 12800 / 15539 - CLASS_LOSS : 0.36052
0 / 500 :: 13440 / 15539 - CLASS_LOSS : 0.46895
0 / 500 :: 14080 / 15539 - CLASS_LOSS : 0.3562
0 / 500 :: 14720 / 15539 - CLASS_LOSS : 0.43066
0 / 500 :: 15360 / 15539 - CLASS_LOSS : 0.34099
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.2030375185018341 0.1691872063839372 0.14110303108308128
PSPrecision@1,3,5: 0.09079779128585794 0.10395313966514695 0.10929699907899226
testing....
Precision@1,3,5: 0.1853504856917826 0.13958169248271637 0.11399317406143344
PSPrecision@1,3,5: 0.08319984714893489 0.085985160681408 0.08970295781885053
1 / 500 :: 448 / 15539 - CLASS_LOSS : 0.36886
1 / 500 :: 1088 / 15539 - CLASS_LOSS : 0.43266
1 / 500 :: 1728 / 15539 - CLASS_LOSS : 0.43871
1 / 500 :: 2368 / 15539 - CLASS_LOSS : 0.4017
1 / 500 :: 3008 / 15539 - CLASS_LOSS : 0.37364
1 / 500 :: 3648 / 15539 - CLASS_LOSS : 0.25846
1 / 500 :: 4288 / 15539 - CLASS_LOSS : 0.38894
1 / 500 :: 4928 / 15539 - CLASS_LOSS : 0.33827
1 / 500 :: 5568 / 15539 - CLASS_LOSS : 0.44004
1 / 500 :: 6208 / 15539 - CLASS_LOSS : 0.36219
1 / 500 :: 6848 / 15539 - CLASS_LOSS : 0.39885
1 / 500 :: 7488 / 15539 - CLASS_LOSS : 0.33191
1 / 500 :: 8128 / 15539 - CLASS_LOSS : 0.38826
1 / 500 :: 8768 / 15539 - CLASS_LOSS : 0.3355
1 / 500 :: 9408 / 15539 - CLASS_LOSS : 0.40957
1 / 500 :: 10048 / 15539 - CLASS_LOSS : 0.4256
1 / 500 :: 10688 / 15539 - CLASS_LOSS : 0.31453
1 / 500 :: 11328 / 15539 - CLASS_LOSS : 0.32201
1 / 500 :: 11968 / 15539 - CLASS_LOSS : 0.37599
1 / 500 :: 12608 / 15539 - CLASS_LOSS : 0.43937
1 / 500 :: 13248 / 15539 - CLASS_LOSS : 0.30049
1 / 500 :: 13888 / 15539 - CLASS_LOSS : 0.36378
1 / 500 :: 14528 / 15539 - CLASS_LOSS : 0.34203
1 / 500 :: 15168 / 15539 - CLASS_LOSS : 0.32928
2 / 500 :: 256 / 15539 - CLASS_LOSS : 0.5599
2 / 500 :: 896 / 15539 - CLASS_LOSS : 0.28382
2 / 500 :: 1536 / 15539 - CLASS_LOSS : 0.50742
2 / 500 :: 2176 / 15539 - CLASS_LOSS : 0.4064
2 / 500 :: 2816 / 15539 - CLASS_LOSS : 0.23326
2 / 500 :: 3456 / 15539 - CLASS_LOSS : 0.365
2 / 500 :: 4096 / 15539 - CLASS_LOSS : 0.50284
2 / 500 :: 4736 / 15539 - CLASS_LOSS : 0.4373
2 / 500 :: 5376 / 15539 - CLASS_LOSS : 0.46505
2 / 500 :: 6016 / 15539 - CLASS_LOSS : 0.53385
2 / 500 :: 6656 / 15539 - CLASS_LOSS : 0.29542
2 / 500 :: 7296 / 15539 - CLASS_LOSS : 0.44069
2 / 500 :: 7936 / 15539 - CLASS_LOSS : 0.27595
2 / 500 :: 8576 / 15539 - CLASS_LOSS : 0.32974
2 / 500 :: 9216 / 15539 - CLASS_LOSS : 0.30373
2 / 500 :: 9856 / 15539 - CLASS_LOSS : 0.37657
2 / 500 :: 10496 / 15539 - CLASS_LOSS : 0.46043
2 / 500 :: 11136 / 15539 - CLASS_LOSS : 0.33181
2 / 500 :: 11776 / 15539 - CLASS_LOSS : 0.32421
2 / 500 :: 12416 / 15539 - CLASS_LOSS : 0.37182
2 / 500 :: 13056 / 15539 - CLASS_LOSS : 0.25315
2 / 500 :: 13696 / 15539 - CLASS_LOSS : 0.26833
2 / 500 :: 14336 / 15539 - CLASS_LOSS : 0.37871
2 / 500 :: 14976 / 15539 - CLASS_LOSS : 0.39553
3 / 500 :: 64 / 15539 - CLASS_LOSS : 0.26152
3 / 500 :: 704 / 15539 - CLASS_LOSS : 0.2517
3 / 500 :: 1344 / 15539 - CLASS_LOSS : 0.34728
3 / 500 :: 1984 / 15539 - CLASS_LOSS : 0.37811
3 / 500 :: 2624 / 15539 - CLASS_LOSS : 0.30908
3 / 500 :: 3264 / 15539 - CLASS_LOSS : 0.34146
3 / 500 :: 3904 / 15539 - CLASS_LOSS : 0.46411
3 / 500 :: 4544 / 15539 - CLASS_LOSS : 0.35615
3 / 500 :: 5184 / 15539 - CLASS_LOSS : 0.44305
3 / 500 :: 5824 / 15539 - CLASS_LOSS : 0.29389
3 / 500 :: 6464 / 15539 - CLASS_LOSS : 0.34893
3 / 500 :: 7104 / 15539 - CLASS_LOSS : 0.26587
3 / 500 :: 7744 / 15539 - CLASS_LOSS : 0.22802
3 / 500 :: 8384 / 15539 - CLASS_LOSS : 0.32601
3 / 500 :: 9024 / 15539 - CLASS_LOSS : 0.23362
3 / 500 :: 9664 / 15539 - CLASS_LOSS : 0.35559
3 / 500 :: 10304 / 15539 - CLASS_LOSS : 0.17858
3 / 500 :: 10944 / 15539 - CLASS_LOSS : 0.32754
3 / 500 :: 11584 / 15539 - CLASS_LOSS : 0.25838
3 / 500 :: 12224 / 15539 - CLASS_LOSS : 0.32252
3 / 500 :: 12864 / 15539 - CLASS_LOSS : 0.22197
3 / 500 :: 13504 / 15539 - CLASS_LOSS : 0.32959
3 / 500 :: 14144 / 15539 - CLASS_LOSS : 0.38223
3 / 500 :: 14784 / 15539 - CLASS_LOSS : 0.43415
3 / 500 :: 15424 / 15539 - CLASS_LOSS : 0.23339
4 / 500 :: 512 / 15539 - CLASS_LOSS : 0.36209
4 / 500 :: 1152 / 15539 - CLASS_LOSS : 0.27884
4 / 500 :: 1792 / 15539 - CLASS_LOSS : 0.23832
4 / 500 :: 2432 / 15539 - CLASS_LOSS : 0.23485
4 / 500 :: 3072 / 15539 - CLASS_LOSS : 0.29583
4 / 500 :: 3712 / 15539 - CLASS_LOSS : 0.49677
4 / 500 :: 4352 / 15539 - CLASS_LOSS : 0.19297
4 / 500 :: 4992 / 15539 - CLASS_LOSS : 0.33263
4 / 500 :: 5632 / 15539 - CLASS_LOSS : 0.30073
4 / 500 :: 6272 / 15539 - CLASS_LOSS : 0.28547
4 / 500 :: 6912 / 15539 - CLASS_LOSS : 0.35901
4 / 500 :: 7552 / 15539 - CLASS_LOSS : 0.28299
4 / 500 :: 8192 / 15539 - CLASS_LOSS : 0.52287
4 / 500 :: 8832 / 15539 - CLASS_LOSS : 0.30914
4 / 500 :: 9472 / 15539 - CLASS_LOSS : 0.31816
4 / 500 :: 10112 / 15539 - CLASS_LOSS : 0.54884
4 / 500 :: 10752 / 15539 - CLASS_LOSS : 0.32883
4 / 500 :: 11392 / 15539 - CLASS_LOSS : 0.24985
4 / 500 :: 12032 / 15539 - CLASS_LOSS : 0.40132
4 / 500 :: 12672 / 15539 - CLASS_LOSS : 0.25365
4 / 500 :: 13312 / 15539 - CLASS_LOSS : 0.35936
4 / 500 :: 13952 / 15539 - CLASS_LOSS : 0.30936
4 / 500 :: 14592 / 15539 - CLASS_LOSS : 0.34921
4 / 500 :: 15232 / 15539 - CLASS_LOSS : 0.31688
5 / 500 :: 320 / 15539 - CLASS_LOSS : 0.51651
5 / 500 :: 960 / 15539 - CLASS_LOSS : 0.53184
5 / 500 :: 1600 / 15539 - CLASS_LOSS : 0.1952
5 / 500 :: 2240 / 15539 - CLASS_LOSS : 0.34121
5 / 500 :: 2880 / 15539 - CLASS_LOSS : 0.26836
5 / 500 :: 3520 / 15539 - CLASS_LOSS : 0.38595
5 / 500 :: 4160 / 15539 - CLASS_LOSS : 0.27187
5 / 500 :: 4800 / 15539 - CLASS_LOSS : 0.40342
5 / 500 :: 5440 / 15539 - CLASS_LOSS : 0.22867
5 / 500 :: 6080 / 15539 - CLASS_LOSS : 0.21992
5 / 500 :: 6720 / 15539 - CLASS_LOSS : 0.28878
5 / 500 :: 7360 / 15539 - CLASS_LOSS : 0.40826
5 / 500 :: 8000 / 15539 - CLASS_LOSS : 0.253
5 / 500 :: 8640 / 15539 - CLASS_LOSS : 0.31312
5 / 500 :: 9280 / 15539 - CLASS_LOSS : 0.28079
5 / 500 :: 9920 / 15539 - CLASS_LOSS : 0.25687
5 / 500 :: 10560 / 15539 - CLASS_LOSS : 0.30476
5 / 500 :: 11200 / 15539 - CLASS_LOSS : 0.29269
5 / 500 :: 11840 / 15539 - CLASS_LOSS : 0.29756
5 / 500 :: 12480 / 15539 - CLASS_LOSS : 0.22209
5 / 500 :: 13120 / 15539 - CLASS_LOSS : 0.17786
5 / 500 :: 13760 / 15539 - CLASS_LOSS : 0.251
5 / 500 :: 14400 / 15539 - CLASS_LOSS : 0.32926
5 / 500 :: 15040 / 15539 - CLASS_LOSS : 0.28273
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.25561490443400475 0.2070274792457687 0.17662655254520884
PSPrecision@1,3,5: 0.1347272106674327 0.14785098984086484 0.15811743801645758
testing....
Precision@1,3,5: 0.21711735363612497 0.17292377701934017 0.14344972433709635
PSPrecision@1,3,5: 0.11362107038345289 0.12471907720808377 0.13078605321736506
6 / 500 :: 128 / 15539 - CLASS_LOSS : 0.50174
6 / 500 :: 768 / 15539 - CLASS_LOSS : 0.30998
6 / 500 :: 1408 / 15539 - CLASS_LOSS : 0.38016
6 / 500 :: 2048 / 15539 - CLASS_LOSS : 0.2676
6 / 500 :: 2688 / 15539 - CLASS_LOSS : 0.24974
6 / 500 :: 3328 / 15539 - CLASS_LOSS : 0.37418
6 / 500 :: 3968 / 15539 - CLASS_LOSS : 0.3582
6 / 500 :: 4608 / 15539 - CLASS_LOSS : 0.35946
6 / 500 :: 5248 / 15539 - CLASS_LOSS : 0.29639
6 / 500 :: 5888 / 15539 - CLASS_LOSS : 0.28539
6 / 500 :: 6528 / 15539 - CLASS_LOSS : 0.42624
6 / 500 :: 7168 / 15539 - CLASS_LOSS : 0.33273
6 / 500 :: 7808 / 15539 - CLASS_LOSS : 0.35741
6 / 500 :: 8448 / 15539 - CLASS_LOSS : 0.32118
6 / 500 :: 9088 / 15539 - CLASS_LOSS : 0.49726
6 / 500 :: 9728 / 15539 - CLASS_LOSS : 0.38985
6 / 500 :: 10368 / 15539 - CLASS_LOSS : 0.23099
6 / 500 :: 11008 / 15539 - CLASS_LOSS : 0.18395
6 / 500 :: 11648 / 15539 - CLASS_LOSS : 0.43179
6 / 500 :: 12288 / 15539 - CLASS_LOSS : 0.324
6 / 500 :: 12928 / 15539 - CLASS_LOSS : 0.27009
6 / 500 :: 13568 / 15539 - CLASS_LOSS : 0.28495
6 / 500 :: 14208 / 15539 - CLASS_LOSS : 0.33488
6 / 500 :: 14848 / 15539 - CLASS_LOSS : 0.34705
6 / 500 :: 15488 / 15539 - CLASS_LOSS : 0.22119
7 / 500 :: 576 / 15539 - CLASS_LOSS : 0.36769
7 / 500 :: 1216 / 15539 - CLASS_LOSS : 0.41732
7 / 500 :: 1856 / 15539 - CLASS_LOSS : 0.16771
7 / 500 :: 2496 / 15539 - CLASS_LOSS : 0.2377
7 / 500 :: 3136 / 15539 - CLASS_LOSS : 0.26867
7 / 500 :: 3776 / 15539 - CLASS_LOSS : 0.18829
7 / 500 :: 4416 / 15539 - CLASS_LOSS : 0.26671
7 / 500 :: 5056 / 15539 - CLASS_LOSS : 0.28662
7 / 500 :: 5696 / 15539 - CLASS_LOSS : 0.33449
7 / 500 :: 6336 / 15539 - CLASS_LOSS : 0.18856
7 / 500 :: 6976 / 15539 - CLASS_LOSS : 0.16738
7 / 500 :: 7616 / 15539 - CLASS_LOSS : 0.21524
7 / 500 :: 8256 / 15539 - CLASS_LOSS : 0.19839
7 / 500 :: 8896 / 15539 - CLASS_LOSS : 0.25091
7 / 500 :: 9536 / 15539 - CLASS_LOSS : 0.32816
7 / 500 :: 10176 / 15539 - CLASS_LOSS : 0.50588
7 / 500 :: 10816 / 15539 - CLASS_LOSS : 0.30082
7 / 500 :: 11456 / 15539 - CLASS_LOSS : 0.23002
7 / 500 :: 12096 / 15539 - CLASS_LOSS : 0.39164
7 / 500 :: 12736 / 15539 - CLASS_LOSS : 0.26786
7 / 500 :: 13376 / 15539 - CLASS_LOSS : 0.24116
7 / 500 :: 14016 / 15539 - CLASS_LOSS : 0.26922
7 / 500 :: 14656 / 15539 - CLASS_LOSS : 0.30936
7 / 500 :: 15296 / 15539 - CLASS_LOSS : 0.3757
8 / 500 :: 384 / 15539 - CLASS_LOSS : 0.34955
8 / 500 :: 1024 / 15539 - CLASS_LOSS : 0.42744
8 / 500 :: 1664 / 15539 - CLASS_LOSS : 0.23769
8 / 500 :: 2304 / 15539 - CLASS_LOSS : 0.29993
8 / 500 :: 2944 / 15539 - CLASS_LOSS : 0.29214
8 / 500 :: 3584 / 15539 - CLASS_LOSS : 0.37615
8 / 500 :: 4224 / 15539 - CLASS_LOSS : 0.23984
8 / 500 :: 4864 / 15539 - CLASS_LOSS : 0.41786
8 / 500 :: 5504 / 15539 - CLASS_LOSS : 0.31617
8 / 500 :: 6144 / 15539 - CLASS_LOSS : 0.2458
8 / 500 :: 6784 / 15539 - CLASS_LOSS : 0.23609
8 / 500 :: 7424 / 15539 - CLASS_LOSS : 0.24886
8 / 500 :: 8064 / 15539 - CLASS_LOSS : 0.35498
8 / 500 :: 8704 / 15539 - CLASS_LOSS : 0.34226
8 / 500 :: 9344 / 15539 - CLASS_LOSS : 0.24395
8 / 500 :: 9984 / 15539 - CLASS_LOSS : 0.24241
8 / 500 :: 10624 / 15539 - CLASS_LOSS : 0.14047
8 / 500 :: 11264 / 15539 - CLASS_LOSS : 0.33312
8 / 500 :: 11904 / 15539 - CLASS_LOSS : 0.28153
8 / 500 :: 12544 / 15539 - CLASS_LOSS : 0.23697
8 / 500 :: 13184 / 15539 - CLASS_LOSS : 0.27165
8 / 500 :: 13824 / 15539 - CLASS_LOSS : 0.30263
8 / 500 :: 14464 / 15539 - CLASS_LOSS : 0.2903
8 / 500 :: 15104 / 15539 - CLASS_LOSS : 0.2576
9 / 500 :: 192 / 15539 - CLASS_LOSS : 0.17354
9 / 500 :: 832 / 15539 - CLASS_LOSS : 0.41694
9 / 500 :: 1472 / 15539 - CLASS_LOSS : 0.33248
9 / 500 :: 2112 / 15539 - CLASS_LOSS : 0.30266
9 / 500 :: 2752 / 15539 - CLASS_LOSS : 0.23789
9 / 500 :: 3392 / 15539 - CLASS_LOSS : 0.232
9 / 500 :: 4032 / 15539 - CLASS_LOSS : 0.24891
9 / 500 :: 4672 / 15539 - CLASS_LOSS : 0.17605
9 / 500 :: 5312 / 15539 - CLASS_LOSS : 0.34224
9 / 500 :: 5952 / 15539 - CLASS_LOSS : 0.22018
9 / 500 :: 6592 / 15539 - CLASS_LOSS : 0.33523
9 / 500 :: 7232 / 15539 - CLASS_LOSS : 0.27008
9 / 500 :: 7872 / 15539 - CLASS_LOSS : 0.23908
9 / 500 :: 8512 / 15539 - CLASS_LOSS : 0.41077
9 / 500 :: 9152 / 15539 - CLASS_LOSS : 0.26364
9 / 500 :: 9792 / 15539 - CLASS_LOSS : 0.30162
9 / 500 :: 10432 / 15539 - CLASS_LOSS : 0.2806
9 / 500 :: 11072 / 15539 - CLASS_LOSS : 0.19408
9 / 500 :: 11712 / 15539 - CLASS_LOSS : 0.26255
9 / 500 :: 12352 / 15539 - CLASS_LOSS : 0.30692
9 / 500 :: 12992 / 15539 - CLASS_LOSS : 0.19372
9 / 500 :: 13632 / 15539 - CLASS_LOSS : 0.228
9 / 500 :: 14272 / 15539 - CLASS_LOSS : 0.16773
9 / 500 :: 14912 / 15539 - CLASS_LOSS : 0.24251
9 / 500 :: 15539 / 15539 - CLASS_LOSS : 0.40376
10 / 500 :: 640 / 15539 - CLASS_LOSS : 0.27908
10 / 500 :: 1280 / 15539 - CLASS_LOSS : 0.25031
10 / 500 :: 1920 / 15539 - CLASS_LOSS : 0.21462
10 / 500 :: 2560 / 15539 - CLASS_LOSS : 0.19281
10 / 500 :: 3200 / 15539 - CLASS_LOSS : 0.37856
10 / 500 :: 3840 / 15539 - CLASS_LOSS : 0.37381
10 / 500 :: 4480 / 15539 - CLASS_LOSS : 0.29059
10 / 500 :: 5120 / 15539 - CLASS_LOSS : 0.26186
10 / 500 :: 5760 / 15539 - CLASS_LOSS : 0.23684
10 / 500 :: 6400 / 15539 - CLASS_LOSS : 0.24395
10 / 500 :: 7040 / 15539 - CLASS_LOSS : 0.23866
10 / 500 :: 7680 / 15539 - CLASS_LOSS : 0.26599
10 / 500 :: 8320 / 15539 - CLASS_LOSS : 0.35267
10 / 500 :: 8960 / 15539 - CLASS_LOSS : 0.18572
10 / 500 :: 9600 / 15539 - CLASS_LOSS : 0.25643
10 / 500 :: 10240 / 15539 - CLASS_LOSS : 0.27799
10 / 500 :: 10880 / 15539 - CLASS_LOSS : 0.17069
10 / 500 :: 11520 / 15539 - CLASS_LOSS : 0.26441
10 / 500 :: 12160 / 15539 - CLASS_LOSS : 0.24975
10 / 500 :: 12800 / 15539 - CLASS_LOSS : 0.20049
10 / 500 :: 13440 / 15539 - CLASS_LOSS : 0.28423
10 / 500 :: 14080 / 15539 - CLASS_LOSS : 0.3008
10 / 500 :: 14720 / 15539 - CLASS_LOSS : 0.2586
10 / 500 :: 15360 / 15539 - CLASS_LOSS : 0.14195
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.26861445395456596 0.2248321427805307 0.19141514897998585
PSPrecision@1,3,5: 0.15613435058696692 0.1709502480051035 0.18257685463029982
testing....
Precision@1,3,5: 0.2383827776319244 0.19287652052157173 0.1615647151483329
PSPrecision@1,3,5: 0.1327003214257399 0.1440252964190374 0.15259314008284053
11 / 500 :: 448 / 15539 - CLASS_LOSS : 0.24727
11 / 500 :: 1088 / 15539 - CLASS_LOSS : 0.22794
11 / 500 :: 1728 / 15539 - CLASS_LOSS : 0.2172
11 / 500 :: 2368 / 15539 - CLASS_LOSS : 0.21912
11 / 500 :: 3008 / 15539 - CLASS_LOSS : 0.228
11 / 500 :: 3648 / 15539 - CLASS_LOSS : 0.37064
11 / 500 :: 4288 / 15539 - CLASS_LOSS : 0.33232
11 / 500 :: 4928 / 15539 - CLASS_LOSS : 0.2997
11 / 500 :: 5568 / 15539 - CLASS_LOSS : 0.31386
11 / 500 :: 6208 / 15539 - CLASS_LOSS : 0.34076
11 / 500 :: 6848 / 15539 - CLASS_LOSS : 0.27409
11 / 500 :: 7488 / 15539 - CLASS_LOSS : 0.12946
11 / 500 :: 8128 / 15539 - CLASS_LOSS : 0.22555
11 / 500 :: 8768 / 15539 - CLASS_LOSS : 0.25286
11 / 500 :: 9408 / 15539 - CLASS_LOSS : 0.22592
11 / 500 :: 10048 / 15539 - CLASS_LOSS : 0.23338
11 / 500 :: 10688 / 15539 - CLASS_LOSS : 0.12976
11 / 500 :: 11328 / 15539 - CLASS_LOSS : 0.13357
11 / 500 :: 11968 / 15539 - CLASS_LOSS : 0.41937
11 / 500 :: 12608 / 15539 - CLASS_LOSS : 0.11634
11 / 500 :: 13248 / 15539 - CLASS_LOSS : 0.226
11 / 500 :: 13888 / 15539 - CLASS_LOSS : 0.2018
11 / 500 :: 14528 / 15539 - CLASS_LOSS : 0.26513
11 / 500 :: 15168 / 15539 - CLASS_LOSS : 0.1633
12 / 500 :: 256 / 15539 - CLASS_LOSS : 0.15471
12 / 500 :: 896 / 15539 - CLASS_LOSS : 0.24843
12 / 500 :: 1536 / 15539 - CLASS_LOSS : 0.18451
12 / 500 :: 2176 / 15539 - CLASS_LOSS : 0.2758
12 / 500 :: 2816 / 15539 - CLASS_LOSS : 0.23626
12 / 500 :: 3456 / 15539 - CLASS_LOSS : 0.31727
12 / 500 :: 4096 / 15539 - CLASS_LOSS : 0.24752
12 / 500 :: 4736 / 15539 - CLASS_LOSS : 0.2228
12 / 500 :: 5376 / 15539 - CLASS_LOSS : 0.24542
12 / 500 :: 6016 / 15539 - CLASS_LOSS : 0.17379
12 / 500 :: 6656 / 15539 - CLASS_LOSS : 0.24972
12 / 500 :: 7296 / 15539 - CLASS_LOSS : 0.26903
12 / 500 :: 7936 / 15539 - CLASS_LOSS : 0.25216
12 / 500 :: 8576 / 15539 - CLASS_LOSS : 0.24922
12 / 500 :: 9216 / 15539 - CLASS_LOSS : 0.22296
12 / 500 :: 9856 / 15539 - CLASS_LOSS : 0.22398
12 / 500 :: 10496 / 15539 - CLASS_LOSS : 0.32329
12 / 500 :: 11136 / 15539 - CLASS_LOSS : 0.29537
12 / 500 :: 11776 / 15539 - CLASS_LOSS : 0.40409
12 / 500 :: 12416 / 15539 - CLASS_LOSS : 0.23911
12 / 500 :: 13056 / 15539 - CLASS_LOSS : 0.25405
12 / 500 :: 13696 / 15539 - CLASS_LOSS : 0.11501
12 / 500 :: 14336 / 15539 - CLASS_LOSS : 0.17937
12 / 500 :: 14976 / 15539 - CLASS_LOSS : 0.23276
13 / 500 :: 64 / 15539 - CLASS_LOSS : 0.29416
13 / 500 :: 704 / 15539 - CLASS_LOSS : 0.23442
13 / 500 :: 1344 / 15539 - CLASS_LOSS : 0.29809
13 / 500 :: 1984 / 15539 - CLASS_LOSS : 0.31985
13 / 500 :: 2624 / 15539 - CLASS_LOSS : 0.33711
13 / 500 :: 3264 / 15539 - CLASS_LOSS : 0.15442
13 / 500 :: 3904 / 15539 - CLASS_LOSS : 0.17954
13 / 500 :: 4544 / 15539 - CLASS_LOSS : 0.19223
13 / 500 :: 5184 / 15539 - CLASS_LOSS : 0.37106
13 / 500 :: 5824 / 15539 - CLASS_LOSS : 0.18009
13 / 500 :: 6464 / 15539 - CLASS_LOSS : 0.13885
13 / 500 :: 7104 / 15539 - CLASS_LOSS : 0.37809
13 / 500 :: 7744 / 15539 - CLASS_LOSS : 0.1963
13 / 500 :: 8384 / 15539 - CLASS_LOSS : 0.15415
13 / 500 :: 9024 / 15539 - CLASS_LOSS : 0.10953
13 / 500 :: 9664 / 15539 - CLASS_LOSS : 0.17826
13 / 500 :: 10304 / 15539 - CLASS_LOSS : 0.21234
13 / 500 :: 10944 / 15539 - CLASS_LOSS : 0.26776
13 / 500 :: 11584 / 15539 - CLASS_LOSS : 0.19363
13 / 500 :: 12224 / 15539 - CLASS_LOSS : 0.2531
13 / 500 :: 12864 / 15539 - CLASS_LOSS : 0.25701
13 / 500 :: 13504 / 15539 - CLASS_LOSS : 0.27693
13 / 500 :: 14144 / 15539 - CLASS_LOSS : 0.24033
13 / 500 :: 14784 / 15539 - CLASS_LOSS : 0.23257
13 / 500 :: 15424 / 15539 - CLASS_LOSS : 0.26111
14 / 500 :: 512 / 15539 - CLASS_LOSS : 0.38281
14 / 500 :: 1152 / 15539 - CLASS_LOSS : 0.17796
14 / 500 :: 1792 / 15539 - CLASS_LOSS : 0.25634
14 / 500 :: 2432 / 15539 - CLASS_LOSS : 0.27787
14 / 500 :: 3072 / 15539 - CLASS_LOSS : 0.26323
14 / 500 :: 3712 / 15539 - CLASS_LOSS : 0.22455
14 / 500 :: 4352 / 15539 - CLASS_LOSS : 0.17262
14 / 500 :: 4992 / 15539 - CLASS_LOSS : 0.21171
14 / 500 :: 5632 / 15539 - CLASS_LOSS : 0.14895
14 / 500 :: 6272 / 15539 - CLASS_LOSS : 0.19886
14 / 500 :: 6912 / 15539 - CLASS_LOSS : 0.25233
14 / 500 :: 7552 / 15539 - CLASS_LOSS : 0.30437
14 / 500 :: 8192 / 15539 - CLASS_LOSS : 0.23369
14 / 500 :: 8832 / 15539 - CLASS_LOSS : 0.1805
14 / 500 :: 9472 / 15539 - CLASS_LOSS : 0.36866
14 / 500 :: 10112 / 15539 - CLASS_LOSS : 0.30324
14 / 500 :: 10752 / 15539 - CLASS_LOSS : 0.21881
14 / 500 :: 11392 / 15539 - CLASS_LOSS : 0.17456
14 / 500 :: 12032 / 15539 - CLASS_LOSS : 0.24469
14 / 500 :: 12672 / 15539 - CLASS_LOSS : 0.21517
14 / 500 :: 13312 / 15539 - CLASS_LOSS : 0.20565
14 / 500 :: 13952 / 15539 - CLASS_LOSS : 0.30932
14 / 500 :: 14592 / 15539 - CLASS_LOSS : 0.20645
14 / 500 :: 15232 / 15539 - CLASS_LOSS : 0.17163
15 / 500 :: 320 / 15539 - CLASS_LOSS : 0.19504
15 / 500 :: 960 / 15539 - CLASS_LOSS : 0.22035
15 / 500 :: 1600 / 15539 - CLASS_LOSS : 0.29923
15 / 500 :: 2240 / 15539 - CLASS_LOSS : 0.34847
15 / 500 :: 2880 / 15539 - CLASS_LOSS : 0.19295
15 / 500 :: 3520 / 15539 - CLASS_LOSS : 0.29461
15 / 500 :: 4160 / 15539 - CLASS_LOSS : 0.26523
15 / 500 :: 4800 / 15539 - CLASS_LOSS : 0.27791
15 / 500 :: 5440 / 15539 - CLASS_LOSS : 0.22121
15 / 500 :: 6080 / 15539 - CLASS_LOSS : 0.1384
15 / 500 :: 6720 / 15539 - CLASS_LOSS : 0.14022
15 / 500 :: 7360 / 15539 - CLASS_LOSS : 0.18808
15 / 500 :: 8000 / 15539 - CLASS_LOSS : 0.19164
15 / 500 :: 8640 / 15539 - CLASS_LOSS : 0.25074
15 / 500 :: 9280 / 15539 - CLASS_LOSS : 0.09939
15 / 500 :: 9920 / 15539 - CLASS_LOSS : 0.19831
15 / 500 :: 10560 / 15539 - CLASS_LOSS : 0.25275
15 / 500 :: 11200 / 15539 - CLASS_LOSS : 0.27127
15 / 500 :: 11840 / 15539 - CLASS_LOSS : 0.27043
15 / 500 :: 12480 / 15539 - CLASS_LOSS : 0.21702
15 / 500 :: 13120 / 15539 - CLASS_LOSS : 0.25097
15 / 500 :: 13760 / 15539 - CLASS_LOSS : 0.18527
15 / 500 :: 14400 / 15539 - CLASS_LOSS : 0.32188
15 / 500 :: 15040 / 15539 - CLASS_LOSS : 0.28685
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.28270802496943176 0.24448162687431624 0.20978183924319455
PSPrecision@1,3,5: 0.17192428158130052 0.19582941001274937 0.20973666169978356
testing....
Precision@1,3,5: 0.25413494355473876 0.21274175199089876 0.17684431609346285
PSPrecision@1,3,5: 0.145602261760711 0.16391951462803467 0.17159661358387704
16 / 500 :: 128 / 15539 - CLASS_LOSS : 0.23863
16 / 500 :: 768 / 15539 - CLASS_LOSS : 0.21449
16 / 500 :: 1408 / 15539 - CLASS_LOSS : 0.23431
16 / 500 :: 2048 / 15539 - CLASS_LOSS : 0.36546
16 / 500 :: 2688 / 15539 - CLASS_LOSS : 0.22608
16 / 500 :: 3328 / 15539 - CLASS_LOSS : 0.30456
16 / 500 :: 3968 / 15539 - CLASS_LOSS : 0.31538
16 / 500 :: 4608 / 15539 - CLASS_LOSS : 0.2287
16 / 500 :: 5248 / 15539 - CLASS_LOSS : 0.26506
16 / 500 :: 5888 / 15539 - CLASS_LOSS : 0.22539
16 / 500 :: 6528 / 15539 - CLASS_LOSS : 0.36402
16 / 500 :: 7168 / 15539 - CLASS_LOSS : 0.27136
16 / 500 :: 7808 / 15539 - CLASS_LOSS : 0.33367
16 / 500 :: 8448 / 15539 - CLASS_LOSS : 0.16281
16 / 500 :: 9088 / 15539 - CLASS_LOSS : 0.25547
16 / 500 :: 9728 / 15539 - CLASS_LOSS : 0.28901
16 / 500 :: 10368 / 15539 - CLASS_LOSS : 0.22813
16 / 500 :: 11008 / 15539 - CLASS_LOSS : 0.26194
16 / 500 :: 11648 / 15539 - CLASS_LOSS : 0.24533
16 / 500 :: 12288 / 15539 - CLASS_LOSS : 0.22573
16 / 500 :: 12928 / 15539 - CLASS_LOSS : 0.32373
16 / 500 :: 13568 / 15539 - CLASS_LOSS : 0.28414
16 / 500 :: 14208 / 15539 - CLASS_LOSS : 0.22237
16 / 500 :: 14848 / 15539 - CLASS_LOSS : 0.19255
16 / 500 :: 15488 / 15539 - CLASS_LOSS : 0.32016
17 / 500 :: 576 / 15539 - CLASS_LOSS : 0.22119
17 / 500 :: 1216 / 15539 - CLASS_LOSS : 0.22372
17 / 500 :: 1856 / 15539 - CLASS_LOSS : 0.20047
17 / 500 :: 2496 / 15539 - CLASS_LOSS : 0.2367
17 / 500 :: 3136 / 15539 - CLASS_LOSS : 0.24008
17 / 500 :: 3776 / 15539 - CLASS_LOSS : 0.24076
17 / 500 :: 4416 / 15539 - CLASS_LOSS : 0.22007
17 / 500 :: 5056 / 15539 - CLASS_LOSS : 0.18196
17 / 500 :: 5696 / 15539 - CLASS_LOSS : 0.24424
17 / 500 :: 6336 / 15539 - CLASS_LOSS : 0.24041
17 / 500 :: 6976 / 15539 - CLASS_LOSS : 0.20109
17 / 500 :: 7616 / 15539 - CLASS_LOSS : 0.31282
17 / 500 :: 8256 / 15539 - CLASS_LOSS : 0.22062
17 / 500 :: 8896 / 15539 - CLASS_LOSS : 0.23652
17 / 500 :: 9536 / 15539 - CLASS_LOSS : 0.20307
17 / 500 :: 10176 / 15539 - CLASS_LOSS : 0.36317
17 / 500 :: 10816 / 15539 - CLASS_LOSS : 0.17531
17 / 500 :: 11456 / 15539 - CLASS_LOSS : 0.24674
17 / 500 :: 12096 / 15539 - CLASS_LOSS : 0.1689
17 / 500 :: 12736 / 15539 - CLASS_LOSS : 0.33969
17 / 500 :: 13376 / 15539 - CLASS_LOSS : 0.22564
17 / 500 :: 14016 / 15539 - CLASS_LOSS : 0.21256
17 / 500 :: 14656 / 15539 - CLASS_LOSS : 0.21071
17 / 500 :: 15296 / 15539 - CLASS_LOSS : 0.24457
18 / 500 :: 384 / 15539 - CLASS_LOSS : 0.18631
18 / 500 :: 1024 / 15539 - CLASS_LOSS : 0.20172
18 / 500 :: 1664 / 15539 - CLASS_LOSS : 0.29029
18 / 500 :: 2304 / 15539 - CLASS_LOSS : 0.20818
18 / 500 :: 2944 / 15539 - CLASS_LOSS : 0.18758
18 / 500 :: 3584 / 15539 - CLASS_LOSS : 0.1566
18 / 500 :: 4224 / 15539 - CLASS_LOSS : 0.27668
18 / 500 :: 4864 / 15539 - CLASS_LOSS : 0.18808
18 / 500 :: 5504 / 15539 - CLASS_LOSS : 0.24217
18 / 500 :: 6144 / 15539 - CLASS_LOSS : 0.30768
18 / 500 :: 6784 / 15539 - CLASS_LOSS : 0.13027
18 / 500 :: 7424 / 15539 - CLASS_LOSS : 0.16898
18 / 500 :: 8064 / 15539 - CLASS_LOSS : 0.18875
18 / 500 :: 8704 / 15539 - CLASS_LOSS : 0.31283
18 / 500 :: 9344 / 15539 - CLASS_LOSS : 0.21059
18 / 500 :: 9984 / 15539 - CLASS_LOSS : 0.25209
18 / 500 :: 10624 / 15539 - CLASS_LOSS : 0.14958
18 / 500 :: 11264 / 15539 - CLASS_LOSS : 0.23446
18 / 500 :: 11904 / 15539 - CLASS_LOSS : 0.32173
18 / 500 :: 12544 / 15539 - CLASS_LOSS : 0.21923
18 / 500 :: 13184 / 15539 - CLASS_LOSS : 0.23353
18 / 500 :: 13824 / 15539 - CLASS_LOSS : 0.34171
18 / 500 :: 14464 / 15539 - CLASS_LOSS : 0.33543
18 / 500 :: 15104 / 15539 - CLASS_LOSS : 0.41303
19 / 500 :: 192 / 15539 - CLASS_LOSS : 0.24117
19 / 500 :: 832 / 15539 - CLASS_LOSS : 0.20054
19 / 500 :: 1472 / 15539 - CLASS_LOSS : 0.30604
19 / 500 :: 2112 / 15539 - CLASS_LOSS : 0.21075
19 / 500 :: 2752 / 15539 - CLASS_LOSS : 0.20228
19 / 500 :: 3392 / 15539 - CLASS_LOSS : 0.23362
19 / 500 :: 4032 / 15539 - CLASS_LOSS : 0.18158
19 / 500 :: 4672 / 15539 - CLASS_LOSS : 0.29235
19 / 500 :: 5312 / 15539 - CLASS_LOSS : 0.25403
19 / 500 :: 5952 / 15539 - CLASS_LOSS : 0.23032
19 / 500 :: 6592 / 15539 - CLASS_LOSS : 0.22282
19 / 500 :: 7232 / 15539 - CLASS_LOSS : 0.17122
19 / 500 :: 7872 / 15539 - CLASS_LOSS : 0.26996
19 / 500 :: 8512 / 15539 - CLASS_LOSS : 0.15435
19 / 500 :: 9152 / 15539 - CLASS_LOSS : 0.23217
19 / 500 :: 9792 / 15539 - CLASS_LOSS : 0.17442
19 / 500 :: 10432 / 15539 - CLASS_LOSS : 0.19506
19 / 500 :: 11072 / 15539 - CLASS_LOSS : 0.23691
19 / 500 :: 11712 / 15539 - CLASS_LOSS : 0.25922
19 / 500 :: 12352 / 15539 - CLASS_LOSS : 0.20183
19 / 500 :: 12992 / 15539 - CLASS_LOSS : 0.3311
19 / 500 :: 13632 / 15539 - CLASS_LOSS : 0.26353
19 / 500 :: 14272 / 15539 - CLASS_LOSS : 0.22081
19 / 500 :: 14912 / 15539 - CLASS_LOSS : 0.1964
19 / 500 :: 15539 / 15539 - CLASS_LOSS : 0.36167
20 / 500 :: 640 / 15539 - CLASS_LOSS : 0.18453
20 / 500 :: 1280 / 15539 - CLASS_LOSS : 0.29479
20 / 500 :: 1920 / 15539 - CLASS_LOSS : 0.18417
20 / 500 :: 2560 / 15539 - CLASS_LOSS : 0.19383
20 / 500 :: 3200 / 15539 - CLASS_LOSS : 0.17362
20 / 500 :: 3840 / 15539 - CLASS_LOSS : 0.29543
20 / 500 :: 4480 / 15539 - CLASS_LOSS : 0.22034
20 / 500 :: 5120 / 15539 - CLASS_LOSS : 0.20153
20 / 500 :: 5760 / 15539 - CLASS_LOSS : 0.24514
20 / 500 :: 6400 / 15539 - CLASS_LOSS : 0.20379
20 / 500 :: 7040 / 15539 - CLASS_LOSS : 0.20877
20 / 500 :: 7680 / 15539 - CLASS_LOSS : 0.19236
20 / 500 :: 8320 / 15539 - CLASS_LOSS : 0.28604
20 / 500 :: 8960 / 15539 - CLASS_LOSS : 0.27593
20 / 500 :: 9600 / 15539 - CLASS_LOSS : 0.1841
20 / 500 :: 10240 / 15539 - CLASS_LOSS : 0.18413
20 / 500 :: 10880 / 15539 - CLASS_LOSS : 0.24225
20 / 500 :: 11520 / 15539 - CLASS_LOSS : 0.24746
20 / 500 :: 12160 / 15539 - CLASS_LOSS : 0.17641
20 / 500 :: 12800 / 15539 - CLASS_LOSS : 0.18378
20 / 500 :: 13440 / 15539 - CLASS_LOSS : 0.2262
20 / 500 :: 14080 / 15539 - CLASS_LOSS : 0.35269
20 / 500 :: 14720 / 15539 - CLASS_LOSS : 0.1649
20 / 500 :: 15360 / 15539 - CLASS_LOSS : 0.2274
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.29590063710663495 0.25664457172276206 0.21823798185211404
PSPrecision@1,3,5: 0.18746234275699122 0.21346178688723744 0.22612079656306064
testing....
Precision@1,3,5: 0.27802572853767393 0.2358449286776932 0.19690207403517984
PSPrecision@1,3,5: 0.15856708588224153 0.18344518687460998 0.1928549731458231
21 / 500 :: 448 / 15539 - CLASS_LOSS : 0.27325
21 / 500 :: 1088 / 15539 - CLASS_LOSS : 0.32631
21 / 500 :: 1728 / 15539 - CLASS_LOSS : 0.19532
21 / 500 :: 2368 / 15539 - CLASS_LOSS : 0.20521
21 / 500 :: 3008 / 15539 - CLASS_LOSS : 0.11429
21 / 500 :: 3648 / 15539 - CLASS_LOSS : 0.21861
21 / 500 :: 4288 / 15539 - CLASS_LOSS : 0.16518
21 / 500 :: 4928 / 15539 - CLASS_LOSS : 0.25984
21 / 500 :: 5568 / 15539 - CLASS_LOSS : 0.16148
21 / 500 :: 6208 / 15539 - CLASS_LOSS : 0.22733
21 / 500 :: 6848 / 15539 - CLASS_LOSS : 0.19288
21 / 500 :: 7488 / 15539 - CLASS_LOSS : 0.26606
21 / 500 :: 8128 / 15539 - CLASS_LOSS : 0.26596
21 / 500 :: 8768 / 15539 - CLASS_LOSS : 0.19702
21 / 500 :: 9408 / 15539 - CLASS_LOSS : 0.22677
21 / 500 :: 10048 / 15539 - CLASS_LOSS : 0.20423
21 / 500 :: 10688 / 15539 - CLASS_LOSS : 0.18748
21 / 500 :: 11328 / 15539 - CLASS_LOSS : 0.19333
21 / 500 :: 11968 / 15539 - CLASS_LOSS : 0.16288
21 / 500 :: 12608 / 15539 - CLASS_LOSS : 0.28441
21 / 500 :: 13248 / 15539 - CLASS_LOSS : 0.16013
21 / 500 :: 13888 / 15539 - CLASS_LOSS : 0.18499
21 / 500 :: 14528 / 15539 - CLASS_LOSS : 0.26382
21 / 500 :: 15168 / 15539 - CLASS_LOSS : 0.2234
22 / 500 :: 256 / 15539 - CLASS_LOSS : 0.23708
22 / 500 :: 896 / 15539 - CLASS_LOSS : 0.19626
22 / 500 :: 1536 / 15539 - CLASS_LOSS : 0.21941
22 / 500 :: 2176 / 15539 - CLASS_LOSS : 0.23577
22 / 500 :: 2816 / 15539 - CLASS_LOSS : 0.20039
22 / 500 :: 3456 / 15539 - CLASS_LOSS : 0.20673
22 / 500 :: 4096 / 15539 - CLASS_LOSS : 0.22034
22 / 500 :: 4736 / 15539 - CLASS_LOSS : 0.30457
22 / 500 :: 5376 / 15539 - CLASS_LOSS : 0.20332
22 / 500 :: 6016 / 15539 - CLASS_LOSS : 0.18042
22 / 500 :: 6656 / 15539 - CLASS_LOSS : 0.21731
22 / 500 :: 7296 / 15539 - CLASS_LOSS : 0.26392
22 / 500 :: 7936 / 15539 - CLASS_LOSS : 0.27643
22 / 500 :: 8576 / 15539 - CLASS_LOSS : 0.3104
22 / 500 :: 9216 / 15539 - CLASS_LOSS : 0.12722
22 / 500 :: 9856 / 15539 - CLASS_LOSS : 0.34194
22 / 500 :: 10496 / 15539 - CLASS_LOSS : 0.12694
22 / 500 :: 11136 / 15539 - CLASS_LOSS : 0.19604
22 / 500 :: 11776 / 15539 - CLASS_LOSS : 0.21238
22 / 500 :: 12416 / 15539 - CLASS_LOSS : 0.26183
22 / 500 :: 13056 / 15539 - CLASS_LOSS : 0.25205
22 / 500 :: 13696 / 15539 - CLASS_LOSS : 0.18848
22 / 500 :: 14336 / 15539 - CLASS_LOSS : 0.19767
22 / 500 :: 14976 / 15539 - CLASS_LOSS : 0.17778
23 / 500 :: 64 / 15539 - CLASS_LOSS : 0.21969
23 / 500 :: 704 / 15539 - CLASS_LOSS : 0.23777
23 / 500 :: 1344 / 15539 - CLASS_LOSS : 0.23205
23 / 500 :: 1984 / 15539 - CLASS_LOSS : 0.14148
23 / 500 :: 2624 / 15539 - CLASS_LOSS : 0.22917
23 / 500 :: 3264 / 15539 - CLASS_LOSS : 0.17919
23 / 500 :: 3904 / 15539 - CLASS_LOSS : 0.09833
23 / 500 :: 4544 / 15539 - CLASS_LOSS : 0.26332
23 / 500 :: 5184 / 15539 - CLASS_LOSS : 0.23013
23 / 500 :: 5824 / 15539 - CLASS_LOSS : 0.17993
23 / 500 :: 6464 / 15539 - CLASS_LOSS : 0.14303
23 / 500 :: 7104 / 15539 - CLASS_LOSS : 0.39346
23 / 500 :: 7744 / 15539 - CLASS_LOSS : 0.23092
23 / 500 :: 8384 / 15539 - CLASS_LOSS : 0.22835
23 / 500 :: 9024 / 15539 - CLASS_LOSS : 0.21991
23 / 500 :: 9664 / 15539 - CLASS_LOSS : 0.20557
23 / 500 :: 10304 / 15539 - CLASS_LOSS : 0.17271
23 / 500 :: 10944 / 15539 - CLASS_LOSS : 0.25396
23 / 500 :: 11584 / 15539 - CLASS_LOSS : 0.15291
23 / 500 :: 12224 / 15539 - CLASS_LOSS : 0.22942
23 / 500 :: 12864 / 15539 - CLASS_LOSS : 0.29687
23 / 500 :: 13504 / 15539 - CLASS_LOSS : 0.30633
23 / 500 :: 14144 / 15539 - CLASS_LOSS : 0.20794
23 / 500 :: 14784 / 15539 - CLASS_LOSS : 0.24966
23 / 500 :: 15424 / 15539 - CLASS_LOSS : 0.26113
24 / 500 :: 512 / 15539 - CLASS_LOSS : 0.23627
24 / 500 :: 1152 / 15539 - CLASS_LOSS : 0.26265
24 / 500 :: 1792 / 15539 - CLASS_LOSS : 0.25815
24 / 500 :: 2432 / 15539 - CLASS_LOSS : 0.16258
24 / 500 :: 3072 / 15539 - CLASS_LOSS : 0.11211
24 / 500 :: 3712 / 15539 - CLASS_LOSS : 0.20822
24 / 500 :: 4352 / 15539 - CLASS_LOSS : 0.18328
24 / 500 :: 4992 / 15539 - CLASS_LOSS : 0.1799
24 / 500 :: 5632 / 15539 - CLASS_LOSS : 0.26393
24 / 500 :: 6272 / 15539 - CLASS_LOSS : 0.31649
24 / 500 :: 6912 / 15539 - CLASS_LOSS : 0.15235
24 / 500 :: 7552 / 15539 - CLASS_LOSS : 0.22367
24 / 500 :: 8192 / 15539 - CLASS_LOSS : 0.24692
24 / 500 :: 8832 / 15539 - CLASS_LOSS : 0.18509
24 / 500 :: 9472 / 15539 - CLASS_LOSS : 0.20951
24 / 500 :: 10112 / 15539 - CLASS_LOSS : 0.14883
24 / 500 :: 10752 / 15539 - CLASS_LOSS : 0.20474
24 / 500 :: 11392 / 15539 - CLASS_LOSS : 0.22574
24 / 500 :: 12032 / 15539 - CLASS_LOSS : 0.3205
24 / 500 :: 12672 / 15539 - CLASS_LOSS : 0.35968
24 / 500 :: 13312 / 15539 - CLASS_LOSS : 0.20449
24 / 500 :: 13952 / 15539 - CLASS_LOSS : 0.21629
24 / 500 :: 14592 / 15539 - CLASS_LOSS : 0.31627
24 / 500 :: 15232 / 15539 - CLASS_LOSS : 0.2453
25 / 500 :: 320 / 15539 - CLASS_LOSS : 0.26381
25 / 500 :: 960 / 15539 - CLASS_LOSS : 0.20991
25 / 500 :: 1600 / 15539 - CLASS_LOSS : 0.22442
25 / 500 :: 2240 / 15539 - CLASS_LOSS : 0.18251
25 / 500 :: 2880 / 15539 - CLASS_LOSS : 0.26874
25 / 500 :: 3520 / 15539 - CLASS_LOSS : 0.29607
25 / 500 :: 4160 / 15539 - CLASS_LOSS : 0.25743
25 / 500 :: 4800 / 15539 - CLASS_LOSS : 0.19454
25 / 500 :: 5440 / 15539 - CLASS_LOSS : 0.17496
25 / 500 :: 6080 / 15539 - CLASS_LOSS : 0.23182
25 / 500 :: 6720 / 15539 - CLASS_LOSS : 0.20977
25 / 500 :: 7360 / 15539 - CLASS_LOSS : 0.15101
25 / 500 :: 8000 / 15539 - CLASS_LOSS : 0.27302
25 / 500 :: 8640 / 15539 - CLASS_LOSS : 0.16227
25 / 500 :: 9280 / 15539 - CLASS_LOSS : 0.18913
25 / 500 :: 9920 / 15539 - CLASS_LOSS : 0.31748
25 / 500 :: 10560 / 15539 - CLASS_LOSS : 0.2521
25 / 500 :: 11200 / 15539 - CLASS_LOSS : 0.27006
25 / 500 :: 11840 / 15539 - CLASS_LOSS : 0.19107
25 / 500 :: 12480 / 15539 - CLASS_LOSS : 0.21443
25 / 500 :: 13120 / 15539 - CLASS_LOSS : 0.20472
25 / 500 :: 13760 / 15539 - CLASS_LOSS : 0.1548
25 / 500 :: 14400 / 15539 - CLASS_LOSS : 0.28274
25 / 500 :: 15040 / 15539 - CLASS_LOSS : 0.1902
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.30864276980500677 0.2645172362013858 0.2271317330587554
PSPrecision@1,3,5: 0.20485995303049545 0.22659836328925753 0.24005608902056988
testing....
Precision@1,3,5: 0.29036492517721185 0.24363349960619585 0.20981885009188764
PSPrecision@1,3,5: 0.16723799637236522 0.19107224293227815 0.20514295730227977
26 / 500 :: 128 / 15539 - CLASS_LOSS : 0.16717
26 / 500 :: 768 / 15539 - CLASS_LOSS : 0.24112
26 / 500 :: 1408 / 15539 - CLASS_LOSS : 0.1743
26 / 500 :: 2048 / 15539 - CLASS_LOSS : 0.16384
26 / 500 :: 2688 / 15539 - CLASS_LOSS : 0.2099
26 / 500 :: 3328 / 15539 - CLASS_LOSS : 0.20613
26 / 500 :: 3968 / 15539 - CLASS_LOSS : 0.17719
26 / 500 :: 4608 / 15539 - CLASS_LOSS : 0.24473
26 / 500 :: 5248 / 15539 - CLASS_LOSS : 0.15059
26 / 500 :: 5888 / 15539 - CLASS_LOSS : 0.2389
26 / 500 :: 6528 / 15539 - CLASS_LOSS : 0.10945
26 / 500 :: 7168 / 15539 - CLASS_LOSS : 0.16964
26 / 500 :: 7808 / 15539 - CLASS_LOSS : 0.24725
26 / 500 :: 8448 / 15539 - CLASS_LOSS : 0.16964
26 / 500 :: 9088 / 15539 - CLASS_LOSS : 0.16805
26 / 500 :: 9728 / 15539 - CLASS_LOSS : 0.19985
26 / 500 :: 10368 / 15539 - CLASS_LOSS : 0.23445
26 / 500 :: 11008 / 15539 - CLASS_LOSS : 0.23468
26 / 500 :: 11648 / 15539 - CLASS_LOSS : 0.28208
26 / 500 :: 12288 / 15539 - CLASS_LOSS : 0.21193
26 / 500 :: 12928 / 15539 - CLASS_LOSS : 0.23362
26 / 500 :: 13568 / 15539 - CLASS_LOSS : 0.17168
26 / 500 :: 14208 / 15539 - CLASS_LOSS : 0.30599
26 / 500 :: 14848 / 15539 - CLASS_LOSS : 0.2462
26 / 500 :: 15488 / 15539 - CLASS_LOSS : 0.24456
27 / 500 :: 576 / 15539 - CLASS_LOSS : 0.20527
27 / 500 :: 1216 / 15539 - CLASS_LOSS : 0.25628
27 / 500 :: 1856 / 15539 - CLASS_LOSS : 0.18326
27 / 500 :: 2496 / 15539 - CLASS_LOSS : 0.20076
27 / 500 :: 3136 / 15539 - CLASS_LOSS : 0.27708
27 / 500 :: 3776 / 15539 - CLASS_LOSS : 0.22732
27 / 500 :: 4416 / 15539 - CLASS_LOSS : 0.35255
27 / 500 :: 5056 / 15539 - CLASS_LOSS : 0.1879
27 / 500 :: 5696 / 15539 - CLASS_LOSS : 0.26221
27 / 500 :: 6336 / 15539 - CLASS_LOSS : 0.21171
27 / 500 :: 6976 / 15539 - CLASS_LOSS : 0.4644
27 / 500 :: 7616 / 15539 - CLASS_LOSS : 0.15333
27 / 500 :: 8256 / 15539 - CLASS_LOSS : 0.14663
27 / 500 :: 8896 / 15539 - CLASS_LOSS : 0.18394
27 / 500 :: 9536 / 15539 - CLASS_LOSS : 0.16636
27 / 500 :: 10176 / 15539 - CLASS_LOSS : 0.23194
27 / 500 :: 10816 / 15539 - CLASS_LOSS : 0.32006
27 / 500 :: 11456 / 15539 - CLASS_LOSS : 0.19569
27 / 500 :: 12096 / 15539 - CLASS_LOSS : 0.207
27 / 500 :: 12736 / 15539 - CLASS_LOSS : 0.2736
27 / 500 :: 13376 / 15539 - CLASS_LOSS : 0.20304
27 / 500 :: 14016 / 15539 - CLASS_LOSS : 0.18556
27 / 500 :: 14656 / 15539 - CLASS_LOSS : 0.14647
27 / 500 :: 15296 / 15539 - CLASS_LOSS : 0.23449
28 / 500 :: 384 / 15539 - CLASS_LOSS : 0.25987
28 / 500 :: 1024 / 15539 - CLASS_LOSS : 0.42914
28 / 500 :: 1664 / 15539 - CLASS_LOSS : 0.32268
28 / 500 :: 2304 / 15539 - CLASS_LOSS : 0.24012
28 / 500 :: 2944 / 15539 - CLASS_LOSS : 0.3226
28 / 500 :: 3584 / 15539 - CLASS_LOSS : 0.1829
28 / 500 :: 4224 / 15539 - CLASS_LOSS : 0.32959
28 / 500 :: 4864 / 15539 - CLASS_LOSS : 0.28107
28 / 500 :: 5504 / 15539 - CLASS_LOSS : 0.31314
28 / 500 :: 6144 / 15539 - CLASS_LOSS : 0.24702
28 / 500 :: 6784 / 15539 - CLASS_LOSS : 0.19591
28 / 500 :: 7424 / 15539 - CLASS_LOSS : 0.13926
28 / 500 :: 8064 / 15539 - CLASS_LOSS : 0.25416
28 / 500 :: 8704 / 15539 - CLASS_LOSS : 0.23847
28 / 500 :: 9344 / 15539 - CLASS_LOSS : 0.35652
28 / 500 :: 9984 / 15539 - CLASS_LOSS : 0.20256
28 / 500 :: 10624 / 15539 - CLASS_LOSS : 0.17517
28 / 500 :: 11264 / 15539 - CLASS_LOSS : 0.09212
28 / 500 :: 11904 / 15539 - CLASS_LOSS : 0.26432
28 / 500 :: 12544 / 15539 - CLASS_LOSS : 0.16414
28 / 500 :: 13184 / 15539 - CLASS_LOSS : 0.2529
28 / 500 :: 13824 / 15539 - CLASS_LOSS : 0.1747
28 / 500 :: 14464 / 15539 - CLASS_LOSS : 0.22916
28 / 500 :: 15104 / 15539 - CLASS_LOSS : 0.11971
29 / 500 :: 192 / 15539 - CLASS_LOSS : 0.24457
29 / 500 :: 832 / 15539 - CLASS_LOSS : 0.25104
29 / 500 :: 1472 / 15539 - CLASS_LOSS : 0.23342
29 / 500 :: 2112 / 15539 - CLASS_LOSS : 0.19878
29 / 500 :: 2752 / 15539 - CLASS_LOSS : 0.27212
29 / 500 :: 3392 / 15539 - CLASS_LOSS : 0.17979
29 / 500 :: 4032 / 15539 - CLASS_LOSS : 0.29671
29 / 500 :: 4672 / 15539 - CLASS_LOSS : 0.23982
29 / 500 :: 5312 / 15539 - CLASS_LOSS : 0.20934
29 / 500 :: 5952 / 15539 - CLASS_LOSS : 0.12335
29 / 500 :: 6592 / 15539 - CLASS_LOSS : 0.18068
29 / 500 :: 7232 / 15539 - CLASS_LOSS : 0.19746
29 / 500 :: 7872 / 15539 - CLASS_LOSS : 0.16964
29 / 500 :: 8512 / 15539 - CLASS_LOSS : 0.15583
29 / 500 :: 9152 / 15539 - CLASS_LOSS : 0.295
29 / 500 :: 9792 / 15539 - CLASS_LOSS : 0.28409
29 / 500 :: 10432 / 15539 - CLASS_LOSS : 0.19167
29 / 500 :: 11072 / 15539 - CLASS_LOSS : 0.17365
29 / 500 :: 11712 / 15539 - CLASS_LOSS : 0.14956
29 / 500 :: 12352 / 15539 - CLASS_LOSS : 0.17436
29 / 500 :: 12992 / 15539 - CLASS_LOSS : 0.14678
29 / 500 :: 13632 / 15539 - CLASS_LOSS : 0.19831
29 / 500 :: 14272 / 15539 - CLASS_LOSS : 0.30322
29 / 500 :: 14912 / 15539 - CLASS_LOSS : 0.23386
29 / 500 :: 15539 / 15539 - CLASS_LOSS : 0.36175
30 / 500 :: 640 / 15539 - CLASS_LOSS : 0.21274
30 / 500 :: 1280 / 15539 - CLASS_LOSS : 0.18791
30 / 500 :: 1920 / 15539 - CLASS_LOSS : 0.258
30 / 500 :: 2560 / 15539 - CLASS_LOSS : 0.2512
30 / 500 :: 3200 / 15539 - CLASS_LOSS : 0.1829
30 / 500 :: 3840 / 15539 - CLASS_LOSS : 0.3141
30 / 500 :: 4480 / 15539 - CLASS_LOSS : 0.22269
30 / 500 :: 5120 / 15539 - CLASS_LOSS : 0.38871
30 / 500 :: 5760 / 15539 - CLASS_LOSS : 0.12055
30 / 500 :: 6400 / 15539 - CLASS_LOSS : 0.13101
30 / 500 :: 7040 / 15539 - CLASS_LOSS : 0.20993
30 / 500 :: 7680 / 15539 - CLASS_LOSS : 0.17787
30 / 500 :: 8320 / 15539 - CLASS_LOSS : 0.12628
30 / 500 :: 8960 / 15539 - CLASS_LOSS : 0.2618
30 / 500 :: 9600 / 15539 - CLASS_LOSS : 0.19576
30 / 500 :: 10240 / 15539 - CLASS_LOSS : 0.18589
30 / 500 :: 10880 / 15539 - CLASS_LOSS : 0.15141
30 / 500 :: 11520 / 15539 - CLASS_LOSS : 0.12051
30 / 500 :: 12160 / 15539 - CLASS_LOSS : 0.15678
30 / 500 :: 12800 / 15539 - CLASS_LOSS : 0.21367
30 / 500 :: 13440 / 15539 - CLASS_LOSS : 0.2176
30 / 500 :: 14080 / 15539 - CLASS_LOSS : 0.3005
30 / 500 :: 14720 / 15539 - CLASS_LOSS : 0.19154
30 / 500 :: 15360 / 15539 - CLASS_LOSS : 0.13104
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.313919814659888 0.2725400604929532 0.23606409678872514
PSPrecision@1,3,5: 0.2153461791171112 0.2395229228538994 0.2556473960971256
testing....
Precision@1,3,5: 0.29719086374376474 0.2488842215804673 0.21569965870307167
PSPrecision@1,3,5: 0.17674139282985088 0.19686814790173718 0.21316923423918363
31 / 500 :: 448 / 15539 - CLASS_LOSS : 0.18819
31 / 500 :: 1088 / 15539 - CLASS_LOSS : 0.23941
31 / 500 :: 1728 / 15539 - CLASS_LOSS : 0.15277
31 / 500 :: 2368 / 15539 - CLASS_LOSS : 0.22521
31 / 500 :: 3008 / 15539 - CLASS_LOSS : 0.27484
31 / 500 :: 3648 / 15539 - CLASS_LOSS : 0.30902
31 / 500 :: 4288 / 15539 - CLASS_LOSS : 0.21829
31 / 500 :: 4928 / 15539 - CLASS_LOSS : 0.26765
31 / 500 :: 5568 / 15539 - CLASS_LOSS : 0.12955
31 / 500 :: 6208 / 15539 - CLASS_LOSS : 0.19835
31 / 500 :: 6848 / 15539 - CLASS_LOSS : 0.21141
31 / 500 :: 7488 / 15539 - CLASS_LOSS : 0.13498
31 / 500 :: 8128 / 15539 - CLASS_LOSS : 0.17728
31 / 500 :: 8768 / 15539 - CLASS_LOSS : 0.2537
31 / 500 :: 9408 / 15539 - CLASS_LOSS : 0.25923
31 / 500 :: 10048 / 15539 - CLASS_LOSS : 0.21495
31 / 500 :: 10688 / 15539 - CLASS_LOSS : 0.18354
31 / 500 :: 11328 / 15539 - CLASS_LOSS : 0.23575
31 / 500 :: 11968 / 15539 - CLASS_LOSS : 0.22442
31 / 500 :: 12608 / 15539 - CLASS_LOSS : 0.3422
31 / 500 :: 13248 / 15539 - CLASS_LOSS : 0.16114
31 / 500 :: 13888 / 15539 - CLASS_LOSS : 0.1845
31 / 500 :: 14528 / 15539 - CLASS_LOSS : 0.20105
31 / 500 :: 15168 / 15539 - CLASS_LOSS : 0.20925
32 / 500 :: 256 / 15539 - CLASS_LOSS : 0.15535
32 / 500 :: 896 / 15539 - CLASS_LOSS : 0.26186
32 / 500 :: 1536 / 15539 - CLASS_LOSS : 0.3285
32 / 500 :: 2176 / 15539 - CLASS_LOSS : 0.15677
32 / 500 :: 2816 / 15539 - CLASS_LOSS : 0.18547
32 / 500 :: 3456 / 15539 - CLASS_LOSS : 0.16094
32 / 500 :: 4096 / 15539 - CLASS_LOSS : 0.13872
32 / 500 :: 4736 / 15539 - CLASS_LOSS : 0.21003
32 / 500 :: 5376 / 15539 - CLASS_LOSS : 0.16326
32 / 500 :: 6016 / 15539 - CLASS_LOSS : 0.22918
32 / 500 :: 6656 / 15539 - CLASS_LOSS : 0.20681
32 / 500 :: 7296 / 15539 - CLASS_LOSS : 0.12539
32 / 500 :: 7936 / 15539 - CLASS_LOSS : 0.27945
32 / 500 :: 8576 / 15539 - CLASS_LOSS : 0.12063
32 / 500 :: 9216 / 15539 - CLASS_LOSS : 0.2439
32 / 500 :: 9856 / 15539 - CLASS_LOSS : 0.14562
32 / 500 :: 10496 / 15539 - CLASS_LOSS : 0.26046
32 / 500 :: 11136 / 15539 - CLASS_LOSS : 0.1539
32 / 500 :: 11776 / 15539 - CLASS_LOSS : 0.2474
32 / 500 :: 12416 / 15539 - CLASS_LOSS : 0.26008
32 / 500 :: 13056 / 15539 - CLASS_LOSS : 0.17685
32 / 500 :: 13696 / 15539 - CLASS_LOSS : 0.16616
32 / 500 :: 14336 / 15539 - CLASS_LOSS : 0.35209
32 / 500 :: 14976 / 15539 - CLASS_LOSS : 0.15408
33 / 500 :: 64 / 15539 - CLASS_LOSS : 0.17597
33 / 500 :: 704 / 15539 - CLASS_LOSS : 0.14415
33 / 500 :: 1344 / 15539 - CLASS_LOSS : 0.19578
33 / 500 :: 1984 / 15539 - CLASS_LOSS : 0.23441
33 / 500 :: 2624 / 15539 - CLASS_LOSS : 0.20064
33 / 500 :: 3264 / 15539 - CLASS_LOSS : 0.18514
33 / 500 :: 3904 / 15539 - CLASS_LOSS : 0.17398
33 / 500 :: 4544 / 15539 - CLASS_LOSS : 0.18692
33 / 500 :: 5184 / 15539 - CLASS_LOSS : 0.14428
33 / 500 :: 5824 / 15539 - CLASS_LOSS : 0.26658
33 / 500 :: 6464 / 15539 - CLASS_LOSS : 0.18606
33 / 500 :: 7104 / 15539 - CLASS_LOSS : 0.25893
33 / 500 :: 7744 / 15539 - CLASS_LOSS : 0.16415
33 / 500 :: 8384 / 15539 - CLASS_LOSS : 0.19527
33 / 500 :: 9024 / 15539 - CLASS_LOSS : 0.2186
33 / 500 :: 9664 / 15539 - CLASS_LOSS : 0.26509
33 / 500 :: 10304 / 15539 - CLASS_LOSS : 0.17608
33 / 500 :: 10944 / 15539 - CLASS_LOSS : 0.21202
33 / 500 :: 11584 / 15539 - CLASS_LOSS : 0.19452
33 / 500 :: 12224 / 15539 - CLASS_LOSS : 0.18684
33 / 500 :: 12864 / 15539 - CLASS_LOSS : 0.23809
33 / 500 :: 13504 / 15539 - CLASS_LOSS : 0.23846
33 / 500 :: 14144 / 15539 - CLASS_LOSS : 0.11865
33 / 500 :: 14784 / 15539 - CLASS_LOSS : 0.18481
33 / 500 :: 15424 / 15539 - CLASS_LOSS : 0.30622
34 / 500 :: 512 / 15539 - CLASS_LOSS : 0.25167
34 / 500 :: 1152 / 15539 - CLASS_LOSS : 0.19333
34 / 500 :: 1792 / 15539 - CLASS_LOSS : 0.32128
34 / 500 :: 2432 / 15539 - CLASS_LOSS : 0.19059
34 / 500 :: 3072 / 15539 - CLASS_LOSS : 0.1764
34 / 500 :: 3712 / 15539 - CLASS_LOSS : 0.19061
34 / 500 :: 4352 / 15539 - CLASS_LOSS : 0.20011
34 / 500 :: 4992 / 15539 - CLASS_LOSS : 0.16369
34 / 500 :: 5632 / 15539 - CLASS_LOSS : 0.20168
34 / 500 :: 6272 / 15539 - CLASS_LOSS : 0.13729
34 / 500 :: 6912 / 15539 - CLASS_LOSS : 0.16441
34 / 500 :: 7552 / 15539 - CLASS_LOSS : 0.23516
34 / 500 :: 8192 / 15539 - CLASS_LOSS : 0.11417
34 / 500 :: 8832 / 15539 - CLASS_LOSS : 0.24254
34 / 500 :: 9472 / 15539 - CLASS_LOSS : 0.15138
34 / 500 :: 10112 / 15539 - CLASS_LOSS : 0.24554
34 / 500 :: 10752 / 15539 - CLASS_LOSS : 0.23664
34 / 500 :: 11392 / 15539 - CLASS_LOSS : 0.14261
34 / 500 :: 12032 / 15539 - CLASS_LOSS : 0.14506
34 / 500 :: 12672 / 15539 - CLASS_LOSS : 0.24326
34 / 500 :: 13312 / 15539 - CLASS_LOSS : 0.18676
34 / 500 :: 13952 / 15539 - CLASS_LOSS : 0.14563
34 / 500 :: 14592 / 15539 - CLASS_LOSS : 0.19069
34 / 500 :: 15232 / 15539 - CLASS_LOSS : 0.20735
35 / 500 :: 320 / 15539 - CLASS_LOSS : 0.2083
35 / 500 :: 960 / 15539 - CLASS_LOSS : 0.31665
35 / 500 :: 1600 / 15539 - CLASS_LOSS : 0.185
35 / 500 :: 2240 / 15539 - CLASS_LOSS : 0.22849
35 / 500 :: 2880 / 15539 - CLASS_LOSS : 0.14476
35 / 500 :: 3520 / 15539 - CLASS_LOSS : 0.20103
35 / 500 :: 4160 / 15539 - CLASS_LOSS : 0.229
35 / 500 :: 4800 / 15539 - CLASS_LOSS : 0.25318
35 / 500 :: 5440 / 15539 - CLASS_LOSS : 0.21703
35 / 500 :: 6080 / 15539 - CLASS_LOSS : 0.25852
35 / 500 :: 6720 / 15539 - CLASS_LOSS : 0.34696
35 / 500 :: 7360 / 15539 - CLASS_LOSS : 0.09772
35 / 500 :: 8000 / 15539 - CLASS_LOSS : 0.23408
35 / 500 :: 8640 / 15539 - CLASS_LOSS : 0.42268
35 / 500 :: 9280 / 15539 - CLASS_LOSS : 0.20412
35 / 500 :: 9920 / 15539 - CLASS_LOSS : 0.20928
35 / 500 :: 10560 / 15539 - CLASS_LOSS : 0.20874
35 / 500 :: 11200 / 15539 - CLASS_LOSS : 0.18305
35 / 500 :: 11840 / 15539 - CLASS_LOSS : 0.25408
35 / 500 :: 12480 / 15539 - CLASS_LOSS : 0.27075
35 / 500 :: 13120 / 15539 - CLASS_LOSS : 0.18385
35 / 500 :: 13760 / 15539 - CLASS_LOSS : 0.19999
35 / 500 :: 14400 / 15539 - CLASS_LOSS : 0.14794
35 / 500 :: 15040 / 15539 - CLASS_LOSS : 0.15509
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.3215136109144733 0.2820430315121093 0.24392818070660918
PSPrecision@1,3,5: 0.2228054976818568 0.2503014828832018 0.2669733350680568
testing....
Precision@1,3,5: 0.31793121554213705 0.26516145970070887 0.2244158571803623
PSPrecision@1,3,5: 0.19651077954211074 0.21267923596906174 0.22363498271196885
36 / 500 :: 128 / 15539 - CLASS_LOSS : 0.20167
36 / 500 :: 768 / 15539 - CLASS_LOSS : 0.20007
36 / 500 :: 1408 / 15539 - CLASS_LOSS : 0.15471
36 / 500 :: 2048 / 15539 - CLASS_LOSS : 0.20804
36 / 500 :: 2688 / 15539 - CLASS_LOSS : 0.2554
36 / 500 :: 3328 / 15539 - CLASS_LOSS : 0.24171
36 / 500 :: 3968 / 15539 - CLASS_LOSS : 0.13287
36 / 500 :: 4608 / 15539 - CLASS_LOSS : 0.27972
36 / 500 :: 5248 / 15539 - CLASS_LOSS : 0.17302
36 / 500 :: 5888 / 15539 - CLASS_LOSS : 0.23439
36 / 500 :: 6528 / 15539 - CLASS_LOSS : 0.17855
36 / 500 :: 7168 / 15539 - CLASS_LOSS : 0.18264
36 / 500 :: 7808 / 15539 - CLASS_LOSS : 0.17596
36 / 500 :: 8448 / 15539 - CLASS_LOSS : 0.15495
36 / 500 :: 9088 / 15539 - CLASS_LOSS : 0.20062
36 / 500 :: 9728 / 15539 - CLASS_LOSS : 0.13434
36 / 500 :: 10368 / 15539 - CLASS_LOSS : 0.1377
36 / 500 :: 11008 / 15539 - CLASS_LOSS : 0.16812
36 / 500 :: 11648 / 15539 - CLASS_LOSS : 0.2277
36 / 500 :: 12288 / 15539 - CLASS_LOSS : 0.19691
36 / 500 :: 12928 / 15539 - CLASS_LOSS : 0.17345
36 / 500 :: 13568 / 15539 - CLASS_LOSS : 0.20194
36 / 500 :: 14208 / 15539 - CLASS_LOSS : 0.22725
36 / 500 :: 14848 / 15539 - CLASS_LOSS : 0.14407
36 / 500 :: 15488 / 15539 - CLASS_LOSS : 0.22288
37 / 500 :: 576 / 15539 - CLASS_LOSS : 0.19525
37 / 500 :: 1216 / 15539 - CLASS_LOSS : 0.18529
37 / 500 :: 1856 / 15539 - CLASS_LOSS : 0.22871
37 / 500 :: 2496 / 15539 - CLASS_LOSS : 0.15695
37 / 500 :: 3136 / 15539 - CLASS_LOSS : 0.23051
37 / 500 :: 3776 / 15539 - CLASS_LOSS : 0.20248
37 / 500 :: 4416 / 15539 - CLASS_LOSS : 0.24346
37 / 500 :: 5056 / 15539 - CLASS_LOSS : 0.18792
37 / 500 :: 5696 / 15539 - CLASS_LOSS : 0.18322
37 / 500 :: 6336 / 15539 - CLASS_LOSS : 0.26004
37 / 500 :: 6976 / 15539 - CLASS_LOSS : 0.17461
37 / 500 :: 7616 / 15539 - CLASS_LOSS : 0.11656
37 / 500 :: 8256 / 15539 - CLASS_LOSS : 0.20998
37 / 500 :: 8896 / 15539 - CLASS_LOSS : 0.13643
37 / 500 :: 9536 / 15539 - CLASS_LOSS : 0.23724
37 / 500 :: 10176 / 15539 - CLASS_LOSS : 0.26685
37 / 500 :: 10816 / 15539 - CLASS_LOSS : 0.16083
37 / 500 :: 11456 / 15539 - CLASS_LOSS : 0.20137
37 / 500 :: 12096 / 15539 - CLASS_LOSS : 0.15299
37 / 500 :: 12736 / 15539 - CLASS_LOSS : 0.22003
37 / 500 :: 13376 / 15539 - CLASS_LOSS : 0.20779
37 / 500 :: 14016 / 15539 - CLASS_LOSS : 0.13987
37 / 500 :: 14656 / 15539 - CLASS_LOSS : 0.21618
37 / 500 :: 15296 / 15539 - CLASS_LOSS : 0.10142
38 / 500 :: 384 / 15539 - CLASS_LOSS : 0.2579
38 / 500 :: 1024 / 15539 - CLASS_LOSS : 0.12684
38 / 500 :: 1664 / 15539 - CLASS_LOSS : 0.1042
38 / 500 :: 2304 / 15539 - CLASS_LOSS : 0.10021
38 / 500 :: 2944 / 15539 - CLASS_LOSS : 0.17482
38 / 500 :: 3584 / 15539 - CLASS_LOSS : 0.2209
38 / 500 :: 4224 / 15539 - CLASS_LOSS : 0.20103
38 / 500 :: 4864 / 15539 - CLASS_LOSS : 0.20858
38 / 500 :: 5504 / 15539 - CLASS_LOSS : 0.13795
38 / 500 :: 6144 / 15539 - CLASS_LOSS : 0.28137
38 / 500 :: 6784 / 15539 - CLASS_LOSS : 0.21309
38 / 500 :: 7424 / 15539 - CLASS_LOSS : 0.20696
38 / 500 :: 8064 / 15539 - CLASS_LOSS : 0.10334
38 / 500 :: 8704 / 15539 - CLASS_LOSS : 0.16824
38 / 500 :: 9344 / 15539 - CLASS_LOSS : 0.14168
38 / 500 :: 9984 / 15539 - CLASS_LOSS : 0.20573
38 / 500 :: 10624 / 15539 - CLASS_LOSS : 0.20948
38 / 500 :: 11264 / 15539 - CLASS_LOSS : 0.18248
38 / 500 :: 11904 / 15539 - CLASS_LOSS : 0.27402
38 / 500 :: 12544 / 15539 - CLASS_LOSS : 0.18752
38 / 500 :: 13184 / 15539 - CLASS_LOSS : 0.20288
38 / 500 :: 13824 / 15539 - CLASS_LOSS : 0.17967
38 / 500 :: 14464 / 15539 - CLASS_LOSS : 0.20644
38 / 500 :: 15104 / 15539 - CLASS_LOSS : 0.30595
39 / 500 :: 192 / 15539 - CLASS_LOSS : 0.2329
39 / 500 :: 832 / 15539 - CLASS_LOSS : 0.19228
39 / 500 :: 1472 / 15539 - CLASS_LOSS : 0.22023
39 / 500 :: 2112 / 15539 - CLASS_LOSS : 0.18463
39 / 500 :: 2752 / 15539 - CLASS_LOSS : 0.23867
39 / 500 :: 3392 / 15539 - CLASS_LOSS : 0.19258
39 / 500 :: 4032 / 15539 - CLASS_LOSS : 0.17372
39 / 500 :: 4672 / 15539 - CLASS_LOSS : 0.23224
39 / 500 :: 5312 / 15539 - CLASS_LOSS : 0.24162
39 / 500 :: 5952 / 15539 - CLASS_LOSS : 0.26927
39 / 500 :: 6592 / 15539 - CLASS_LOSS : 0.2408
39 / 500 :: 7232 / 15539 - CLASS_LOSS : 0.29504
39 / 500 :: 7872 / 15539 - CLASS_LOSS : 0.23663
39 / 500 :: 8512 / 15539 - CLASS_LOSS : 0.19067
39 / 500 :: 9152 / 15539 - CLASS_LOSS : 0.19837
39 / 500 :: 9792 / 15539 - CLASS_LOSS : 0.18941
39 / 500 :: 10432 / 15539 - CLASS_LOSS : 0.16599
39 / 500 :: 11072 / 15539 - CLASS_LOSS : 0.36584
39 / 500 :: 11712 / 15539 - CLASS_LOSS : 0.17781
39 / 500 :: 12352 / 15539 - CLASS_LOSS : 0.28925
39 / 500 :: 12992 / 15539 - CLASS_LOSS : 0.14126
39 / 500 :: 13632 / 15539 - CLASS_LOSS : 0.14466
39 / 500 :: 14272 / 15539 - CLASS_LOSS : 0.14192
39 / 500 :: 14912 / 15539 - CLASS_LOSS : 0.1381
39 / 500 :: 15539 / 15539 - CLASS_LOSS : 0.38556
40 / 500 :: 640 / 15539 - CLASS_LOSS : 0.15355
40 / 500 :: 1280 / 15539 - CLASS_LOSS : 0.14612
40 / 500 :: 1920 / 15539 - CLASS_LOSS : 0.13261
40 / 500 :: 2560 / 15539 - CLASS_LOSS : 0.21175
40 / 500 :: 3200 / 15539 - CLASS_LOSS : 0.165
40 / 500 :: 3840 / 15539 - CLASS_LOSS : 0.30055
40 / 500 :: 4480 / 15539 - CLASS_LOSS : 0.24783
40 / 500 :: 5120 / 15539 - CLASS_LOSS : 0.34189
40 / 500 :: 5760 / 15539 - CLASS_LOSS : 0.17101
40 / 500 :: 6400 / 15539 - CLASS_LOSS : 0.20959
40 / 500 :: 7040 / 15539 - CLASS_LOSS : 0.28393
40 / 500 :: 7680 / 15539 - CLASS_LOSS : 0.21378
40 / 500 :: 8320 / 15539 - CLASS_LOSS : 0.19642
40 / 500 :: 8960 / 15539 - CLASS_LOSS : 0.16111
40 / 500 :: 9600 / 15539 - CLASS_LOSS : 0.24614
40 / 500 :: 10240 / 15539 - CLASS_LOSS : 0.28692
40 / 500 :: 10880 / 15539 - CLASS_LOSS : 0.17493
40 / 500 :: 11520 / 15539 - CLASS_LOSS : 0.28349
40 / 500 :: 12160 / 15539 - CLASS_LOSS : 0.2213
40 / 500 :: 12800 / 15539 - CLASS_LOSS : 0.30728
40 / 500 :: 13440 / 15539 - CLASS_LOSS : 0.17647
40 / 500 :: 14080 / 15539 - CLASS_LOSS : 0.22673
40 / 500 :: 14720 / 15539 - CLASS_LOSS : 0.15269
40 / 500 :: 15360 / 15539 - CLASS_LOSS : 0.16951
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.3403693931398417 0.2906450436536028 0.25174078126005534
PSPrecision@1,3,5: 0.23769520437685615 0.26121645461384074 0.2782853112626574
testing....
Precision@1,3,5: 0.3223943292202678 0.2685744289839853 0.22856392754003677
PSPrecision@1,3,5: 0.19635803332143972 0.21626537907000198 0.23065185075348668
41 / 500 :: 448 / 15539 - CLASS_LOSS : 0.22246
41 / 500 :: 1088 / 15539 - CLASS_LOSS : 0.15991
41 / 500 :: 1728 / 15539 - CLASS_LOSS : 0.37224
41 / 500 :: 2368 / 15539 - CLASS_LOSS : 0.13676
41 / 500 :: 3008 / 15539 - CLASS_LOSS : 0.18419
41 / 500 :: 3648 / 15539 - CLASS_LOSS : 0.1694
41 / 500 :: 4288 / 15539 - CLASS_LOSS : 0.22159
41 / 500 :: 4928 / 15539 - CLASS_LOSS : 0.16915
41 / 500 :: 5568 / 15539 - CLASS_LOSS : 0.25758
41 / 500 :: 6208 / 15539 - CLASS_LOSS : 0.26451
41 / 500 :: 6848 / 15539 - CLASS_LOSS : 0.1695
41 / 500 :: 7488 / 15539 - CLASS_LOSS : 0.20673
41 / 500 :: 8128 / 15539 - CLASS_LOSS : 0.24448
41 / 500 :: 8768 / 15539 - CLASS_LOSS : 0.18271
41 / 500 :: 9408 / 15539 - CLASS_LOSS : 0.12845
41 / 500 :: 10048 / 15539 - CLASS_LOSS : 0.14539
41 / 500 :: 10688 / 15539 - CLASS_LOSS : 0.21366
41 / 500 :: 11328 / 15539 - CLASS_LOSS : 0.24609
41 / 500 :: 11968 / 15539 - CLASS_LOSS : 0.30312
41 / 500 :: 12608 / 15539 - CLASS_LOSS : 0.2836
41 / 500 :: 13248 / 15539 - CLASS_LOSS : 0.07928
41 / 500 :: 13888 / 15539 - CLASS_LOSS : 0.19509
41 / 500 :: 14528 / 15539 - CLASS_LOSS : 0.17846
41 / 500 :: 15168 / 15539 - CLASS_LOSS : 0.20025
42 / 500 :: 256 / 15539 - CLASS_LOSS : 0.2044
42 / 500 :: 896 / 15539 - CLASS_LOSS : 0.19019
42 / 500 :: 1536 / 15539 - CLASS_LOSS : 0.14876
42 / 500 :: 2176 / 15539 - CLASS_LOSS : 0.16057
42 / 500 :: 2816 / 15539 - CLASS_LOSS : 0.18788
42 / 500 :: 3456 / 15539 - CLASS_LOSS : 0.16513
42 / 500 :: 4096 / 15539 - CLASS_LOSS : 0.18781
42 / 500 :: 4736 / 15539 - CLASS_LOSS : 0.21263
42 / 500 :: 5376 / 15539 - CLASS_LOSS : 0.27461
42 / 500 :: 6016 / 15539 - CLASS_LOSS : 0.27069
42 / 500 :: 6656 / 15539 - CLASS_LOSS : 0.19119
42 / 500 :: 7296 / 15539 - CLASS_LOSS : 0.14932
42 / 500 :: 7936 / 15539 - CLASS_LOSS : 0.17462
42 / 500 :: 8576 / 15539 - CLASS_LOSS : 0.26718
42 / 500 :: 9216 / 15539 - CLASS_LOSS : 0.27435
42 / 500 :: 9856 / 15539 - CLASS_LOSS : 0.24174
42 / 500 :: 10496 / 15539 - CLASS_LOSS : 0.07869
42 / 500 :: 11136 / 15539 - CLASS_LOSS : 0.09445
42 / 500 :: 11776 / 15539 - CLASS_LOSS : 0.2457
42 / 500 :: 12416 / 15539 - CLASS_LOSS : 0.23675
42 / 500 :: 13056 / 15539 - CLASS_LOSS : 0.24979
42 / 500 :: 13696 / 15539 - CLASS_LOSS : 0.18205
42 / 500 :: 14336 / 15539 - CLASS_LOSS : 0.19931
42 / 500 :: 14976 / 15539 - CLASS_LOSS : 0.19311
43 / 500 :: 64 / 15539 - CLASS_LOSS : 0.23579
43 / 500 :: 704 / 15539 - CLASS_LOSS : 0.21797
43 / 500 :: 1344 / 15539 - CLASS_LOSS : 0.26986
43 / 500 :: 1984 / 15539 - CLASS_LOSS : 0.14497
43 / 500 :: 2624 / 15539 - CLASS_LOSS : 0.1443
43 / 500 :: 3264 / 15539 - CLASS_LOSS : 0.19596
43 / 500 :: 3904 / 15539 - CLASS_LOSS : 0.34139
43 / 500 :: 4544 / 15539 - CLASS_LOSS : 0.19267
43 / 500 :: 5184 / 15539 - CLASS_LOSS : 0.20424
43 / 500 :: 5824 / 15539 - CLASS_LOSS : 0.15193
43 / 500 :: 6464 / 15539 - CLASS_LOSS : 0.31937
43 / 500 :: 7104 / 15539 - CLASS_LOSS : 0.20317
43 / 500 :: 7744 / 15539 - CLASS_LOSS : 0.17436
43 / 500 :: 8384 / 15539 - CLASS_LOSS : 0.17323
43 / 500 :: 9024 / 15539 - CLASS_LOSS : 0.1873
43 / 500 :: 9664 / 15539 - CLASS_LOSS : 0.15641
43 / 500 :: 10304 / 15539 - CLASS_LOSS : 0.18234
43 / 500 :: 10944 / 15539 - CLASS_LOSS : 0.25264
43 / 500 :: 11584 / 15539 - CLASS_LOSS : 0.16818
43 / 500 :: 12224 / 15539 - CLASS_LOSS : 0.13178
43 / 500 :: 12864 / 15539 - CLASS_LOSS : 0.2588
43 / 500 :: 13504 / 15539 - CLASS_LOSS : 0.18019
43 / 500 :: 14144 / 15539 - CLASS_LOSS : 0.21231
43 / 500 :: 14784 / 15539 - CLASS_LOSS : 0.19444
43 / 500 :: 15424 / 15539 - CLASS_LOSS : 0.21304
44 / 500 :: 512 / 15539 - CLASS_LOSS : 0.10589
44 / 500 :: 1152 / 15539 - CLASS_LOSS : 0.29235
44 / 500 :: 1792 / 15539 - CLASS_LOSS : 0.16481
44 / 500 :: 2432 / 15539 - CLASS_LOSS : 0.15645
44 / 500 :: 3072 / 15539 - CLASS_LOSS : 0.24791
44 / 500 :: 3712 / 15539 - CLASS_LOSS : 0.2383
44 / 500 :: 4352 / 15539 - CLASS_LOSS : 0.11668
44 / 500 :: 4992 / 15539 - CLASS_LOSS : 0.15348
44 / 500 :: 5632 / 15539 - CLASS_LOSS : 0.22687
44 / 500 :: 6272 / 15539 - CLASS_LOSS : 0.08969
44 / 500 :: 6912 / 15539 - CLASS_LOSS : 0.21776
44 / 500 :: 7552 / 15539 - CLASS_LOSS : 0.15867
44 / 500 :: 8192 / 15539 - CLASS_LOSS : 0.18238
44 / 500 :: 8832 / 15539 - CLASS_LOSS : 0.22058
44 / 500 :: 9472 / 15539 - CLASS_LOSS : 0.18161
44 / 500 :: 10112 / 15539 - CLASS_LOSS : 0.29812
44 / 500 :: 10752 / 15539 - CLASS_LOSS : 0.18786
44 / 500 :: 11392 / 15539 - CLASS_LOSS : 0.22675
44 / 500 :: 12032 / 15539 - CLASS_LOSS : 0.15956
44 / 500 :: 12672 / 15539 - CLASS_LOSS : 0.194
44 / 500 :: 13312 / 15539 - CLASS_LOSS : 0.20536
44 / 500 :: 13952 / 15539 - CLASS_LOSS : 0.20256
44 / 500 :: 14592 / 15539 - CLASS_LOSS : 0.14868
44 / 500 :: 15232 / 15539 - CLASS_LOSS : 0.23032
45 / 500 :: 320 / 15539 - CLASS_LOSS : 0.12808
45 / 500 :: 960 / 15539 - CLASS_LOSS : 0.2892
45 / 500 :: 1600 / 15539 - CLASS_LOSS : 0.1021
45 / 500 :: 2240 / 15539 - CLASS_LOSS : 0.15226
45 / 500 :: 2880 / 15539 - CLASS_LOSS : 0.17421
45 / 500 :: 3520 / 15539 - CLASS_LOSS : 0.21795
45 / 500 :: 4160 / 15539 - CLASS_LOSS : 0.18328
45 / 500 :: 4800 / 15539 - CLASS_LOSS : 0.16817
45 / 500 :: 5440 / 15539 - CLASS_LOSS : 0.07402
45 / 500 :: 6080 / 15539 - CLASS_LOSS : 0.21846
45 / 500 :: 6720 / 15539 - CLASS_LOSS : 0.21969
45 / 500 :: 7360 / 15539 - CLASS_LOSS : 0.35738
45 / 500 :: 8000 / 15539 - CLASS_LOSS : 0.1342
45 / 500 :: 8640 / 15539 - CLASS_LOSS : 0.15549
45 / 500 :: 9280 / 15539 - CLASS_LOSS : 0.21167
45 / 500 :: 9920 / 15539 - CLASS_LOSS : 0.25604
45 / 500 :: 10560 / 15539 - CLASS_LOSS : 0.18568
45 / 500 :: 11200 / 15539 - CLASS_LOSS : 0.11047
45 / 500 :: 11840 / 15539 - CLASS_LOSS : 0.18716
45 / 500 :: 12480 / 15539 - CLASS_LOSS : 0.16405
45 / 500 :: 13120 / 15539 - CLASS_LOSS : 0.12704
45 / 500 :: 13760 / 15539 - CLASS_LOSS : 0.21204
45 / 500 :: 14400 / 15539 - CLASS_LOSS : 0.1706
45 / 500 :: 15040 / 15539 - CLASS_LOSS : 0.12023
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.36894266040285734 0.30548941373318744 0.26416114293069054
PSPrecision@1,3,5: 0.2574153656350924 0.2763979599819627 0.2943896269018261
testing....
Precision@1,3,5: 0.33735888684694143 0.27154983810273914 0.23297453399842477
PSPrecision@1,3,5: 0.20001895886223123 0.21665993616275941 0.23359898977576948
46 / 500 :: 128 / 15539 - CLASS_LOSS : 0.11353
46 / 500 :: 768 / 15539 - CLASS_LOSS : 0.17076
46 / 500 :: 1408 / 15539 - CLASS_LOSS : 0.18973
46 / 500 :: 2048 / 15539 - CLASS_LOSS : 0.22651
46 / 500 :: 2688 / 15539 - CLASS_LOSS : 0.13669
46 / 500 :: 3328 / 15539 - CLASS_LOSS : 0.2235
46 / 500 :: 3968 / 15539 - CLASS_LOSS : 0.14243
46 / 500 :: 4608 / 15539 - CLASS_LOSS : 0.21006
46 / 500 :: 5248 / 15539 - CLASS_LOSS : 0.19608
46 / 500 :: 5888 / 15539 - CLASS_LOSS : 0.1217
46 / 500 :: 6528 / 15539 - CLASS_LOSS : 0.19486
46 / 500 :: 7168 / 15539 - CLASS_LOSS : 0.16724
46 / 500 :: 7808 / 15539 - CLASS_LOSS : 0.19729
46 / 500 :: 8448 / 15539 - CLASS_LOSS : 0.2183
46 / 500 :: 9088 / 15539 - CLASS_LOSS : 0.17803
46 / 500 :: 9728 / 15539 - CLASS_LOSS : 0.19572
46 / 500 :: 10368 / 15539 - CLASS_LOSS : 0.13852
46 / 500 :: 11008 / 15539 - CLASS_LOSS : 0.28548
46 / 500 :: 11648 / 15539 - CLASS_LOSS : 0.20335
46 / 500 :: 12288 / 15539 - CLASS_LOSS : 0.21084
46 / 500 :: 12928 / 15539 - CLASS_LOSS : 0.18271
46 / 500 :: 13568 / 15539 - CLASS_LOSS : 0.16786
46 / 500 :: 14208 / 15539 - CLASS_LOSS : 0.21238
46 / 500 :: 14848 / 15539 - CLASS_LOSS : 0.28289
46 / 500 :: 15488 / 15539 - CLASS_LOSS : 0.12118
47 / 500 :: 576 / 15539 - CLASS_LOSS : 0.17817
47 / 500 :: 1216 / 15539 - CLASS_LOSS : 0.18034
47 / 500 :: 1856 / 15539 - CLASS_LOSS : 0.19093
47 / 500 :: 2496 / 15539 - CLASS_LOSS : 0.20521
47 / 500 :: 3136 / 15539 - CLASS_LOSS : 0.20704
47 / 500 :: 3776 / 15539 - CLASS_LOSS : 0.24133
47 / 500 :: 4416 / 15539 - CLASS_LOSS : 0.16042
47 / 500 :: 5056 / 15539 - CLASS_LOSS : 0.28723
47 / 500 :: 5696 / 15539 - CLASS_LOSS : 0.17321
47 / 500 :: 6336 / 15539 - CLASS_LOSS : 0.23399
47 / 500 :: 6976 / 15539 - CLASS_LOSS : 0.15316
47 / 500 :: 7616 / 15539 - CLASS_LOSS : 0.15984
47 / 500 :: 8256 / 15539 - CLASS_LOSS : 0.15168
47 / 500 :: 8896 / 15539 - CLASS_LOSS : 0.16762
47 / 500 :: 9536 / 15539 - CLASS_LOSS : 0.26198
47 / 500 :: 10176 / 15539 - CLASS_LOSS : 0.16914
47 / 500 :: 10816 / 15539 - CLASS_LOSS : 0.1669
47 / 500 :: 11456 / 15539 - CLASS_LOSS : 0.09584
47 / 500 :: 12096 / 15539 - CLASS_LOSS : 0.10655
47 / 500 :: 12736 / 15539 - CLASS_LOSS : 0.13643
47 / 500 :: 13376 / 15539 - CLASS_LOSS : 0.21568
47 / 500 :: 14016 / 15539 - CLASS_LOSS : 0.11172
47 / 500 :: 14656 / 15539 - CLASS_LOSS : 0.27121
47 / 500 :: 15296 / 15539 - CLASS_LOSS : 0.20912
48 / 500 :: 384 / 15539 - CLASS_LOSS : 0.20307
48 / 500 :: 1024 / 15539 - CLASS_LOSS : 0.21706
48 / 500 :: 1664 / 15539 - CLASS_LOSS : 0.26992
48 / 500 :: 2304 / 15539 - CLASS_LOSS : 0.14335
48 / 500 :: 2944 / 15539 - CLASS_LOSS : 0.22679
48 / 500 :: 3584 / 15539 - CLASS_LOSS : 0.26573
48 / 500 :: 4224 / 15539 - CLASS_LOSS : 0.16256
48 / 500 :: 4864 / 15539 - CLASS_LOSS : 0.18149
48 / 500 :: 5504 / 15539 - CLASS_LOSS : 0.14281
48 / 500 :: 6144 / 15539 - CLASS_LOSS : 0.21429
48 / 500 :: 6784 / 15539 - CLASS_LOSS : 0.12796
48 / 500 :: 7424 / 15539 - CLASS_LOSS : 0.1293
48 / 500 :: 8064 / 15539 - CLASS_LOSS : 0.15213
48 / 500 :: 8704 / 15539 - CLASS_LOSS : 0.27218
48 / 500 :: 9344 / 15539 - CLASS_LOSS : 0.15191
48 / 500 :: 9984 / 15539 - CLASS_LOSS : 0.12304
48 / 500 :: 10624 / 15539 - CLASS_LOSS : 0.18183
48 / 500 :: 11264 / 15539 - CLASS_LOSS : 0.23325
48 / 500 :: 11904 / 15539 - CLASS_LOSS : 0.15382
48 / 500 :: 12544 / 15539 - CLASS_LOSS : 0.14047
48 / 500 :: 13184 / 15539 - CLASS_LOSS : 0.20898
48 / 500 :: 13824 / 15539 - CLASS_LOSS : 0.14418
48 / 500 :: 14464 / 15539 - CLASS_LOSS : 0.16001
48 / 500 :: 15104 / 15539 - CLASS_LOSS : 0.18363
49 / 500 :: 192 / 15539 - CLASS_LOSS : 0.1703
49 / 500 :: 832 / 15539 - CLASS_LOSS : 0.26924
49 / 500 :: 1472 / 15539 - CLASS_LOSS : 0.14509
49 / 500 :: 2112 / 15539 - CLASS_LOSS : 0.14121
49 / 500 :: 2752 / 15539 - CLASS_LOSS : 0.14704
49 / 500 :: 3392 / 15539 - CLASS_LOSS : 0.16046
49 / 500 :: 4032 / 15539 - CLASS_LOSS : 0.16463
49 / 500 :: 4672 / 15539 - CLASS_LOSS : 0.15824
49 / 500 :: 5312 / 15539 - CLASS_LOSS : 0.21819
49 / 500 :: 5952 / 15539 - CLASS_LOSS : 0.23939
49 / 500 :: 6592 / 15539 - CLASS_LOSS : 0.28321
49 / 500 :: 7232 / 15539 - CLASS_LOSS : 0.13877
49 / 500 :: 7872 / 15539 - CLASS_LOSS : 0.13689
49 / 500 :: 8512 / 15539 - CLASS_LOSS : 0.25748
49 / 500 :: 9152 / 15539 - CLASS_LOSS : 0.15588
49 / 500 :: 9792 / 15539 - CLASS_LOSS : 0.08579
49 / 500 :: 10432 / 15539 - CLASS_LOSS : 0.25939
49 / 500 :: 11072 / 15539 - CLASS_LOSS : 0.34343
49 / 500 :: 11712 / 15539 - CLASS_LOSS : 0.241
49 / 500 :: 12352 / 15539 - CLASS_LOSS : 0.26275
49 / 500 :: 12992 / 15539 - CLASS_LOSS : 0.06952
49 / 500 :: 13632 / 15539 - CLASS_LOSS : 0.26619
49 / 500 :: 14272 / 15539 - CLASS_LOSS : 0.21134
49 / 500 :: 14912 / 15539 - CLASS_LOSS : 0.22605
49 / 500 :: 15539 / 15539 - CLASS_LOSS : 0.32359
50 / 500 :: 640 / 15539 - CLASS_LOSS : 0.17516
50 / 500 :: 1280 / 15539 - CLASS_LOSS : 0.27359
50 / 500 :: 1920 / 15539 - CLASS_LOSS : 0.21596
50 / 500 :: 2560 / 15539 - CLASS_LOSS : 0.15294
50 / 500 :: 3200 / 15539 - CLASS_LOSS : 0.17696
50 / 500 :: 3840 / 15539 - CLASS_LOSS : 0.14462
50 / 500 :: 4480 / 15539 - CLASS_LOSS : 0.18512
50 / 500 :: 5120 / 15539 - CLASS_LOSS : 0.17074
50 / 500 :: 5760 / 15539 - CLASS_LOSS : 0.20926
50 / 500 :: 6400 / 15539 - CLASS_LOSS : 0.16124
50 / 500 :: 7040 / 15539 - CLASS_LOSS : 0.08398
50 / 500 :: 7680 / 15539 - CLASS_LOSS : 0.19387
50 / 500 :: 8320 / 15539 - CLASS_LOSS : 0.17066
50 / 500 :: 8960 / 15539 - CLASS_LOSS : 0.21071
50 / 500 :: 9600 / 15539 - CLASS_LOSS : 0.17105
50 / 500 :: 10240 / 15539 - CLASS_LOSS : 0.15026
50 / 500 :: 10880 / 15539 - CLASS_LOSS : 0.16626
50 / 500 :: 11520 / 15539 - CLASS_LOSS : 0.212
50 / 500 :: 12160 / 15539 - CLASS_LOSS : 0.20689
50 / 500 :: 12800 / 15539 - CLASS_LOSS : 0.26832
50 / 500 :: 13440 / 15539 - CLASS_LOSS : 0.21258
50 / 500 :: 14080 / 15539 - CLASS_LOSS : 0.2304
50 / 500 :: 14720 / 15539 - CLASS_LOSS : 0.19002
50 / 500 :: 15360 / 15539 - CLASS_LOSS : 0.14207
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.3847094407619538 0.3202479782053757 0.27308063581955083
PSPrecision@1,3,5: 0.26880523129328576 0.29037838737968263 0.3066047659457751
testing....
Precision@1,3,5: 0.33998424783407716 0.2833639625448499 0.23995799422420583
PSPrecision@1,3,5: 0.20080457140499613 0.22620613984738566 0.24134413622905332
51 / 500 :: 448 / 15539 - CLASS_LOSS : 0.2449
51 / 500 :: 1088 / 15539 - CLASS_LOSS : 0.1184
51 / 500 :: 1728 / 15539 - CLASS_LOSS : 0.07518
51 / 500 :: 2368 / 15539 - CLASS_LOSS : 0.13789
51 / 500 :: 3008 / 15539 - CLASS_LOSS : 0.21805
51 / 500 :: 3648 / 15539 - CLASS_LOSS : 0.15174
51 / 500 :: 4288 / 15539 - CLASS_LOSS : 0.14447
51 / 500 :: 4928 / 15539 - CLASS_LOSS : 0.14735
51 / 500 :: 5568 / 15539 - CLASS_LOSS : 0.18096
51 / 500 :: 6208 / 15539 - CLASS_LOSS : 0.2342
51 / 500 :: 6848 / 15539 - CLASS_LOSS : 0.21732
51 / 500 :: 7488 / 15539 - CLASS_LOSS : 0.14772
51 / 500 :: 8128 / 15539 - CLASS_LOSS : 0.19038
51 / 500 :: 8768 / 15539 - CLASS_LOSS : 0.28996
51 / 500 :: 9408 / 15539 - CLASS_LOSS : 0.1384
51 / 500 :: 10048 / 15539 - CLASS_LOSS : 0.17957
51 / 500 :: 10688 / 15539 - CLASS_LOSS : 0.20914
51 / 500 :: 11328 / 15539 - CLASS_LOSS : 0.16998
51 / 500 :: 11968 / 15539 - CLASS_LOSS : 0.18129
51 / 500 :: 12608 / 15539 - CLASS_LOSS : 0.19679
51 / 500 :: 13248 / 15539 - CLASS_LOSS : 0.27587
51 / 500 :: 13888 / 15539 - CLASS_LOSS : 0.27083
51 / 500 :: 14528 / 15539 - CLASS_LOSS : 0.18837
51 / 500 :: 15168 / 15539 - CLASS_LOSS : 0.14229
52 / 500 :: 256 / 15539 - CLASS_LOSS : 0.22196
52 / 500 :: 896 / 15539 - CLASS_LOSS : 0.19027
52 / 500 :: 1536 / 15539 - CLASS_LOSS : 0.21542
52 / 500 :: 2176 / 15539 - CLASS_LOSS : 0.23159
52 / 500 :: 2816 / 15539 - CLASS_LOSS : 0.19768
52 / 500 :: 3456 / 15539 - CLASS_LOSS : 0.16822
52 / 500 :: 4096 / 15539 - CLASS_LOSS : 0.15463
52 / 500 :: 4736 / 15539 - CLASS_LOSS : 0.18285
52 / 500 :: 5376 / 15539 - CLASS_LOSS : 0.22397
52 / 500 :: 6016 / 15539 - CLASS_LOSS : 0.27343
52 / 500 :: 6656 / 15539 - CLASS_LOSS : 0.22499
52 / 500 :: 7296 / 15539 - CLASS_LOSS : 0.17696
52 / 500 :: 7936 / 15539 - CLASS_LOSS : 0.18035
52 / 500 :: 8576 / 15539 - CLASS_LOSS : 0.20667
52 / 500 :: 9216 / 15539 - CLASS_LOSS : 0.19907
52 / 500 :: 9856 / 15539 - CLASS_LOSS : 0.24144
52 / 500 :: 10496 / 15539 - CLASS_LOSS : 0.17201
52 / 500 :: 11136 / 15539 - CLASS_LOSS : 0.20994
52 / 500 :: 11776 / 15539 - CLASS_LOSS : 0.2694
52 / 500 :: 12416 / 15539 - CLASS_LOSS : 0.19895
52 / 500 :: 13056 / 15539 - CLASS_LOSS : 0.13798
52 / 500 :: 13696 / 15539 - CLASS_LOSS : 0.2306
52 / 500 :: 14336 / 15539 - CLASS_LOSS : 0.26924
52 / 500 :: 14976 / 15539 - CLASS_LOSS : 0.19569
53 / 500 :: 64 / 15539 - CLASS_LOSS : 0.2541
53 / 500 :: 704 / 15539 - CLASS_LOSS : 0.18117
53 / 500 :: 1344 / 15539 - CLASS_LOSS : 0.18925
53 / 500 :: 1984 / 15539 - CLASS_LOSS : 0.24567
53 / 500 :: 2624 / 15539 - CLASS_LOSS : 0.11885
53 / 500 :: 3264 / 15539 - CLASS_LOSS : 0.19992
53 / 500 :: 3904 / 15539 - CLASS_LOSS : 0.25525
53 / 500 :: 4544 / 15539 - CLASS_LOSS : 0.17692
53 / 500 :: 5184 / 15539 - CLASS_LOSS : 0.10435
53 / 500 :: 5824 / 15539 - CLASS_LOSS : 0.17687
53 / 500 :: 6464 / 15539 - CLASS_LOSS : 0.13263
53 / 500 :: 7104 / 15539 - CLASS_LOSS : 0.12892
53 / 500 :: 7744 / 15539 - CLASS_LOSS : 0.20746
53 / 500 :: 8384 / 15539 - CLASS_LOSS : 0.20589
53 / 500 :: 9024 / 15539 - CLASS_LOSS : 0.14677
53 / 500 :: 9664 / 15539 - CLASS_LOSS : 0.17497
53 / 500 :: 10304 / 15539 - CLASS_LOSS : 0.17271
53 / 500 :: 10944 / 15539 - CLASS_LOSS : 0.23373
53 / 500 :: 11584 / 15539 - CLASS_LOSS : 0.14176
53 / 500 :: 12224 / 15539 - CLASS_LOSS : 0.18097
53 / 500 :: 12864 / 15539 - CLASS_LOSS : 0.2749
53 / 500 :: 13504 / 15539 - CLASS_LOSS : 0.21623
53 / 500 :: 14144 / 15539 - CLASS_LOSS : 0.22804
53 / 500 :: 14784 / 15539 - CLASS_LOSS : 0.19814
53 / 500 :: 15424 / 15539 - CLASS_LOSS : 0.16888
54 / 500 :: 512 / 15539 - CLASS_LOSS : 0.18378
54 / 500 :: 1152 / 15539 - CLASS_LOSS : 0.18223
54 / 500 :: 1792 / 15539 - CLASS_LOSS : 0.15971
54 / 500 :: 2432 / 15539 - CLASS_LOSS : 0.17294
54 / 500 :: 3072 / 15539 - CLASS_LOSS : 0.18553
54 / 500 :: 3712 / 15539 - CLASS_LOSS : 0.25333
54 / 500 :: 4352 / 15539 - CLASS_LOSS : 0.17318
54 / 500 :: 4992 / 15539 - CLASS_LOSS : 0.25861
54 / 500 :: 5632 / 15539 - CLASS_LOSS : 0.21973
54 / 500 :: 6272 / 15539 - CLASS_LOSS : 0.26101
54 / 500 :: 6912 / 15539 - CLASS_LOSS : 0.29439
54 / 500 :: 7552 / 15539 - CLASS_LOSS : 0.17025
54 / 500 :: 8192 / 15539 - CLASS_LOSS : 0.09845
54 / 500 :: 8832 / 15539 - CLASS_LOSS : 0.19825
54 / 500 :: 9472 / 15539 - CLASS_LOSS : 0.23186
54 / 500 :: 10112 / 15539 - CLASS_LOSS : 0.22591
54 / 500 :: 10752 / 15539 - CLASS_LOSS : 0.14275
54 / 500 :: 11392 / 15539 - CLASS_LOSS : 0.12314
54 / 500 :: 12032 / 15539 - CLASS_LOSS : 0.21689
54 / 500 :: 12672 / 15539 - CLASS_LOSS : 0.18966
54 / 500 :: 13312 / 15539 - CLASS_LOSS : 0.14018
54 / 500 :: 13952 / 15539 - CLASS_LOSS : 0.11498
54 / 500 :: 14592 / 15539 - CLASS_LOSS : 0.28878
54 / 500 :: 15232 / 15539 - CLASS_LOSS : 0.15679
55 / 500 :: 320 / 15539 - CLASS_LOSS : 0.23513
55 / 500 :: 960 / 15539 - CLASS_LOSS : 0.3271
55 / 500 :: 1600 / 15539 - CLASS_LOSS : 0.25199
55 / 500 :: 2240 / 15539 - CLASS_LOSS : 0.22344
55 / 500 :: 2880 / 15539 - CLASS_LOSS : 0.2038
55 / 500 :: 3520 / 15539 - CLASS_LOSS : 0.13881
55 / 500 :: 4160 / 15539 - CLASS_LOSS : 0.17902
55 / 500 :: 4800 / 15539 - CLASS_LOSS : 0.25684
55 / 500 :: 5440 / 15539 - CLASS_LOSS : 0.23789
55 / 500 :: 6080 / 15539 - CLASS_LOSS : 0.19581
55 / 500 :: 6720 / 15539 - CLASS_LOSS : 0.13451
55 / 500 :: 7360 / 15539 - CLASS_LOSS : 0.15911
55 / 500 :: 8000 / 15539 - CLASS_LOSS : 0.31515
55 / 500 :: 8640 / 15539 - CLASS_LOSS : 0.2213
55 / 500 :: 9280 / 15539 - CLASS_LOSS : 0.21592
55 / 500 :: 9920 / 15539 - CLASS_LOSS : 0.10117
55 / 500 :: 10560 / 15539 - CLASS_LOSS : 0.26953
55 / 500 :: 11200 / 15539 - CLASS_LOSS : 0.21152
55 / 500 :: 11840 / 15539 - CLASS_LOSS : 0.14264
55 / 500 :: 12480 / 15539 - CLASS_LOSS : 0.1971
55 / 500 :: 13120 / 15539 - CLASS_LOSS : 0.26046
55 / 500 :: 13760 / 15539 - CLASS_LOSS : 0.16827
55 / 500 :: 14400 / 15539 - CLASS_LOSS : 0.27024
55 / 500 :: 15040 / 15539 - CLASS_LOSS : 0.26612
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.38561039963961646 0.3281206426839994 0.2795031855331746
PSPrecision@1,3,5: 0.2754544693292486 0.30032454850323065 0.3157039007530659
testing....
Precision@1,3,5: 0.33525859805723285 0.2821387940841866 0.24069309530060384
PSPrecision@1,3,5: 0.2030324061760516 0.22896306531419736 0.24456695783314894
56 / 500 :: 128 / 15539 - CLASS_LOSS : 0.1748
56 / 500 :: 768 / 15539 - CLASS_LOSS : 0.21176
56 / 500 :: 1408 / 15539 - CLASS_LOSS : 0.22145
56 / 500 :: 2048 / 15539 - CLASS_LOSS : 0.23446
56 / 500 :: 2688 / 15539 - CLASS_LOSS : 0.21596
56 / 500 :: 3328 / 15539 - CLASS_LOSS : 0.22345
56 / 500 :: 3968 / 15539 - CLASS_LOSS : 0.25357
56 / 500 :: 4608 / 15539 - CLASS_LOSS : 0.14817
56 / 500 :: 5248 / 15539 - CLASS_LOSS : 0.36572
56 / 500 :: 5888 / 15539 - CLASS_LOSS : 0.23016
56 / 500 :: 6528 / 15539 - CLASS_LOSS : 0.15383
56 / 500 :: 7168 / 15539 - CLASS_LOSS : 0.21988
56 / 500 :: 7808 / 15539 - CLASS_LOSS : 0.13143
56 / 500 :: 8448 / 15539 - CLASS_LOSS : 0.2567
56 / 500 :: 9088 / 15539 - CLASS_LOSS : 0.20817
56 / 500 :: 9728 / 15539 - CLASS_LOSS : 0.18044
56 / 500 :: 10368 / 15539 - CLASS_LOSS : 0.17812
56 / 500 :: 11008 / 15539 - CLASS_LOSS : 0.21145
56 / 500 :: 11648 / 15539 - CLASS_LOSS : 0.25675
56 / 500 :: 12288 / 15539 - CLASS_LOSS : 0.18024
56 / 500 :: 12928 / 15539 - CLASS_LOSS : 0.22779
56 / 500 :: 13568 / 15539 - CLASS_LOSS : 0.16897
56 / 500 :: 14208 / 15539 - CLASS_LOSS : 0.14561
56 / 500 :: 14848 / 15539 - CLASS_LOSS : 0.13371
56 / 500 :: 15488 / 15539 - CLASS_LOSS : 0.16816
57 / 500 :: 576 / 15539 - CLASS_LOSS : 0.12557
57 / 500 :: 1216 / 15539 - CLASS_LOSS : 0.18516
57 / 500 :: 1856 / 15539 - CLASS_LOSS : 0.13625
57 / 500 :: 2496 / 15539 - CLASS_LOSS : 0.20852
57 / 500 :: 3136 / 15539 - CLASS_LOSS : 0.16983
57 / 500 :: 3776 / 15539 - CLASS_LOSS : 0.1808
57 / 500 :: 4416 / 15539 - CLASS_LOSS : 0.24687
57 / 500 :: 5056 / 15539 - CLASS_LOSS : 0.18447
57 / 500 :: 5696 / 15539 - CLASS_LOSS : 0.13717
57 / 500 :: 6336 / 15539 - CLASS_LOSS : 0.10747
57 / 500 :: 6976 / 15539 - CLASS_LOSS : 0.24386
57 / 500 :: 7616 / 15539 - CLASS_LOSS : 0.14118
57 / 500 :: 8256 / 15539 - CLASS_LOSS : 0.23675
57 / 500 :: 8896 / 15539 - CLASS_LOSS : 0.14189
57 / 500 :: 9536 / 15539 - CLASS_LOSS : 0.21835
57 / 500 :: 10176 / 15539 - CLASS_LOSS : 0.17691
57 / 500 :: 10816 / 15539 - CLASS_LOSS : 0.16449
57 / 500 :: 11456 / 15539 - CLASS_LOSS : 0.23421
57 / 500 :: 12096 / 15539 - CLASS_LOSS : 0.19407
57 / 500 :: 12736 / 15539 - CLASS_LOSS : 0.21881
57 / 500 :: 13376 / 15539 - CLASS_LOSS : 0.21906
57 / 500 :: 14016 / 15539 - CLASS_LOSS : 0.14454
57 / 500 :: 14656 / 15539 - CLASS_LOSS : 0.15621
57 / 500 :: 15296 / 15539 - CLASS_LOSS : 0.10554
58 / 500 :: 384 / 15539 - CLASS_LOSS : 0.23767
58 / 500 :: 1024 / 15539 - CLASS_LOSS : 0.16599
58 / 500 :: 1664 / 15539 - CLASS_LOSS : 0.14382
58 / 500 :: 2304 / 15539 - CLASS_LOSS : 0.13572
58 / 500 :: 2944 / 15539 - CLASS_LOSS : 0.18003
58 / 500 :: 3584 / 15539 - CLASS_LOSS : 0.13954
58 / 500 :: 4224 / 15539 - CLASS_LOSS : 0.18796
58 / 500 :: 4864 / 15539 - CLASS_LOSS : 0.16166
58 / 500 :: 5504 / 15539 - CLASS_LOSS : 0.29132
58 / 500 :: 6144 / 15539 - CLASS_LOSS : 0.13855
58 / 500 :: 6784 / 15539 - CLASS_LOSS : 0.22035
58 / 500 :: 7424 / 15539 - CLASS_LOSS : 0.23876
58 / 500 :: 8064 / 15539 - CLASS_LOSS : 0.1909
58 / 500 :: 8704 / 15539 - CLASS_LOSS : 0.18229
58 / 500 :: 9344 / 15539 - CLASS_LOSS : 0.14929
58 / 500 :: 9984 / 15539 - CLASS_LOSS : 0.12137
58 / 500 :: 10624 / 15539 - CLASS_LOSS : 0.14461
58 / 500 :: 11264 / 15539 - CLASS_LOSS : 0.16449
58 / 500 :: 11904 / 15539 - CLASS_LOSS : 0.24431
58 / 500 :: 12544 / 15539 - CLASS_LOSS : 0.12022
58 / 500 :: 13184 / 15539 - CLASS_LOSS : 0.19159
58 / 500 :: 13824 / 15539 - CLASS_LOSS : 0.23615
58 / 500 :: 14464 / 15539 - CLASS_LOSS : 0.23235
58 / 500 :: 15104 / 15539 - CLASS_LOSS : 0.23185
59 / 500 :: 192 / 15539 - CLASS_LOSS : 0.28388
59 / 500 :: 832 / 15539 - CLASS_LOSS : 0.14902
59 / 500 :: 1472 / 15539 - CLASS_LOSS : 0.12747
59 / 500 :: 2112 / 15539 - CLASS_LOSS : 0.11456
59 / 500 :: 2752 / 15539 - CLASS_LOSS : 0.31747
59 / 500 :: 3392 / 15539 - CLASS_LOSS : 0.09081
59 / 500 :: 4032 / 15539 - CLASS_LOSS : 0.16044
59 / 500 :: 4672 / 15539 - CLASS_LOSS : 0.17526
59 / 500 :: 5312 / 15539 - CLASS_LOSS : 0.2346
59 / 500 :: 5952 / 15539 - CLASS_LOSS : 0.16786
59 / 500 :: 6592 / 15539 - CLASS_LOSS : 0.1472
59 / 500 :: 7232 / 15539 - CLASS_LOSS : 0.19784
59 / 500 :: 7872 / 15539 - CLASS_LOSS : 0.19714
59 / 500 :: 8512 / 15539 - CLASS_LOSS : 0.17741
59 / 500 :: 9152 / 15539 - CLASS_LOSS : 0.26577
59 / 500 :: 9792 / 15539 - CLASS_LOSS : 0.19442
59 / 500 :: 10432 / 15539 - CLASS_LOSS : 0.27143
59 / 500 :: 11072 / 15539 - CLASS_LOSS : 0.22818
59 / 500 :: 11712 / 15539 - CLASS_LOSS : 0.27678
59 / 500 :: 12352 / 15539 - CLASS_LOSS : 0.13838
59 / 500 :: 12992 / 15539 - CLASS_LOSS : 0.16495
59 / 500 :: 13632 / 15539 - CLASS_LOSS : 0.26492
59 / 500 :: 14272 / 15539 - CLASS_LOSS : 0.21495
59 / 500 :: 14912 / 15539 - CLASS_LOSS : 0.18167
59 / 500 :: 15539 / 15539 - CLASS_LOSS : 0.13798
60 / 500 :: 640 / 15539 - CLASS_LOSS : 0.21542
60 / 500 :: 1280 / 15539 - CLASS_LOSS : 0.16189
60 / 500 :: 1920 / 15539 - CLASS_LOSS : 0.17696
60 / 500 :: 2560 / 15539 - CLASS_LOSS : 0.19533
60 / 500 :: 3200 / 15539 - CLASS_LOSS : 0.17528
60 / 500 :: 3840 / 15539 - CLASS_LOSS : 0.18293
60 / 500 :: 4480 / 15539 - CLASS_LOSS : 0.28856
60 / 500 :: 5120 / 15539 - CLASS_LOSS : 0.27075
60 / 500 :: 5760 / 15539 - CLASS_LOSS : 0.20232
60 / 500 :: 6400 / 15539 - CLASS_LOSS : 0.16804
60 / 500 :: 7040 / 15539 - CLASS_LOSS : 0.18899
60 / 500 :: 7680 / 15539 - CLASS_LOSS : 0.22507
60 / 500 :: 8320 / 15539 - CLASS_LOSS : 0.11455
60 / 500 :: 8960 / 15539 - CLASS_LOSS : 0.26123
60 / 500 :: 9600 / 15539 - CLASS_LOSS : 0.20107
60 / 500 :: 10240 / 15539 - CLASS_LOSS : 0.16421
60 / 500 :: 10880 / 15539 - CLASS_LOSS : 0.17017
60 / 500 :: 11520 / 15539 - CLASS_LOSS : 0.15968
60 / 500 :: 12160 / 15539 - CLASS_LOSS : 0.17181
60 / 500 :: 12800 / 15539 - CLASS_LOSS : 0.34043
60 / 500 :: 13440 / 15539 - CLASS_LOSS : 0.13337
60 / 500 :: 14080 / 15539 - CLASS_LOSS : 0.17647
60 / 500 :: 14720 / 15539 - CLASS_LOSS : 0.20252
60 / 500 :: 15360 / 15539 - CLASS_LOSS : 0.17815
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.38271446038998647 0.3317030267928009 0.28529506403243454
PSPrecision@1,3,5: 0.2752331598052736 0.30654492884908047 0.32386691556398783
testing....
Precision@1,3,5: 0.3300078760829614 0.2877395641900761 0.2484641638225256
PSPrecision@1,3,5: 0.20171565563081678 0.234377996293827 0.2531939579979156
61 / 500 :: 448 / 15539 - CLASS_LOSS : 0.18616
61 / 500 :: 1088 / 15539 - CLASS_LOSS : 0.09163
61 / 500 :: 1728 / 15539 - CLASS_LOSS : 0.29563
61 / 500 :: 2368 / 15539 - CLASS_LOSS : 0.14938
61 / 500 :: 3008 / 15539 - CLASS_LOSS : 0.18229
61 / 500 :: 3648 / 15539 - CLASS_LOSS : 0.22654
61 / 500 :: 4288 / 15539 - CLASS_LOSS : 0.15651
61 / 500 :: 4928 / 15539 - CLASS_LOSS : 0.18592
61 / 500 :: 5568 / 15539 - CLASS_LOSS : 0.19817
61 / 500 :: 6208 / 15539 - CLASS_LOSS : 0.15306
61 / 500 :: 6848 / 15539 - CLASS_LOSS : 0.15449
61 / 500 :: 7488 / 15539 - CLASS_LOSS : 0.1891
61 / 500 :: 8128 / 15539 - CLASS_LOSS : 0.21017
61 / 500 :: 8768 / 15539 - CLASS_LOSS : 0.23387
61 / 500 :: 9408 / 15539 - CLASS_LOSS : 0.12399
61 / 500 :: 10048 / 15539 - CLASS_LOSS : 0.12561
61 / 500 :: 10688 / 15539 - CLASS_LOSS : 0.17899
61 / 500 :: 11328 / 15539 - CLASS_LOSS : 0.23532
61 / 500 :: 11968 / 15539 - CLASS_LOSS : 0.14528
61 / 500 :: 12608 / 15539 - CLASS_LOSS : 0.13577
61 / 500 :: 13248 / 15539 - CLASS_LOSS : 0.26843
61 / 500 :: 13888 / 15539 - CLASS_LOSS : 0.18636
61 / 500 :: 14528 / 15539 - CLASS_LOSS : 0.19496
61 / 500 :: 15168 / 15539 - CLASS_LOSS : 0.28215
62 / 500 :: 256 / 15539 - CLASS_LOSS : 0.40834
62 / 500 :: 896 / 15539 - CLASS_LOSS : 0.13418
62 / 500 :: 1536 / 15539 - CLASS_LOSS : 0.18101
62 / 500 :: 2176 / 15539 - CLASS_LOSS : 0.19443
62 / 500 :: 2816 / 15539 - CLASS_LOSS : 0.15085
62 / 500 :: 3456 / 15539 - CLASS_LOSS : 0.20583
62 / 500 :: 4096 / 15539 - CLASS_LOSS : 0.20312
62 / 500 :: 4736 / 15539 - CLASS_LOSS : 0.17917
62 / 500 :: 5376 / 15539 - CLASS_LOSS : 0.23685
62 / 500 :: 6016 / 15539 - CLASS_LOSS : 0.1802
62 / 500 :: 6656 / 15539 - CLASS_LOSS : 0.2004
62 / 500 :: 7296 / 15539 - CLASS_LOSS : 0.13179
62 / 500 :: 7936 / 15539 - CLASS_LOSS : 0.33968
62 / 500 :: 8576 / 15539 - CLASS_LOSS : 0.29235
62 / 500 :: 9216 / 15539 - CLASS_LOSS : 0.21758
62 / 500 :: 9856 / 15539 - CLASS_LOSS : 0.12292
62 / 500 :: 10496 / 15539 - CLASS_LOSS : 0.33341
62 / 500 :: 11136 / 15539 - CLASS_LOSS : 0.18784
62 / 500 :: 11776 / 15539 - CLASS_LOSS : 0.18913
62 / 500 :: 12416 / 15539 - CLASS_LOSS : 0.15839
62 / 500 :: 13056 / 15539 - CLASS_LOSS : 0.13181
62 / 500 :: 13696 / 15539 - CLASS_LOSS : 0.15303
62 / 500 :: 14336 / 15539 - CLASS_LOSS : 0.18643
62 / 500 :: 14976 / 15539 - CLASS_LOSS : 0.25726
63 / 500 :: 64 / 15539 - CLASS_LOSS : 0.23703
63 / 500 :: 704 / 15539 - CLASS_LOSS : 0.16287
63 / 500 :: 1344 / 15539 - CLASS_LOSS : 0.15251
63 / 500 :: 1984 / 15539 - CLASS_LOSS : 0.13516
63 / 500 :: 2624 / 15539 - CLASS_LOSS : 0.15305
63 / 500 :: 3264 / 15539 - CLASS_LOSS : 0.11553
63 / 500 :: 3904 / 15539 - CLASS_LOSS : 0.21231
63 / 500 :: 4544 / 15539 - CLASS_LOSS : 0.13863
63 / 500 :: 5184 / 15539 - CLASS_LOSS : 0.26991
63 / 500 :: 5824 / 15539 - CLASS_LOSS : 0.14995
63 / 500 :: 6464 / 15539 - CLASS_LOSS : 0.23865
63 / 500 :: 7104 / 15539 - CLASS_LOSS : 0.09146
63 / 500 :: 7744 / 15539 - CLASS_LOSS : 0.15371
63 / 500 :: 8384 / 15539 - CLASS_LOSS : 0.18938
63 / 500 :: 9024 / 15539 - CLASS_LOSS : 0.23438
63 / 500 :: 9664 / 15539 - CLASS_LOSS : 0.16875
63 / 500 :: 10304 / 15539 - CLASS_LOSS : 0.21103
63 / 500 :: 10944 / 15539 - CLASS_LOSS : 0.11215
63 / 500 :: 11584 / 15539 - CLASS_LOSS : 0.27898
63 / 500 :: 12224 / 15539 - CLASS_LOSS : 0.24661
63 / 500 :: 12864 / 15539 - CLASS_LOSS : 0.21757
63 / 500 :: 13504 / 15539 - CLASS_LOSS : 0.19055
63 / 500 :: 14144 / 15539 - CLASS_LOSS : 0.22643
63 / 500 :: 14784 / 15539 - CLASS_LOSS : 0.31863
63 / 500 :: 15424 / 15539 - CLASS_LOSS : 0.20986
64 / 500 :: 512 / 15539 - CLASS_LOSS : 0.18909
64 / 500 :: 1152 / 15539 - CLASS_LOSS : 0.20785
64 / 500 :: 1792 / 15539 - CLASS_LOSS : 0.24187
64 / 500 :: 2432 / 15539 - CLASS_LOSS : 0.16689
64 / 500 :: 3072 / 15539 - CLASS_LOSS : 0.13972
64 / 500 :: 3712 / 15539 - CLASS_LOSS : 0.15957
64 / 500 :: 4352 / 15539 - CLASS_LOSS : 0.2014
64 / 500 :: 4992 / 15539 - CLASS_LOSS : 0.11284
64 / 500 :: 5632 / 15539 - CLASS_LOSS : 0.14945
64 / 500 :: 6272 / 15539 - CLASS_LOSS : 0.17701
64 / 500 :: 6912 / 15539 - CLASS_LOSS : 0.11899
64 / 500 :: 7552 / 15539 - CLASS_LOSS : 0.18132
64 / 500 :: 8192 / 15539 - CLASS_LOSS : 0.19511
64 / 500 :: 8832 / 15539 - CLASS_LOSS : 0.11525
64 / 500 :: 9472 / 15539 - CLASS_LOSS : 0.26649
64 / 500 :: 10112 / 15539 - CLASS_LOSS : 0.24226
64 / 500 :: 10752 / 15539 - CLASS_LOSS : 0.24592
64 / 500 :: 11392 / 15539 - CLASS_LOSS : 0.13595
64 / 500 :: 12032 / 15539 - CLASS_LOSS : 0.15445
64 / 500 :: 12672 / 15539 - CLASS_LOSS : 0.17316
64 / 500 :: 13312 / 15539 - CLASS_LOSS : 0.15878
64 / 500 :: 13952 / 15539 - CLASS_LOSS : 0.18173
64 / 500 :: 14592 / 15539 - CLASS_LOSS : 0.1146
64 / 500 :: 15232 / 15539 - CLASS_LOSS : 0.29546
65 / 500 :: 320 / 15539 - CLASS_LOSS : 0.25473
65 / 500 :: 960 / 15539 - CLASS_LOSS : 0.16112
65 / 500 :: 1600 / 15539 - CLASS_LOSS : 0.16778
65 / 500 :: 2240 / 15539 - CLASS_LOSS : 0.16456
65 / 500 :: 2880 / 15539 - CLASS_LOSS : 0.20165
65 / 500 :: 3520 / 15539 - CLASS_LOSS : 0.24752
65 / 500 :: 4160 / 15539 - CLASS_LOSS : 0.14448
65 / 500 :: 4800 / 15539 - CLASS_LOSS : 0.26105
65 / 500 :: 5440 / 15539 - CLASS_LOSS : 0.17728
65 / 500 :: 6080 / 15539 - CLASS_LOSS : 0.19748
65 / 500 :: 6720 / 15539 - CLASS_LOSS : 0.1681
65 / 500 :: 7360 / 15539 - CLASS_LOSS : 0.16618
65 / 500 :: 8000 / 15539 - CLASS_LOSS : 0.22119
65 / 500 :: 8640 / 15539 - CLASS_LOSS : 0.21996
65 / 500 :: 9280 / 15539 - CLASS_LOSS : 0.17475
65 / 500 :: 9920 / 15539 - CLASS_LOSS : 0.1926
65 / 500 :: 10560 / 15539 - CLASS_LOSS : 0.20592
65 / 500 :: 11200 / 15539 - CLASS_LOSS : 0.13844
65 / 500 :: 11840 / 15539 - CLASS_LOSS : 0.18018
65 / 500 :: 12480 / 15539 - CLASS_LOSS : 0.22398
65 / 500 :: 13120 / 15539 - CLASS_LOSS : 0.16062
65 / 500 :: 13760 / 15539 - CLASS_LOSS : 0.19618
65 / 500 :: 14400 / 15539 - CLASS_LOSS : 0.16892
65 / 500 :: 15040 / 15539 - CLASS_LOSS : 0.12826
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.41354012484715874 0.3482420576184654 0.29753523392753717
PSPrecision@1,3,5: 0.2948278472164908 0.3195125994041767 0.3364406090453888
testing....
Precision@1,3,5: 0.359149383040168 0.3000787608296141 0.25318981359936993
PSPrecision@1,3,5: 0.2182772783686307 0.24283606916594275 0.25753523613714135
66 / 500 :: 128 / 15539 - CLASS_LOSS : 0.13961
66 / 500 :: 768 / 15539 - CLASS_LOSS : 0.19618
66 / 500 :: 1408 / 15539 - CLASS_LOSS : 0.23238
66 / 500 :: 2048 / 15539 - CLASS_LOSS : 0.18311
66 / 500 :: 2688 / 15539 - CLASS_LOSS : 0.20577
66 / 500 :: 3328 / 15539 - CLASS_LOSS : 0.24003
66 / 500 :: 3968 / 15539 - CLASS_LOSS : 0.20323
66 / 500 :: 4608 / 15539 - CLASS_LOSS : 0.20433
66 / 500 :: 5248 / 15539 - CLASS_LOSS : 0.24922
66 / 500 :: 5888 / 15539 - CLASS_LOSS : 0.2459
66 / 500 :: 6528 / 15539 - CLASS_LOSS : 0.11275
66 / 500 :: 7168 / 15539 - CLASS_LOSS : 0.26463
66 / 500 :: 7808 / 15539 - CLASS_LOSS : 0.16782
66 / 500 :: 8448 / 15539 - CLASS_LOSS : 0.22692
66 / 500 :: 9088 / 15539 - CLASS_LOSS : 0.14117
66 / 500 :: 9728 / 15539 - CLASS_LOSS : 0.20935
66 / 500 :: 10368 / 15539 - CLASS_LOSS : 0.16748
66 / 500 :: 11008 / 15539 - CLASS_LOSS : 0.22631
66 / 500 :: 11648 / 15539 - CLASS_LOSS : 0.19063
66 / 500 :: 12288 / 15539 - CLASS_LOSS : 0.14464
66 / 500 :: 12928 / 15539 - CLASS_LOSS : 0.26317
66 / 500 :: 13568 / 15539 - CLASS_LOSS : 0.21164
66 / 500 :: 14208 / 15539 - CLASS_LOSS : 0.19815
66 / 500 :: 14848 / 15539 - CLASS_LOSS : 0.13172
66 / 500 :: 15488 / 15539 - CLASS_LOSS : 0.17916
67 / 500 :: 576 / 15539 - CLASS_LOSS : 0.18183
67 / 500 :: 1216 / 15539 - CLASS_LOSS : 0.16758
67 / 500 :: 1856 / 15539 - CLASS_LOSS : 0.21624
67 / 500 :: 2496 / 15539 - CLASS_LOSS : 0.16272
67 / 500 :: 3136 / 15539 - CLASS_LOSS : 0.14289
67 / 500 :: 3776 / 15539 - CLASS_LOSS : 0.17436
67 / 500 :: 4416 / 15539 - CLASS_LOSS : 0.3231
67 / 500 :: 5056 / 15539 - CLASS_LOSS : 0.20699
67 / 500 :: 5696 / 15539 - CLASS_LOSS : 0.17157
67 / 500 :: 6336 / 15539 - CLASS_LOSS : 0.1789
67 / 500 :: 6976 / 15539 - CLASS_LOSS : 0.18568
67 / 500 :: 7616 / 15539 - CLASS_LOSS : 0.24548
67 / 500 :: 8256 / 15539 - CLASS_LOSS : 0.12015
67 / 500 :: 8896 / 15539 - CLASS_LOSS : 0.08811
67 / 500 :: 9536 / 15539 - CLASS_LOSS : 0.23028
67 / 500 :: 10176 / 15539 - CLASS_LOSS : 0.1866
67 / 500 :: 10816 / 15539 - CLASS_LOSS : 0.18288
67 / 500 :: 11456 / 15539 - CLASS_LOSS : 0.17659
67 / 500 :: 12096 / 15539 - CLASS_LOSS : 0.22931
67 / 500 :: 12736 / 15539 - CLASS_LOSS : 0.17458
67 / 500 :: 13376 / 15539 - CLASS_LOSS : 0.16884
67 / 500 :: 14016 / 15539 - CLASS_LOSS : 0.12582
67 / 500 :: 14656 / 15539 - CLASS_LOSS : 0.14255
67 / 500 :: 15296 / 15539 - CLASS_LOSS : 0.14365
68 / 500 :: 384 / 15539 - CLASS_LOSS : 0.17258
68 / 500 :: 1024 / 15539 - CLASS_LOSS : 0.16505
68 / 500 :: 1664 / 15539 - CLASS_LOSS : 0.21049
68 / 500 :: 2304 / 15539 - CLASS_LOSS : 0.11707
68 / 500 :: 2944 / 15539 - CLASS_LOSS : 0.2726
68 / 500 :: 3584 / 15539 - CLASS_LOSS : 0.09247
68 / 500 :: 4224 / 15539 - CLASS_LOSS : 0.26808
68 / 500 :: 4864 / 15539 - CLASS_LOSS : 0.21471
68 / 500 :: 5504 / 15539 - CLASS_LOSS : 0.16653
68 / 500 :: 6144 / 15539 - CLASS_LOSS : 0.18792
68 / 500 :: 6784 / 15539 - CLASS_LOSS : 0.15516
68 / 500 :: 7424 / 15539 - CLASS_LOSS : 0.19806
68 / 500 :: 8064 / 15539 - CLASS_LOSS : 0.14638
68 / 500 :: 8704 / 15539 - CLASS_LOSS : 0.23114
68 / 500 :: 9344 / 15539 - CLASS_LOSS : 0.17775
68 / 500 :: 9984 / 15539 - CLASS_LOSS : 0.17319
68 / 500 :: 10624 / 15539 - CLASS_LOSS : 0.10832
68 / 500 :: 11264 / 15539 - CLASS_LOSS : 0.22371
68 / 500 :: 11904 / 15539 - CLASS_LOSS : 0.20407
68 / 500 :: 12544 / 15539 - CLASS_LOSS : 0.2675
68 / 500 :: 13184 / 15539 - CLASS_LOSS : 0.10467
68 / 500 :: 13824 / 15539 - CLASS_LOSS : 0.24707
68 / 500 :: 14464 / 15539 - CLASS_LOSS : 0.17787
68 / 500 :: 15104 / 15539 - CLASS_LOSS : 0.18477
69 / 500 :: 192 / 15539 - CLASS_LOSS : 0.17234
69 / 500 :: 832 / 15539 - CLASS_LOSS : 0.16727
69 / 500 :: 1472 / 15539 - CLASS_LOSS : 0.16348
69 / 500 :: 2112 / 15539 - CLASS_LOSS : 0.12004
69 / 500 :: 2752 / 15539 - CLASS_LOSS : 0.14991
69 / 500 :: 3392 / 15539 - CLASS_LOSS : 0.09219
69 / 500 :: 4032 / 15539 - CLASS_LOSS : 0.2499
69 / 500 :: 4672 / 15539 - CLASS_LOSS : 0.13312
69 / 500 :: 5312 / 15539 - CLASS_LOSS : 0.22111
69 / 500 :: 5952 / 15539 - CLASS_LOSS : 0.1814
69 / 500 :: 6592 / 15539 - CLASS_LOSS : 0.14379
69 / 500 :: 7232 / 15539 - CLASS_LOSS : 0.20547
69 / 500 :: 7872 / 15539 - CLASS_LOSS : 0.13972
69 / 500 :: 8512 / 15539 - CLASS_LOSS : 0.12977
69 / 500 :: 9152 / 15539 - CLASS_LOSS : 0.12478
69 / 500 :: 9792 / 15539 - CLASS_LOSS : 0.22449
69 / 500 :: 10432 / 15539 - CLASS_LOSS : 0.14312
69 / 500 :: 11072 / 15539 - CLASS_LOSS : 0.14933
69 / 500 :: 11712 / 15539 - CLASS_LOSS : 0.25282
69 / 500 :: 12352 / 15539 - CLASS_LOSS : 0.17305
69 / 500 :: 12992 / 15539 - CLASS_LOSS : 0.19263
69 / 500 :: 13632 / 15539 - CLASS_LOSS : 0.12058
69 / 500 :: 14272 / 15539 - CLASS_LOSS : 0.21007
69 / 500 :: 14912 / 15539 - CLASS_LOSS : 0.22555
69 / 500 :: 15539 / 15539 - CLASS_LOSS : 0.29147
70 / 500 :: 640 / 15539 - CLASS_LOSS : 0.22115
70 / 500 :: 1280 / 15539 - CLASS_LOSS : 0.19396
70 / 500 :: 1920 / 15539 - CLASS_LOSS : 0.20453
70 / 500 :: 2560 / 15539 - CLASS_LOSS : 0.10501
70 / 500 :: 3200 / 15539 - CLASS_LOSS : 0.17245
70 / 500 :: 3840 / 15539 - CLASS_LOSS : 0.08312
70 / 500 :: 4480 / 15539 - CLASS_LOSS : 0.24336
70 / 500 :: 5120 / 15539 - CLASS_LOSS : 0.30609
70 / 500 :: 5760 / 15539 - CLASS_LOSS : 0.17368
70 / 500 :: 6400 / 15539 - CLASS_LOSS : 0.16325
70 / 500 :: 7040 / 15539 - CLASS_LOSS : 0.14609
70 / 500 :: 7680 / 15539 - CLASS_LOSS : 0.18572
70 / 500 :: 8320 / 15539 - CLASS_LOSS : 0.13025
70 / 500 :: 8960 / 15539 - CLASS_LOSS : 0.12499
70 / 500 :: 9600 / 15539 - CLASS_LOSS : 0.14995
70 / 500 :: 10240 / 15539 - CLASS_LOSS : 0.10263
70 / 500 :: 10880 / 15539 - CLASS_LOSS : 0.11801
70 / 500 :: 11520 / 15539 - CLASS_LOSS : 0.14219
70 / 500 :: 12160 / 15539 - CLASS_LOSS : 0.15592
70 / 500 :: 12800 / 15539 - CLASS_LOSS : 0.25056
70 / 500 :: 13440 / 15539 - CLASS_LOSS : 0.16367
70 / 500 :: 14080 / 15539 - CLASS_LOSS : 0.22915
70 / 500 :: 14720 / 15539 - CLASS_LOSS : 0.12373
70 / 500 :: 15360 / 15539 - CLASS_LOSS : 0.22157
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.4171439603578094 0.3537550678936868 0.30331424158568765
PSPrecision@1,3,5: 0.30411565606189866 0.3306635605247996 0.3460883201778599
testing....
Precision@1,3,5: 0.3630874245208716 0.3073422595606896 0.2592806510895248
PSPrecision@1,3,5: 0.22325945653547088 0.2501010812727942 0.26235084130050357
71 / 500 :: 448 / 15539 - CLASS_LOSS : 0.22455
71 / 500 :: 1088 / 15539 - CLASS_LOSS : 0.39399
71 / 500 :: 1728 / 15539 - CLASS_LOSS : 0.33439
71 / 500 :: 2368 / 15539 - CLASS_LOSS : 0.19092
71 / 500 :: 3008 / 15539 - CLASS_LOSS : 0.19974
71 / 500 :: 3648 / 15539 - CLASS_LOSS : 0.17211
71 / 500 :: 4288 / 15539 - CLASS_LOSS : 0.12957
71 / 500 :: 4928 / 15539 - CLASS_LOSS : 0.20698
71 / 500 :: 5568 / 15539 - CLASS_LOSS : 0.13368
71 / 500 :: 6208 / 15539 - CLASS_LOSS : 0.16697
71 / 500 :: 6848 / 15539 - CLASS_LOSS : 0.24348
71 / 500 :: 7488 / 15539 - CLASS_LOSS : 0.17808
71 / 500 :: 8128 / 15539 - CLASS_LOSS : 0.15352
71 / 500 :: 8768 / 15539 - CLASS_LOSS : 0.14769
71 / 500 :: 9408 / 15539 - CLASS_LOSS : 0.20613
71 / 500 :: 10048 / 15539 - CLASS_LOSS : 0.16673
71 / 500 :: 10688 / 15539 - CLASS_LOSS : 0.18255
71 / 500 :: 11328 / 15539 - CLASS_LOSS : 0.20795
71 / 500 :: 11968 / 15539 - CLASS_LOSS : 0.22073
71 / 500 :: 12608 / 15539 - CLASS_LOSS : 0.20999
71 / 500 :: 13248 / 15539 - CLASS_LOSS : 0.19983
71 / 500 :: 13888 / 15539 - CLASS_LOSS : 0.24499
71 / 500 :: 14528 / 15539 - CLASS_LOSS : 0.11773
71 / 500 :: 15168 / 15539 - CLASS_LOSS : 0.149
72 / 500 :: 256 / 15539 - CLASS_LOSS : 0.09825
72 / 500 :: 896 / 15539 - CLASS_LOSS : 0.15618
72 / 500 :: 1536 / 15539 - CLASS_LOSS : 0.17289
72 / 500 :: 2176 / 15539 - CLASS_LOSS : 0.14861
72 / 500 :: 2816 / 15539 - CLASS_LOSS : 0.19558
72 / 500 :: 3456 / 15539 - CLASS_LOSS : 0.19349
72 / 500 :: 4096 / 15539 - CLASS_LOSS : 0.12059
72 / 500 :: 4736 / 15539 - CLASS_LOSS : 0.19903
72 / 500 :: 5376 / 15539 - CLASS_LOSS : 0.23986
72 / 500 :: 6016 / 15539 - CLASS_LOSS : 0.12248
72 / 500 :: 6656 / 15539 - CLASS_LOSS : 0.16078
72 / 500 :: 7296 / 15539 - CLASS_LOSS : 0.23444
72 / 500 :: 7936 / 15539 - CLASS_LOSS : 0.24944
72 / 500 :: 8576 / 15539 - CLASS_LOSS : 0.2141
72 / 500 :: 9216 / 15539 - CLASS_LOSS : 0.13737
72 / 500 :: 9856 / 15539 - CLASS_LOSS : 0.20285
72 / 500 :: 10496 / 15539 - CLASS_LOSS : 0.12848
72 / 500 :: 11136 / 15539 - CLASS_LOSS : 0.12763
72 / 500 :: 11776 / 15539 - CLASS_LOSS : 0.14005
72 / 500 :: 12416 / 15539 - CLASS_LOSS : 0.2111
72 / 500 :: 13056 / 15539 - CLASS_LOSS : 0.17828
72 / 500 :: 13696 / 15539 - CLASS_LOSS : 0.21133
72 / 500 :: 14336 / 15539 - CLASS_LOSS : 0.18836
72 / 500 :: 14976 / 15539 - CLASS_LOSS : 0.20951
73 / 500 :: 64 / 15539 - CLASS_LOSS : 0.11969
73 / 500 :: 704 / 15539 - CLASS_LOSS : 0.29049
73 / 500 :: 1344 / 15539 - CLASS_LOSS : 0.22749
73 / 500 :: 1984 / 15539 - CLASS_LOSS : 0.22571
73 / 500 :: 2624 / 15539 - CLASS_LOSS : 0.17363
73 / 500 :: 3264 / 15539 - CLASS_LOSS : 0.18699
73 / 500 :: 3904 / 15539 - CLASS_LOSS : 0.17087
73 / 500 :: 4544 / 15539 - CLASS_LOSS : 0.16551
73 / 500 :: 5184 / 15539 - CLASS_LOSS : 0.23616
73 / 500 :: 5824 / 15539 - CLASS_LOSS : 0.17489
73 / 500 :: 6464 / 15539 - CLASS_LOSS : 0.14821
73 / 500 :: 7104 / 15539 - CLASS_LOSS : 0.22791
73 / 500 :: 7744 / 15539 - CLASS_LOSS : 0.21082
73 / 500 :: 8384 / 15539 - CLASS_LOSS : 0.30063
73 / 500 :: 9024 / 15539 - CLASS_LOSS : 0.14264
73 / 500 :: 9664 / 15539 - CLASS_LOSS : 0.10554
73 / 500 :: 10304 / 15539 - CLASS_LOSS : 0.21633
73 / 500 :: 10944 / 15539 - CLASS_LOSS : 0.19702
73 / 500 :: 11584 / 15539 - CLASS_LOSS : 0.20817
73 / 500 :: 12224 / 15539 - CLASS_LOSS : 0.23939
73 / 500 :: 12864 / 15539 - CLASS_LOSS : 0.17094
73 / 500 :: 13504 / 15539 - CLASS_LOSS : 0.1773
73 / 500 :: 14144 / 15539 - CLASS_LOSS : 0.12293
73 / 500 :: 14784 / 15539 - CLASS_LOSS : 0.24769
73 / 500 :: 15424 / 15539 - CLASS_LOSS : 0.11169
74 / 500 :: 512 / 15539 - CLASS_LOSS : 0.08136
74 / 500 :: 1152 / 15539 - CLASS_LOSS : 0.16714
74 / 500 :: 1792 / 15539 - CLASS_LOSS : 0.25937
74 / 500 :: 2432 / 15539 - CLASS_LOSS : 0.19018
74 / 500 :: 3072 / 15539 - CLASS_LOSS : 0.22249
74 / 500 :: 3712 / 15539 - CLASS_LOSS : 0.17068
74 / 500 :: 4352 / 15539 - CLASS_LOSS : 0.21977
74 / 500 :: 4992 / 15539 - CLASS_LOSS : 0.19403
74 / 500 :: 5632 / 15539 - CLASS_LOSS : 0.13148
74 / 500 :: 6272 / 15539 - CLASS_LOSS : 0.19861
74 / 500 :: 6912 / 15539 - CLASS_LOSS : 0.19186
74 / 500 :: 7552 / 15539 - CLASS_LOSS : 0.24474
74 / 500 :: 8192 / 15539 - CLASS_LOSS : 0.24499
74 / 500 :: 8832 / 15539 - CLASS_LOSS : 0.25368
74 / 500 :: 9472 / 15539 - CLASS_LOSS : 0.18613
74 / 500 :: 10112 / 15539 - CLASS_LOSS : 0.19943
74 / 500 :: 10752 / 15539 - CLASS_LOSS : 0.13683
74 / 500 :: 11392 / 15539 - CLASS_LOSS : 0.16002
74 / 500 :: 12032 / 15539 - CLASS_LOSS : 0.15409
74 / 500 :: 12672 / 15539 - CLASS_LOSS : 0.08919
74 / 500 :: 13312 / 15539 - CLASS_LOSS : 0.17976
74 / 500 :: 13952 / 15539 - CLASS_LOSS : 0.16233
74 / 500 :: 14592 / 15539 - CLASS_LOSS : 0.14277
74 / 500 :: 15232 / 15539 - CLASS_LOSS : 0.19478
75 / 500 :: 320 / 15539 - CLASS_LOSS : 0.11446
75 / 500 :: 960 / 15539 - CLASS_LOSS : 0.18348
75 / 500 :: 1600 / 15539 - CLASS_LOSS : 0.10153
75 / 500 :: 2240 / 15539 - CLASS_LOSS : 0.30355
75 / 500 :: 2880 / 15539 - CLASS_LOSS : 0.22035
75 / 500 :: 3520 / 15539 - CLASS_LOSS : 0.12089
75 / 500 :: 4160 / 15539 - CLASS_LOSS : 0.21599
75 / 500 :: 4800 / 15539 - CLASS_LOSS : 0.16209
75 / 500 :: 5440 / 15539 - CLASS_LOSS : 0.16381
75 / 500 :: 6080 / 15539 - CLASS_LOSS : 0.18328
75 / 500 :: 6720 / 15539 - CLASS_LOSS : 0.17827
75 / 500 :: 7360 / 15539 - CLASS_LOSS : 0.1667
75 / 500 :: 8000 / 15539 - CLASS_LOSS : 0.15316
75 / 500 :: 8640 / 15539 - CLASS_LOSS : 0.21142
75 / 500 :: 9280 / 15539 - CLASS_LOSS : 0.24646
75 / 500 :: 9920 / 15539 - CLASS_LOSS : 0.20496
75 / 500 :: 10560 / 15539 - CLASS_LOSS : 0.15572
75 / 500 :: 11200 / 15539 - CLASS_LOSS : 0.31026
75 / 500 :: 11840 / 15539 - CLASS_LOSS : 0.16144
75 / 500 :: 12480 / 15539 - CLASS_LOSS : 0.20916
75 / 500 :: 13120 / 15539 - CLASS_LOSS : 0.15332
75 / 500 :: 13760 / 15539 - CLASS_LOSS : 0.16076
75 / 500 :: 14400 / 15539 - CLASS_LOSS : 0.12309
75 / 500 :: 15040 / 15539 - CLASS_LOSS : 0.18159
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.4406975995881331 0.36521011648111207 0.3104060750370037
PSPrecision@1,3,5: 0.3199476916525597 0.34113803676654286 0.3561293884535144
testing....
Precision@1,3,5: 0.37621422945655025 0.30821737988973485 0.26358624310842743
PSPrecision@1,3,5: 0.2308023338357945 0.25130975051146975 0.26731286972189316
76 / 500 :: 128 / 15539 - CLASS_LOSS : 0.24569
76 / 500 :: 768 / 15539 - CLASS_LOSS : 0.19819
76 / 500 :: 1408 / 15539 - CLASS_LOSS : 0.1001
76 / 500 :: 2048 / 15539 - CLASS_LOSS : 0.15926
76 / 500 :: 2688 / 15539 - CLASS_LOSS : 0.20692
76 / 500 :: 3328 / 15539 - CLASS_LOSS : 0.15697
76 / 500 :: 3968 / 15539 - CLASS_LOSS : 0.22993
76 / 500 :: 4608 / 15539 - CLASS_LOSS : 0.14785
76 / 500 :: 5248 / 15539 - CLASS_LOSS : 0.18858
76 / 500 :: 5888 / 15539 - CLASS_LOSS : 0.18904
76 / 500 :: 6528 / 15539 - CLASS_LOSS : 0.2244
76 / 500 :: 7168 / 15539 - CLASS_LOSS : 0.16337
76 / 500 :: 7808 / 15539 - CLASS_LOSS : 0.16155
76 / 500 :: 8448 / 15539 - CLASS_LOSS : 0.22873
76 / 500 :: 9088 / 15539 - CLASS_LOSS : 0.21885
76 / 500 :: 9728 / 15539 - CLASS_LOSS : 0.21644
76 / 500 :: 10368 / 15539 - CLASS_LOSS : 0.27236
76 / 500 :: 11008 / 15539 - CLASS_LOSS : 0.0984
76 / 500 :: 11648 / 15539 - CLASS_LOSS : 0.24356
76 / 500 :: 12288 / 15539 - CLASS_LOSS : 0.20809
76 / 500 :: 12928 / 15539 - CLASS_LOSS : 0.10967
76 / 500 :: 13568 / 15539 - CLASS_LOSS : 0.20955
76 / 500 :: 14208 / 15539 - CLASS_LOSS : 0.1955
76 / 500 :: 14848 / 15539 - CLASS_LOSS : 0.25566
76 / 500 :: 15488 / 15539 - CLASS_LOSS : 0.13107
77 / 500 :: 576 / 15539 - CLASS_LOSS : 0.26855
77 / 500 :: 1216 / 15539 - CLASS_LOSS : 0.24078
77 / 500 :: 1856 / 15539 - CLASS_LOSS : 0.17507
77 / 500 :: 2496 / 15539 - CLASS_LOSS : 0.14406
77 / 500 :: 3136 / 15539 - CLASS_LOSS : 0.12088
77 / 500 :: 3776 / 15539 - CLASS_LOSS : 0.19204
77 / 500 :: 4416 / 15539 - CLASS_LOSS : 0.24073
77 / 500 :: 5056 / 15539 - CLASS_LOSS : 0.15106
77 / 500 :: 5696 / 15539 - CLASS_LOSS : 0.17557
77 / 500 :: 6336 / 15539 - CLASS_LOSS : 0.15777
77 / 500 :: 6976 / 15539 - CLASS_LOSS : 0.15142
77 / 500 :: 7616 / 15539 - CLASS_LOSS : 0.16793
77 / 500 :: 8256 / 15539 - CLASS_LOSS : 0.18832
77 / 500 :: 8896 / 15539 - CLASS_LOSS : 0.13414
77 / 500 :: 9536 / 15539 - CLASS_LOSS : 0.16509
77 / 500 :: 10176 / 15539 - CLASS_LOSS : 0.13773
77 / 500 :: 10816 / 15539 - CLASS_LOSS : 0.22738
77 / 500 :: 11456 / 15539 - CLASS_LOSS : 0.18225
77 / 500 :: 12096 / 15539 - CLASS_LOSS : 0.21616
77 / 500 :: 12736 / 15539 - CLASS_LOSS : 0.1853
77 / 500 :: 13376 / 15539 - CLASS_LOSS : 0.19262
77 / 500 :: 14016 / 15539 - CLASS_LOSS : 0.25105
77 / 500 :: 14656 / 15539 - CLASS_LOSS : 0.16797
77 / 500 :: 15296 / 15539 - CLASS_LOSS : 0.22832
78 / 500 :: 384 / 15539 - CLASS_LOSS : 0.17022
78 / 500 :: 1024 / 15539 - CLASS_LOSS : 0.16847
78 / 500 :: 1664 / 15539 - CLASS_LOSS : 0.17897
78 / 500 :: 2304 / 15539 - CLASS_LOSS : 0.19803
78 / 500 :: 2944 / 15539 - CLASS_LOSS : 0.16481
78 / 500 :: 3584 / 15539 - CLASS_LOSS : 0.18723
78 / 500 :: 4224 / 15539 - CLASS_LOSS : 0.19096
78 / 500 :: 4864 / 15539 - CLASS_LOSS : 0.23843
78 / 500 :: 5504 / 15539 - CLASS_LOSS : 0.25124
78 / 500 :: 6144 / 15539 - CLASS_LOSS : 0.10733
78 / 500 :: 6784 / 15539 - CLASS_LOSS : 0.19259
78 / 500 :: 7424 / 15539 - CLASS_LOSS : 0.13971
78 / 500 :: 8064 / 15539 - CLASS_LOSS : 0.13627
78 / 500 :: 8704 / 15539 - CLASS_LOSS : 0.19086
78 / 500 :: 9344 / 15539 - CLASS_LOSS : 0.1967
78 / 500 :: 9984 / 15539 - CLASS_LOSS : 0.095
78 / 500 :: 10624 / 15539 - CLASS_LOSS : 0.14658
78 / 500 :: 11264 / 15539 - CLASS_LOSS : 0.18224
78 / 500 :: 11904 / 15539 - CLASS_LOSS : 0.16392
78 / 500 :: 12544 / 15539 - CLASS_LOSS : 0.1835
78 / 500 :: 13184 / 15539 - CLASS_LOSS : 0.18303
78 / 500 :: 13824 / 15539 - CLASS_LOSS : 0.28186
78 / 500 :: 14464 / 15539 - CLASS_LOSS : 0.11024
78 / 500 :: 15104 / 15539 - CLASS_LOSS : 0.24274
79 / 500 :: 192 / 15539 - CLASS_LOSS : 0.17538
79 / 500 :: 832 / 15539 - CLASS_LOSS : 0.16388
79 / 500 :: 1472 / 15539 - CLASS_LOSS : 0.14069
79 / 500 :: 2112 / 15539 - CLASS_LOSS : 0.16361
79 / 500 :: 2752 / 15539 - CLASS_LOSS : 0.17202
79 / 500 :: 3392 / 15539 - CLASS_LOSS : 0.28898
79 / 500 :: 4032 / 15539 - CLASS_LOSS : 0.20365
79 / 500 :: 4672 / 15539 - CLASS_LOSS : 0.20769
79 / 500 :: 5312 / 15539 - CLASS_LOSS : 0.19308
79 / 500 :: 5952 / 15539 - CLASS_LOSS : 0.11636
79 / 500 :: 6592 / 15539 - CLASS_LOSS : 0.12989
79 / 500 :: 7232 / 15539 - CLASS_LOSS : 0.15396
79 / 500 :: 7872 / 15539 - CLASS_LOSS : 0.15758
79 / 500 :: 8512 / 15539 - CLASS_LOSS : 0.22452
79 / 500 :: 9152 / 15539 - CLASS_LOSS : 0.20222
79 / 500 :: 9792 / 15539 - CLASS_LOSS : 0.22654
79 / 500 :: 10432 / 15539 - CLASS_LOSS : 0.21616
79 / 500 :: 11072 / 15539 - CLASS_LOSS : 0.22008
79 / 500 :: 11712 / 15539 - CLASS_LOSS : 0.20704
79 / 500 :: 12352 / 15539 - CLASS_LOSS : 0.1624
79 / 500 :: 12992 / 15539 - CLASS_LOSS : 0.10159
79 / 500 :: 13632 / 15539 - CLASS_LOSS : 0.17553
79 / 500 :: 14272 / 15539 - CLASS_LOSS : 0.09972
79 / 500 :: 14912 / 15539 - CLASS_LOSS : 0.18505
79 / 500 :: 15539 / 15539 - CLASS_LOSS : 0.29877
80 / 500 :: 640 / 15539 - CLASS_LOSS : 0.19633
80 / 500 :: 1280 / 15539 - CLASS_LOSS : 0.12795
80 / 500 :: 1920 / 15539 - CLASS_LOSS : 0.1467
80 / 500 :: 2560 / 15539 - CLASS_LOSS : 0.2319
80 / 500 :: 3200 / 15539 - CLASS_LOSS : 0.20415
80 / 500 :: 3840 / 15539 - CLASS_LOSS : 0.22246
80 / 500 :: 4480 / 15539 - CLASS_LOSS : 0.27813
80 / 500 :: 5120 / 15539 - CLASS_LOSS : 0.15573
80 / 500 :: 5760 / 15539 - CLASS_LOSS : 0.25484
80 / 500 :: 6400 / 15539 - CLASS_LOSS : 0.17131
80 / 500 :: 7040 / 15539 - CLASS_LOSS : 0.28593
80 / 500 :: 7680 / 15539 - CLASS_LOSS : 0.19008
80 / 500 :: 8320 / 15539 - CLASS_LOSS : 0.21536
80 / 500 :: 8960 / 15539 - CLASS_LOSS : 0.18318
80 / 500 :: 9600 / 15539 - CLASS_LOSS : 0.13209
80 / 500 :: 10240 / 15539 - CLASS_LOSS : 0.14308
80 / 500 :: 10880 / 15539 - CLASS_LOSS : 0.3023
80 / 500 :: 11520 / 15539 - CLASS_LOSS : 0.13452
80 / 500 :: 12160 / 15539 - CLASS_LOSS : 0.17344
80 / 500 :: 12800 / 15539 - CLASS_LOSS : 0.16144
80 / 500 :: 13440 / 15539 - CLASS_LOSS : 0.13369
80 / 500 :: 14080 / 15539 - CLASS_LOSS : 0.16784
80 / 500 :: 14720 / 15539 - CLASS_LOSS : 0.13268
80 / 500 :: 15360 / 15539 - CLASS_LOSS : 0.14705
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.4322028444558852 0.3641589977905056 0.31072784606474035
PSPrecision@1,3,5: 0.31455614183663344 0.3420068990960031 0.3586210887318591
testing....
Precision@1,3,5: 0.37831451824625884 0.3102301566465389 0.26232606983460227
PSPrecision@1,3,5: 0.22796484319834628 0.2529784851373277 0.26687517155679674
81 / 500 :: 448 / 15539 - CLASS_LOSS : 0.23926
81 / 500 :: 1088 / 15539 - CLASS_LOSS : 0.18847
81 / 500 :: 1728 / 15539 - CLASS_LOSS : 0.13685
81 / 500 :: 2368 / 15539 - CLASS_LOSS : 0.08947
81 / 500 :: 3008 / 15539 - CLASS_LOSS : 0.17204
81 / 500 :: 3648 / 15539 - CLASS_LOSS : 0.12366
81 / 500 :: 4288 / 15539 - CLASS_LOSS : 0.18771
81 / 500 :: 4928 / 15539 - CLASS_LOSS : 0.25966
81 / 500 :: 5568 / 15539 - CLASS_LOSS : 0.1045
81 / 500 :: 6208 / 15539 - CLASS_LOSS : 0.12969
81 / 500 :: 6848 / 15539 - CLASS_LOSS : 0.178
81 / 500 :: 7488 / 15539 - CLASS_LOSS : 0.15634
81 / 500 :: 8128 / 15539 - CLASS_LOSS : 0.1887
81 / 500 :: 8768 / 15539 - CLASS_LOSS : 0.1885
81 / 500 :: 9408 / 15539 - CLASS_LOSS : 0.2613
81 / 500 :: 10048 / 15539 - CLASS_LOSS : 0.16591
81 / 500 :: 10688 / 15539 - CLASS_LOSS : 0.16119
81 / 500 :: 11328 / 15539 - CLASS_LOSS : 0.18341
81 / 500 :: 11968 / 15539 - CLASS_LOSS : 0.18656
81 / 500 :: 12608 / 15539 - CLASS_LOSS : 0.22003
81 / 500 :: 13248 / 15539 - CLASS_LOSS : 0.10839
81 / 500 :: 13888 / 15539 - CLASS_LOSS : 0.15598
81 / 500 :: 14528 / 15539 - CLASS_LOSS : 0.16292
81 / 500 :: 15168 / 15539 - CLASS_LOSS : 0.13167
82 / 500 :: 256 / 15539 - CLASS_LOSS : 0.21554
82 / 500 :: 896 / 15539 - CLASS_LOSS : 0.14962
82 / 500 :: 1536 / 15539 - CLASS_LOSS : 0.25014
82 / 500 :: 2176 / 15539 - CLASS_LOSS : 0.15282
82 / 500 :: 2816 / 15539 - CLASS_LOSS : 0.20272
82 / 500 :: 3456 / 15539 - CLASS_LOSS : 0.17017
82 / 500 :: 4096 / 15539 - CLASS_LOSS : 0.14866
82 / 500 :: 4736 / 15539 - CLASS_LOSS : 0.22205
82 / 500 :: 5376 / 15539 - CLASS_LOSS : 0.22352
82 / 500 :: 6016 / 15539 - CLASS_LOSS : 0.17861
82 / 500 :: 6656 / 15539 - CLASS_LOSS : 0.30557
82 / 500 :: 7296 / 15539 - CLASS_LOSS : 0.20447
82 / 500 :: 7936 / 15539 - CLASS_LOSS : 0.21543
82 / 500 :: 8576 / 15539 - CLASS_LOSS : 0.0996
82 / 500 :: 9216 / 15539 - CLASS_LOSS : 0.27885
82 / 500 :: 9856 / 15539 - CLASS_LOSS : 0.19219
82 / 500 :: 10496 / 15539 - CLASS_LOSS : 0.17716
82 / 500 :: 11136 / 15539 - CLASS_LOSS : 0.23718
82 / 500 :: 11776 / 15539 - CLASS_LOSS : 0.22101
82 / 500 :: 12416 / 15539 - CLASS_LOSS : 0.23594
82 / 500 :: 13056 / 15539 - CLASS_LOSS : 0.20266
82 / 500 :: 13696 / 15539 - CLASS_LOSS : 0.29289
82 / 500 :: 14336 / 15539 - CLASS_LOSS : 0.14397
82 / 500 :: 14976 / 15539 - CLASS_LOSS : 0.22088
83 / 500 :: 64 / 15539 - CLASS_LOSS : 0.17314
83 / 500 :: 704 / 15539 - CLASS_LOSS : 0.17287
83 / 500 :: 1344 / 15539 - CLASS_LOSS : 0.17082
83 / 500 :: 1984 / 15539 - CLASS_LOSS : 0.16821
83 / 500 :: 2624 / 15539 - CLASS_LOSS : 0.18165
83 / 500 :: 3264 / 15539 - CLASS_LOSS : 0.16188
83 / 500 :: 3904 / 15539 - CLASS_LOSS : 0.19271
83 / 500 :: 4544 / 15539 - CLASS_LOSS : 0.10079
83 / 500 :: 5184 / 15539 - CLASS_LOSS : 0.19928
83 / 500 :: 5824 / 15539 - CLASS_LOSS : 0.26356
83 / 500 :: 6464 / 15539 - CLASS_LOSS : 0.15849
83 / 500 :: 7104 / 15539 - CLASS_LOSS : 0.11174
83 / 500 :: 7744 / 15539 - CLASS_LOSS : 0.13062
83 / 500 :: 8384 / 15539 - CLASS_LOSS : 0.22276
83 / 500 :: 9024 / 15539 - CLASS_LOSS : 0.25155
83 / 500 :: 9664 / 15539 - CLASS_LOSS : 0.30022
83 / 500 :: 10304 / 15539 - CLASS_LOSS : 0.1345
83 / 500 :: 10944 / 15539 - CLASS_LOSS : 0.16376
83 / 500 :: 11584 / 15539 - CLASS_LOSS : 0.2073
83 / 500 :: 12224 / 15539 - CLASS_LOSS : 0.11708
83 / 500 :: 12864 / 15539 - CLASS_LOSS : 0.1416
83 / 500 :: 13504 / 15539 - CLASS_LOSS : 0.25352
83 / 500 :: 14144 / 15539 - CLASS_LOSS : 0.20895
83 / 500 :: 14784 / 15539 - CLASS_LOSS : 0.26287
83 / 500 :: 15424 / 15539 - CLASS_LOSS : 0.14506
84 / 500 :: 512 / 15539 - CLASS_LOSS : 0.22907
84 / 500 :: 1152 / 15539 - CLASS_LOSS : 0.22186
84 / 500 :: 1792 / 15539 - CLASS_LOSS : 0.17336
84 / 500 :: 2432 / 15539 - CLASS_LOSS : 0.17902
84 / 500 :: 3072 / 15539 - CLASS_LOSS : 0.16348
84 / 500 :: 3712 / 15539 - CLASS_LOSS : 0.17165
84 / 500 :: 4352 / 15539 - CLASS_LOSS : 0.20301
84 / 500 :: 4992 / 15539 - CLASS_LOSS : 0.24399
84 / 500 :: 5632 / 15539 - CLASS_LOSS : 0.13454
84 / 500 :: 6272 / 15539 - CLASS_LOSS : 0.21184
84 / 500 :: 6912 / 15539 - CLASS_LOSS : 0.182
84 / 500 :: 7552 / 15539 - CLASS_LOSS : 0.17228
84 / 500 :: 8192 / 15539 - CLASS_LOSS : 0.1852
84 / 500 :: 8832 / 15539 - CLASS_LOSS : 0.17527
84 / 500 :: 9472 / 15539 - CLASS_LOSS : 0.12022
84 / 500 :: 10112 / 15539 - CLASS_LOSS : 0.19957
84 / 500 :: 10752 / 15539 - CLASS_LOSS : 0.18907
84 / 500 :: 11392 / 15539 - CLASS_LOSS : 0.23244
84 / 500 :: 12032 / 15539 - CLASS_LOSS : 0.17959
84 / 500 :: 12672 / 15539 - CLASS_LOSS : 0.12999
84 / 500 :: 13312 / 15539 - CLASS_LOSS : 0.11879
84 / 500 :: 13952 / 15539 - CLASS_LOSS : 0.12627
84 / 500 :: 14592 / 15539 - CLASS_LOSS : 0.18773
84 / 500 :: 15232 / 15539 - CLASS_LOSS : 0.16819
85 / 500 :: 320 / 15539 - CLASS_LOSS : 0.14776
85 / 500 :: 960 / 15539 - CLASS_LOSS : 0.12261
85 / 500 :: 1600 / 15539 - CLASS_LOSS : 0.16643
85 / 500 :: 2240 / 15539 - CLASS_LOSS : 0.13414
85 / 500 :: 2880 / 15539 - CLASS_LOSS : 0.09671
85 / 500 :: 3520 / 15539 - CLASS_LOSS : 0.16386
85 / 500 :: 4160 / 15539 - CLASS_LOSS : 0.17574
85 / 500 :: 4800 / 15539 - CLASS_LOSS : 0.18203
85 / 500 :: 5440 / 15539 - CLASS_LOSS : 0.28777
85 / 500 :: 6080 / 15539 - CLASS_LOSS : 0.18423
85 / 500 :: 6720 / 15539 - CLASS_LOSS : 0.18961
85 / 500 :: 7360 / 15539 - CLASS_LOSS : 0.24628
85 / 500 :: 8000 / 15539 - CLASS_LOSS : 0.18208
85 / 500 :: 8640 / 15539 - CLASS_LOSS : 0.13378
85 / 500 :: 9280 / 15539 - CLASS_LOSS : 0.19646
85 / 500 :: 9920 / 15539 - CLASS_LOSS : 0.14654
85 / 500 :: 10560 / 15539 - CLASS_LOSS : 0.21093
85 / 500 :: 11200 / 15539 - CLASS_LOSS : 0.2091
85 / 500 :: 11840 / 15539 - CLASS_LOSS : 0.11298
85 / 500 :: 12480 / 15539 - CLASS_LOSS : 0.11345
85 / 500 :: 13120 / 15539 - CLASS_LOSS : 0.31602
85 / 500 :: 13760 / 15539 - CLASS_LOSS : 0.29933
85 / 500 :: 14400 / 15539 - CLASS_LOSS : 0.14177
85 / 500 :: 15040 / 15539 - CLASS_LOSS : 0.17273
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.4556277752751142 0.37458437908917347 0.31941566381363024
PSPrecision@1,3,5: 0.32739692722765606 0.3500202267988042 0.3676041126452476
testing....
Precision@1,3,5: 0.3822525597269625 0.3104926927452525 0.26668416907324755
PSPrecision@1,3,5: 0.229415083246784 0.25444741521252007 0.27217782340049096
86 / 500 :: 128 / 15539 - CLASS_LOSS : 0.11945
86 / 500 :: 768 / 15539 - CLASS_LOSS : 0.18836
86 / 500 :: 1408 / 15539 - CLASS_LOSS : 0.14997
86 / 500 :: 2048 / 15539 - CLASS_LOSS : 0.13987
86 / 500 :: 2688 / 15539 - CLASS_LOSS : 0.17791
86 / 500 :: 3328 / 15539 - CLASS_LOSS : 0.11773
86 / 500 :: 3968 / 15539 - CLASS_LOSS : 0.11206
86 / 500 :: 4608 / 15539 - CLASS_LOSS : 0.23596
86 / 500 :: 5248 / 15539 - CLASS_LOSS : 0.18733
86 / 500 :: 5888 / 15539 - CLASS_LOSS : 0.164
86 / 500 :: 6528 / 15539 - CLASS_LOSS : 0.16406
86 / 500 :: 7168 / 15539 - CLASS_LOSS : 0.19927
86 / 500 :: 7808 / 15539 - CLASS_LOSS : 0.18524
86 / 500 :: 8448 / 15539 - CLASS_LOSS : 0.14112
86 / 500 :: 9088 / 15539 - CLASS_LOSS : 0.16419
86 / 500 :: 9728 / 15539 - CLASS_LOSS : 0.14658
86 / 500 :: 10368 / 15539 - CLASS_LOSS : 0.15553
86 / 500 :: 11008 / 15539 - CLASS_LOSS : 0.21627
86 / 500 :: 11648 / 15539 - CLASS_LOSS : 0.19402
86 / 500 :: 12288 / 15539 - CLASS_LOSS : 0.20527
86 / 500 :: 12928 / 15539 - CLASS_LOSS : 0.17134
86 / 500 :: 13568 / 15539 - CLASS_LOSS : 0.11019
86 / 500 :: 14208 / 15539 - CLASS_LOSS : 0.27733
86 / 500 :: 14848 / 15539 - CLASS_LOSS : 0.1991
86 / 500 :: 15488 / 15539 - CLASS_LOSS : 0.1085
87 / 500 :: 576 / 15539 - CLASS_LOSS : 0.12599
87 / 500 :: 1216 / 15539 - CLASS_LOSS : 0.14684
87 / 500 :: 1856 / 15539 - CLASS_LOSS : 0.19574
87 / 500 :: 2496 / 15539 - CLASS_LOSS : 0.16314
87 / 500 :: 3136 / 15539 - CLASS_LOSS : 0.12387
87 / 500 :: 3776 / 15539 - CLASS_LOSS : 0.19718
87 / 500 :: 4416 / 15539 - CLASS_LOSS : 0.18568
87 / 500 :: 5056 / 15539 - CLASS_LOSS : 0.11462
87 / 500 :: 5696 / 15539 - CLASS_LOSS : 0.12888
87 / 500 :: 6336 / 15539 - CLASS_LOSS : 0.16145
87 / 500 :: 6976 / 15539 - CLASS_LOSS : 0.24314
87 / 500 :: 7616 / 15539 - CLASS_LOSS : 0.10837
87 / 500 :: 8256 / 15539 - CLASS_LOSS : 0.21578
87 / 500 :: 8896 / 15539 - CLASS_LOSS : 0.14636
87 / 500 :: 9536 / 15539 - CLASS_LOSS : 0.12268
87 / 500 :: 10176 / 15539 - CLASS_LOSS : 0.21097
87 / 500 :: 10816 / 15539 - CLASS_LOSS : 0.23456
87 / 500 :: 11456 / 15539 - CLASS_LOSS : 0.15129
87 / 500 :: 12096 / 15539 - CLASS_LOSS : 0.33139
87 / 500 :: 12736 / 15539 - CLASS_LOSS : 0.27309
87 / 500 :: 13376 / 15539 - CLASS_LOSS : 0.13145
87 / 500 :: 14016 / 15539 - CLASS_LOSS : 0.27131
87 / 500 :: 14656 / 15539 - CLASS_LOSS : 0.15765
87 / 500 :: 15296 / 15539 - CLASS_LOSS : 0.23717
88 / 500 :: 384 / 15539 - CLASS_LOSS : 0.15581
88 / 500 :: 1024 / 15539 - CLASS_LOSS : 0.10913
88 / 500 :: 1664 / 15539 - CLASS_LOSS : 0.25961
88 / 500 :: 2304 / 15539 - CLASS_LOSS : 0.20077
88 / 500 :: 2944 / 15539 - CLASS_LOSS : 0.22739
88 / 500 :: 3584 / 15539 - CLASS_LOSS : 0.16764
88 / 500 :: 4224 / 15539 - CLASS_LOSS : 0.30515
88 / 500 :: 4864 / 15539 - CLASS_LOSS : 0.18964
88 / 500 :: 5504 / 15539 - CLASS_LOSS : 0.11013
88 / 500 :: 6144 / 15539 - CLASS_LOSS : 0.15286
88 / 500 :: 6784 / 15539 - CLASS_LOSS : 0.14166
88 / 500 :: 7424 / 15539 - CLASS_LOSS : 0.28287
88 / 500 :: 8064 / 15539 - CLASS_LOSS : 0.08805
88 / 500 :: 8704 / 15539 - CLASS_LOSS : 0.13966
88 / 500 :: 9344 / 15539 - CLASS_LOSS : 0.17155
88 / 500 :: 9984 / 15539 - CLASS_LOSS : 0.13176
88 / 500 :: 10624 / 15539 - CLASS_LOSS : 0.23417
88 / 500 :: 11264 / 15539 - CLASS_LOSS : 0.10964
88 / 500 :: 11904 / 15539 - CLASS_LOSS : 0.18351
88 / 500 :: 12544 / 15539 - CLASS_LOSS : 0.18467
88 / 500 :: 13184 / 15539 - CLASS_LOSS : 0.17205
88 / 500 :: 13824 / 15539 - CLASS_LOSS : 0.11637
88 / 500 :: 14464 / 15539 - CLASS_LOSS : 0.21226
88 / 500 :: 15104 / 15539 - CLASS_LOSS : 0.14743
89 / 500 :: 192 / 15539 - CLASS_LOSS : 0.21212
89 / 500 :: 832 / 15539 - CLASS_LOSS : 0.18054
89 / 500 :: 1472 / 15539 - CLASS_LOSS : 0.13046
89 / 500 :: 2112 / 15539 - CLASS_LOSS : 0.27485
89 / 500 :: 2752 / 15539 - CLASS_LOSS : 0.19363
89 / 500 :: 3392 / 15539 - CLASS_LOSS : 0.16146
89 / 500 :: 4032 / 15539 - CLASS_LOSS : 0.13459
89 / 500 :: 4672 / 15539 - CLASS_LOSS : 0.17354
89 / 500 :: 5312 / 15539 - CLASS_LOSS : 0.13347
89 / 500 :: 5952 / 15539 - CLASS_LOSS : 0.18788
89 / 500 :: 6592 / 15539 - CLASS_LOSS : 0.25576
89 / 500 :: 7232 / 15539 - CLASS_LOSS : 0.18913
89 / 500 :: 7872 / 15539 - CLASS_LOSS : 0.21296
89 / 500 :: 8512 / 15539 - CLASS_LOSS : 0.14662
89 / 500 :: 9152 / 15539 - CLASS_LOSS : 0.18109
89 / 500 :: 9792 / 15539 - CLASS_LOSS : 0.21343
89 / 500 :: 10432 / 15539 - CLASS_LOSS : 0.18157
89 / 500 :: 11072 / 15539 - CLASS_LOSS : 0.13683
89 / 500 :: 11712 / 15539 - CLASS_LOSS : 0.21969
89 / 500 :: 12352 / 15539 - CLASS_LOSS : 0.29701
89 / 500 :: 12992 / 15539 - CLASS_LOSS : 0.16098
89 / 500 :: 13632 / 15539 - CLASS_LOSS : 0.24577
89 / 500 :: 14272 / 15539 - CLASS_LOSS : 0.18164
89 / 500 :: 14912 / 15539 - CLASS_LOSS : 0.2994
89 / 500 :: 15539 / 15539 - CLASS_LOSS : 0.2283
90 / 500 :: 640 / 15539 - CLASS_LOSS : 0.16482
90 / 500 :: 1280 / 15539 - CLASS_LOSS : 0.19065
90 / 500 :: 1920 / 15539 - CLASS_LOSS : 0.21936
90 / 500 :: 2560 / 15539 - CLASS_LOSS : 0.27142
90 / 500 :: 3200 / 15539 - CLASS_LOSS : 0.22965
90 / 500 :: 3840 / 15539 - CLASS_LOSS : 0.12407
90 / 500 :: 4480 / 15539 - CLASS_LOSS : 0.0502
90 / 500 :: 5120 / 15539 - CLASS_LOSS : 0.12608
90 / 500 :: 5760 / 15539 - CLASS_LOSS : 0.15687
90 / 500 :: 6400 / 15539 - CLASS_LOSS : 0.1438
90 / 500 :: 7040 / 15539 - CLASS_LOSS : 0.14408
90 / 500 :: 7680 / 15539 - CLASS_LOSS : 0.17867
90 / 500 :: 8320 / 15539 - CLASS_LOSS : 0.15307
90 / 500 :: 8960 / 15539 - CLASS_LOSS : 0.20258
90 / 500 :: 9600 / 15539 - CLASS_LOSS : 0.21459
90 / 500 :: 10240 / 15539 - CLASS_LOSS : 0.17287
90 / 500 :: 10880 / 15539 - CLASS_LOSS : 0.10866
90 / 500 :: 11520 / 15539 - CLASS_LOSS : 0.21607
90 / 500 :: 12160 / 15539 - CLASS_LOSS : 0.18696
90 / 500 :: 12800 / 15539 - CLASS_LOSS : 0.34734
90 / 500 :: 13440 / 15539 - CLASS_LOSS : 0.13859
90 / 500 :: 14080 / 15539 - CLASS_LOSS : 0.17472
90 / 500 :: 14720 / 15539 - CLASS_LOSS : 0.14076
90 / 500 :: 15360 / 15539 - CLASS_LOSS : 0.30093
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.45524165004183026 0.3773516099277088 0.32071561876568633
PSPrecision@1,3,5: 0.3307257267454838 0.3544713151023327 0.3694250004977571
testing....
Precision@1,3,5: 0.3896035704909425 0.323269449549313 0.2738776581779995
PSPrecision@1,3,5: 0.2366334112379371 0.2664814592022311 0.281020035680578
91 / 500 :: 448 / 15539 - CLASS_LOSS : 0.16469
91 / 500 :: 1088 / 15539 - CLASS_LOSS : 0.17728
91 / 500 :: 1728 / 15539 - CLASS_LOSS : 0.11318
91 / 500 :: 2368 / 15539 - CLASS_LOSS : 0.17522
91 / 500 :: 3008 / 15539 - CLASS_LOSS : 0.15696
91 / 500 :: 3648 / 15539 - CLASS_LOSS : 0.15199
91 / 500 :: 4288 / 15539 - CLASS_LOSS : 0.22203
91 / 500 :: 4928 / 15539 - CLASS_LOSS : 0.14096
91 / 500 :: 5568 / 15539 - CLASS_LOSS : 0.23038
91 / 500 :: 6208 / 15539 - CLASS_LOSS : 0.19152
91 / 500 :: 6848 / 15539 - CLASS_LOSS : 0.25923
91 / 500 :: 7488 / 15539 - CLASS_LOSS : 0.16069
91 / 500 :: 8128 / 15539 - CLASS_LOSS : 0.11688
91 / 500 :: 8768 / 15539 - CLASS_LOSS : 0.17534
91 / 500 :: 9408 / 15539 - CLASS_LOSS : 0.10879
91 / 500 :: 10048 / 15539 - CLASS_LOSS : 0.13727
91 / 500 :: 10688 / 15539 - CLASS_LOSS : 0.18927
91 / 500 :: 11328 / 15539 - CLASS_LOSS : 0.23756
91 / 500 :: 11968 / 15539 - CLASS_LOSS : 0.12269
91 / 500 :: 12608 / 15539 - CLASS_LOSS : 0.18437
91 / 500 :: 13248 / 15539 - CLASS_LOSS : 0.25461
91 / 500 :: 13888 / 15539 - CLASS_LOSS : 0.22544
91 / 500 :: 14528 / 15539 - CLASS_LOSS : 0.24238
91 / 500 :: 15168 / 15539 - CLASS_LOSS : 0.19524
92 / 500 :: 256 / 15539 - CLASS_LOSS : 0.16146
92 / 500 :: 896 / 15539 - CLASS_LOSS : 0.18941
92 / 500 :: 1536 / 15539 - CLASS_LOSS : 0.27075
92 / 500 :: 2176 / 15539 - CLASS_LOSS : 0.12643
92 / 500 :: 2816 / 15539 - CLASS_LOSS : 0.29828
92 / 500 :: 3456 / 15539 - CLASS_LOSS : 0.13965
92 / 500 :: 4096 / 15539 - CLASS_LOSS : 0.19112
92 / 500 :: 4736 / 15539 - CLASS_LOSS : 0.22683
92 / 500 :: 5376 / 15539 - CLASS_LOSS : 0.16389
92 / 500 :: 6016 / 15539 - CLASS_LOSS : 0.18284
92 / 500 :: 6656 / 15539 - CLASS_LOSS : 0.17058
92 / 500 :: 7296 / 15539 - CLASS_LOSS : 0.12984
92 / 500 :: 7936 / 15539 - CLASS_LOSS : 0.16091
92 / 500 :: 8576 / 15539 - CLASS_LOSS : 0.19605
92 / 500 :: 9216 / 15539 - CLASS_LOSS : 0.11542
92 / 500 :: 9856 / 15539 - CLASS_LOSS : 0.10754
92 / 500 :: 10496 / 15539 - CLASS_LOSS : 0.20733
92 / 500 :: 11136 / 15539 - CLASS_LOSS : 0.16505
92 / 500 :: 11776 / 15539 - CLASS_LOSS : 0.17499
92 / 500 :: 12416 / 15539 - CLASS_LOSS : 0.13523
92 / 500 :: 13056 / 15539 - CLASS_LOSS : 0.11537
92 / 500 :: 13696 / 15539 - CLASS_LOSS : 0.31348
92 / 500 :: 14336 / 15539 - CLASS_LOSS : 0.19992
92 / 500 :: 14976 / 15539 - CLASS_LOSS : 0.13865
93 / 500 :: 64 / 15539 - CLASS_LOSS : 0.15228
93 / 500 :: 704 / 15539 - CLASS_LOSS : 0.18998
93 / 500 :: 1344 / 15539 - CLASS_LOSS : 0.1769
93 / 500 :: 1984 / 15539 - CLASS_LOSS : 0.16269
93 / 500 :: 2624 / 15539 - CLASS_LOSS : 0.12292
93 / 500 :: 3264 / 15539 - CLASS_LOSS : 0.18762
93 / 500 :: 3904 / 15539 - CLASS_LOSS : 0.16663
93 / 500 :: 4544 / 15539 - CLASS_LOSS : 0.19168
93 / 500 :: 5184 / 15539 - CLASS_LOSS : 0.19122
93 / 500 :: 5824 / 15539 - CLASS_LOSS : 0.12405
93 / 500 :: 6464 / 15539 - CLASS_LOSS : 0.1619
93 / 500 :: 7104 / 15539 - CLASS_LOSS : 0.19262
93 / 500 :: 7744 / 15539 - CLASS_LOSS : 0.16804
93 / 500 :: 8384 / 15539 - CLASS_LOSS : 0.12873
93 / 500 :: 9024 / 15539 - CLASS_LOSS : 0.13152
93 / 500 :: 9664 / 15539 - CLASS_LOSS : 0.21422
93 / 500 :: 10304 / 15539 - CLASS_LOSS : 0.14736
93 / 500 :: 10944 / 15539 - CLASS_LOSS : 0.2014
93 / 500 :: 11584 / 15539 - CLASS_LOSS : 0.30239
93 / 500 :: 12224 / 15539 - CLASS_LOSS : 0.24037
93 / 500 :: 12864 / 15539 - CLASS_LOSS : 0.18799
93 / 500 :: 13504 / 15539 - CLASS_LOSS : 0.26648
93 / 500 :: 14144 / 15539 - CLASS_LOSS : 0.17948
93 / 500 :: 14784 / 15539 - CLASS_LOSS : 0.1039
93 / 500 :: 15424 / 15539 - CLASS_LOSS : 0.13116
94 / 500 :: 512 / 15539 - CLASS_LOSS : 0.26435
94 / 500 :: 1152 / 15539 - CLASS_LOSS : 0.22205
94 / 500 :: 1792 / 15539 - CLASS_LOSS : 0.15928
94 / 500 :: 2432 / 15539 - CLASS_LOSS : 0.22372
94 / 500 :: 3072 / 15539 - CLASS_LOSS : 0.18076
94 / 500 :: 3712 / 15539 - CLASS_LOSS : 0.17622
94 / 500 :: 4352 / 15539 - CLASS_LOSS : 0.16264
94 / 500 :: 4992 / 15539 - CLASS_LOSS : 0.1479
94 / 500 :: 5632 / 15539 - CLASS_LOSS : 0.20986
94 / 500 :: 6272 / 15539 - CLASS_LOSS : 0.21753
94 / 500 :: 6912 / 15539 - CLASS_LOSS : 0.24266
94 / 500 :: 7552 / 15539 - CLASS_LOSS : 0.21488
94 / 500 :: 8192 / 15539 - CLASS_LOSS : 0.1564
94 / 500 :: 8832 / 15539 - CLASS_LOSS : 0.11591
94 / 500 :: 9472 / 15539 - CLASS_LOSS : 0.13717
94 / 500 :: 10112 / 15539 - CLASS_LOSS : 0.24973
94 / 500 :: 10752 / 15539 - CLASS_LOSS : 0.13089
94 / 500 :: 11392 / 15539 - CLASS_LOSS : 0.20776
94 / 500 :: 12032 / 15539 - CLASS_LOSS : 0.19557
94 / 500 :: 12672 / 15539 - CLASS_LOSS : 0.14507
94 / 500 :: 13312 / 15539 - CLASS_LOSS : 0.14677
94 / 500 :: 13952 / 15539 - CLASS_LOSS : 0.16659
94 / 500 :: 14592 / 15539 - CLASS_LOSS : 0.20746
94 / 500 :: 15232 / 15539 - CLASS_LOSS : 0.1686
95 / 500 :: 320 / 15539 - CLASS_LOSS : 0.15757
95 / 500 :: 960 / 15539 - CLASS_LOSS : 0.15319
95 / 500 :: 1600 / 15539 - CLASS_LOSS : 0.16775
95 / 500 :: 2240 / 15539 - CLASS_LOSS : 0.19378
95 / 500 :: 2880 / 15539 - CLASS_LOSS : 0.11861
95 / 500 :: 3520 / 15539 - CLASS_LOSS : 0.19956
95 / 500 :: 4160 / 15539 - CLASS_LOSS : 0.25115
95 / 500 :: 4800 / 15539 - CLASS_LOSS : 0.10671
95 / 500 :: 5440 / 15539 - CLASS_LOSS : 0.18365
95 / 500 :: 6080 / 15539 - CLASS_LOSS : 0.15045
95 / 500 :: 6720 / 15539 - CLASS_LOSS : 0.09668
95 / 500 :: 7360 / 15539 - CLASS_LOSS : 0.1843
95 / 500 :: 8000 / 15539 - CLASS_LOSS : 0.15182
95 / 500 :: 8640 / 15539 - CLASS_LOSS : 0.16881
95 / 500 :: 9280 / 15539 - CLASS_LOSS : 0.16682
95 / 500 :: 9920 / 15539 - CLASS_LOSS : 0.20668
95 / 500 :: 10560 / 15539 - CLASS_LOSS : 0.11545
95 / 500 :: 11200 / 15539 - CLASS_LOSS : 0.17392
95 / 500 :: 11840 / 15539 - CLASS_LOSS : 0.12623
95 / 500 :: 12480 / 15539 - CLASS_LOSS : 0.21969
95 / 500 :: 13120 / 15539 - CLASS_LOSS : 0.09682
95 / 500 :: 13760 / 15539 - CLASS_LOSS : 0.21965
95 / 500 :: 14400 / 15539 - CLASS_LOSS : 0.13065
95 / 500 :: 15040 / 15539 - CLASS_LOSS : 0.09537
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.4793101229165326 0.3866615183302229 0.327768839693674
PSPrecision@1,3,5: 0.34304255875272077 0.36406553717477097 0.3783755352386312
testing....
Precision@1,3,5: 0.4166447886584405 0.33018290014877044 0.27587293252822265
PSPrecision@1,3,5: 0.24921307158202888 0.2717157592908599 0.2826181642360266
96 / 500 :: 128 / 15539 - CLASS_LOSS : 0.15081
96 / 500 :: 768 / 15539 - CLASS_LOSS : 0.23787
96 / 500 :: 1408 / 15539 - CLASS_LOSS : 0.1674
96 / 500 :: 2048 / 15539 - CLASS_LOSS : 0.24795
96 / 500 :: 2688 / 15539 - CLASS_LOSS : 0.23261
96 / 500 :: 3328 / 15539 - CLASS_LOSS : 0.16553
96 / 500 :: 3968 / 15539 - CLASS_LOSS : 0.1614
96 / 500 :: 4608 / 15539 - CLASS_LOSS : 0.1804
96 / 500 :: 5248 / 15539 - CLASS_LOSS : 0.11583
96 / 500 :: 5888 / 15539 - CLASS_LOSS : 0.13972
96 / 500 :: 6528 / 15539 - CLASS_LOSS : 0.10796
96 / 500 :: 7168 / 15539 - CLASS_LOSS : 0.13103
96 / 500 :: 7808 / 15539 - CLASS_LOSS : 0.15598
96 / 500 :: 8448 / 15539 - CLASS_LOSS : 0.14537
96 / 500 :: 9088 / 15539 - CLASS_LOSS : 0.13788
96 / 500 :: 9728 / 15539 - CLASS_LOSS : 0.18649
96 / 500 :: 10368 / 15539 - CLASS_LOSS : 0.17122
96 / 500 :: 11008 / 15539 - CLASS_LOSS : 0.13555
96 / 500 :: 11648 / 15539 - CLASS_LOSS : 0.22489
96 / 500 :: 12288 / 15539 - CLASS_LOSS : 0.15953
96 / 500 :: 12928 / 15539 - CLASS_LOSS : 0.1936
96 / 500 :: 13568 / 15539 - CLASS_LOSS : 0.12722
96 / 500 :: 14208 / 15539 - CLASS_LOSS : 0.24892
96 / 500 :: 14848 / 15539 - CLASS_LOSS : 0.17929
96 / 500 :: 15488 / 15539 - CLASS_LOSS : 0.15138
97 / 500 :: 576 / 15539 - CLASS_LOSS : 0.26177
97 / 500 :: 1216 / 15539 - CLASS_LOSS : 0.16115
97 / 500 :: 1856 / 15539 - CLASS_LOSS : 0.13907
97 / 500 :: 2496 / 15539 - CLASS_LOSS : 0.12797
97 / 500 :: 3136 / 15539 - CLASS_LOSS : 0.26382
97 / 500 :: 3776 / 15539 - CLASS_LOSS : 0.12241
97 / 500 :: 4416 / 15539 - CLASS_LOSS : 0.22157
97 / 500 :: 5056 / 15539 - CLASS_LOSS : 0.15226
97 / 500 :: 5696 / 15539 - CLASS_LOSS : 0.16179
97 / 500 :: 6336 / 15539 - CLASS_LOSS : 0.18009
97 / 500 :: 6976 / 15539 - CLASS_LOSS : 0.19351
97 / 500 :: 7616 / 15539 - CLASS_LOSS : 0.23577
97 / 500 :: 8256 / 15539 - CLASS_LOSS : 0.147
97 / 500 :: 8896 / 15539 - CLASS_LOSS : 0.22573
97 / 500 :: 9536 / 15539 - CLASS_LOSS : 0.16665
97 / 500 :: 10176 / 15539 - CLASS_LOSS : 0.21935
97 / 500 :: 10816 / 15539 - CLASS_LOSS : 0.17632
97 / 500 :: 11456 / 15539 - CLASS_LOSS : 0.28821
97 / 500 :: 12096 / 15539 - CLASS_LOSS : 0.14151
97 / 500 :: 12736 / 15539 - CLASS_LOSS : 0.28193
97 / 500 :: 13376 / 15539 - CLASS_LOSS : 0.1555
97 / 500 :: 14016 / 15539 - CLASS_LOSS : 0.14392
97 / 500 :: 14656 / 15539 - CLASS_LOSS : 0.15244
97 / 500 :: 15296 / 15539 - CLASS_LOSS : 0.22274
98 / 500 :: 384 / 15539 - CLASS_LOSS : 0.16332
98 / 500 :: 1024 / 15539 - CLASS_LOSS : 0.11562
98 / 500 :: 1664 / 15539 - CLASS_LOSS : 0.16793
98 / 500 :: 2304 / 15539 - CLASS_LOSS : 0.09962
98 / 500 :: 2944 / 15539 - CLASS_LOSS : 0.14563
98 / 500 :: 3584 / 15539 - CLASS_LOSS : 0.17994
98 / 500 :: 4224 / 15539 - CLASS_LOSS : 0.1282
98 / 500 :: 4864 / 15539 - CLASS_LOSS : 0.31096
98 / 500 :: 5504 / 15539 - CLASS_LOSS : 0.24844
98 / 500 :: 6144 / 15539 - CLASS_LOSS : 0.15699
98 / 500 :: 6784 / 15539 - CLASS_LOSS : 0.12087
98 / 500 :: 7424 / 15539 - CLASS_LOSS : 0.2804
98 / 500 :: 8064 / 15539 - CLASS_LOSS : 0.15239
98 / 500 :: 8704 / 15539 - CLASS_LOSS : 0.16293
98 / 500 :: 9344 / 15539 - CLASS_LOSS : 0.15333
98 / 500 :: 9984 / 15539 - CLASS_LOSS : 0.16659
98 / 500 :: 10624 / 15539 - CLASS_LOSS : 0.13499
98 / 500 :: 11264 / 15539 - CLASS_LOSS : 0.15897
98 / 500 :: 11904 / 15539 - CLASS_LOSS : 0.1214
98 / 500 :: 12544 / 15539 - CLASS_LOSS : 0.16026
98 / 500 :: 13184 / 15539 - CLASS_LOSS : 0.2305
98 / 500 :: 13824 / 15539 - CLASS_LOSS : 0.164
98 / 500 :: 14464 / 15539 - CLASS_LOSS : 0.22063
98 / 500 :: 15104 / 15539 - CLASS_LOSS : 0.11878
99 / 500 :: 192 / 15539 - CLASS_LOSS : 0.23554
99 / 500 :: 832 / 15539 - CLASS_LOSS : 0.2761
99 / 500 :: 1472 / 15539 - CLASS_LOSS : 0.23422
99 / 500 :: 2112 / 15539 - CLASS_LOSS : 0.21388
99 / 500 :: 2752 / 15539 - CLASS_LOSS : 0.18261
99 / 500 :: 3392 / 15539 - CLASS_LOSS : 0.14168
99 / 500 :: 4032 / 15539 - CLASS_LOSS : 0.20354
99 / 500 :: 4672 / 15539 - CLASS_LOSS : 0.21211
99 / 500 :: 5312 / 15539 - CLASS_LOSS : 0.16505
99 / 500 :: 5952 / 15539 - CLASS_LOSS : 0.11526
99 / 500 :: 6592 / 15539 - CLASS_LOSS : 0.19831
99 / 500 :: 7232 / 15539 - CLASS_LOSS : 0.12629
99 / 500 :: 7872 / 15539 - CLASS_LOSS : 0.20866
99 / 500 :: 8512 / 15539 - CLASS_LOSS : 0.21276
99 / 500 :: 9152 / 15539 - CLASS_LOSS : 0.19656
99 / 500 :: 9792 / 15539 - CLASS_LOSS : 0.17385
99 / 500 :: 10432 / 15539 - CLASS_LOSS : 0.25084
99 / 500 :: 11072 / 15539 - CLASS_LOSS : 0.15871
99 / 500 :: 11712 / 15539 - CLASS_LOSS : 0.16295
99 / 500 :: 12352 / 15539 - CLASS_LOSS : 0.27982
99 / 500 :: 12992 / 15539 - CLASS_LOSS : 0.2536
99 / 500 :: 13632 / 15539 - CLASS_LOSS : 0.16717
99 / 500 :: 14272 / 15539 - CLASS_LOSS : 0.21285
99 / 500 :: 14912 / 15539 - CLASS_LOSS : 0.10964
99 / 500 :: 15539 / 15539 - CLASS_LOSS : 0.19872
100 / 500 :: 640 / 15539 - CLASS_LOSS : 0.16856
100 / 500 :: 1280 / 15539 - CLASS_LOSS : 0.29277
100 / 500 :: 1920 / 15539 - CLASS_LOSS : 0.11037
100 / 500 :: 2560 / 15539 - CLASS_LOSS : 0.13613
100 / 500 :: 3200 / 15539 - CLASS_LOSS : 0.18858
100 / 500 :: 3840 / 15539 - CLASS_LOSS : 0.3298
100 / 500 :: 4480 / 15539 - CLASS_LOSS : 0.13913
100 / 500 :: 5120 / 15539 - CLASS_LOSS : 0.20737
100 / 500 :: 5760 / 15539 - CLASS_LOSS : 0.13306
100 / 500 :: 6400 / 15539 - CLASS_LOSS : 0.17202
100 / 500 :: 7040 / 15539 - CLASS_LOSS : 0.26586
100 / 500 :: 7680 / 15539 - CLASS_LOSS : 0.16753
100 / 500 :: 8320 / 15539 - CLASS_LOSS : 0.10705
100 / 500 :: 8960 / 15539 - CLASS_LOSS : 0.17085
100 / 500 :: 9600 / 15539 - CLASS_LOSS : 0.20728
100 / 500 :: 10240 / 15539 - CLASS_LOSS : 0.19735
100 / 500 :: 10880 / 15539 - CLASS_LOSS : 0.14997
100 / 500 :: 11520 / 15539 - CLASS_LOSS : 0.14329
100 / 500 :: 12160 / 15539 - CLASS_LOSS : 0.12338
100 / 500 :: 12800 / 15539 - CLASS_LOSS : 0.22453
100 / 500 :: 13440 / 15539 - CLASS_LOSS : 0.15538
100 / 500 :: 14080 / 15539 - CLASS_LOSS : 0.16369
100 / 500 :: 14720 / 15539 - CLASS_LOSS : 0.11009
100 / 500 :: 15360 / 15539 - CLASS_LOSS : 0.24594
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.46978570049552737 0.3914022781388764 0.3328785636141322
PSPrecision@1,3,5: 0.3456804336038538 0.36990634988529303 0.38537389685323387
testing....
Precision@1,3,5: 0.40771856130217904 0.3281701233919664 0.2784982935153584
PSPrecision@1,3,5: 0.24706172774892862 0.27002152727941775 0.2839049982850576
101 / 500 :: 448 / 15539 - CLASS_LOSS : 0.20476
101 / 500 :: 1088 / 15539 - CLASS_LOSS : 0.13067
101 / 500 :: 1728 / 15539 - CLASS_LOSS : 0.21745
101 / 500 :: 2368 / 15539 - CLASS_LOSS : 0.18169
101 / 500 :: 3008 / 15539 - CLASS_LOSS : 0.10525
101 / 500 :: 3648 / 15539 - CLASS_LOSS : 0.16361
101 / 500 :: 4288 / 15539 - CLASS_LOSS : 0.15322
101 / 500 :: 4928 / 15539 - CLASS_LOSS : 0.23092
101 / 500 :: 5568 / 15539 - CLASS_LOSS : 0.24238
101 / 500 :: 6208 / 15539 - CLASS_LOSS : 0.16021
101 / 500 :: 6848 / 15539 - CLASS_LOSS : 0.2572
101 / 500 :: 7488 / 15539 - CLASS_LOSS : 0.20329
101 / 500 :: 8128 / 15539 - CLASS_LOSS : 0.14491
101 / 500 :: 8768 / 15539 - CLASS_LOSS : 0.19383
101 / 500 :: 9408 / 15539 - CLASS_LOSS : 0.13255
101 / 500 :: 10048 / 15539 - CLASS_LOSS : 0.14524
101 / 500 :: 10688 / 15539 - CLASS_LOSS : 0.22356
101 / 500 :: 11328 / 15539 - CLASS_LOSS : 0.2027
101 / 500 :: 11968 / 15539 - CLASS_LOSS : 0.18485
101 / 500 :: 12608 / 15539 - CLASS_LOSS : 0.24104
101 / 500 :: 13248 / 15539 - CLASS_LOSS : 0.15806
101 / 500 :: 13888 / 15539 - CLASS_LOSS : 0.18761
101 / 500 :: 14528 / 15539 - CLASS_LOSS : 0.26209
101 / 500 :: 15168 / 15539 - CLASS_LOSS : 0.13439
102 / 500 :: 256 / 15539 - CLASS_LOSS : 0.28346
102 / 500 :: 896 / 15539 - CLASS_LOSS : 0.22172
102 / 500 :: 1536 / 15539 - CLASS_LOSS : 0.14307
102 / 500 :: 2176 / 15539 - CLASS_LOSS : 0.23258
102 / 500 :: 2816 / 15539 - CLASS_LOSS : 0.17721
102 / 500 :: 3456 / 15539 - CLASS_LOSS : 0.14544
102 / 500 :: 4096 / 15539 - CLASS_LOSS : 0.09594
102 / 500 :: 4736 / 15539 - CLASS_LOSS : 0.18524
102 / 500 :: 5376 / 15539 - CLASS_LOSS : 0.12203
102 / 500 :: 6016 / 15539 - CLASS_LOSS : 0.12969
102 / 500 :: 6656 / 15539 - CLASS_LOSS : 0.21306
102 / 500 :: 7296 / 15539 - CLASS_LOSS : 0.17613
102 / 500 :: 7936 / 15539 - CLASS_LOSS : 0.16259
102 / 500 :: 8576 / 15539 - CLASS_LOSS : 0.20377
102 / 500 :: 9216 / 15539 - CLASS_LOSS : 0.15106
102 / 500 :: 9856 / 15539 - CLASS_LOSS : 0.2237
102 / 500 :: 10496 / 15539 - CLASS_LOSS : 0.26088
102 / 500 :: 11136 / 15539 - CLASS_LOSS : 0.15113
102 / 500 :: 11776 / 15539 - CLASS_LOSS : 0.13017
102 / 500 :: 12416 / 15539 - CLASS_LOSS : 0.14584
102 / 500 :: 13056 / 15539 - CLASS_LOSS : 0.2027
102 / 500 :: 13696 / 15539 - CLASS_LOSS : 0.15062
102 / 500 :: 14336 / 15539 - CLASS_LOSS : 0.09384
102 / 500 :: 14976 / 15539 - CLASS_LOSS : 0.13691
103 / 500 :: 64 / 15539 - CLASS_LOSS : 0.14666
103 / 500 :: 704 / 15539 - CLASS_LOSS : 0.11395
103 / 500 :: 1344 / 15539 - CLASS_LOSS : 0.15955
103 / 500 :: 1984 / 15539 - CLASS_LOSS : 0.22231
103 / 500 :: 2624 / 15539 - CLASS_LOSS : 0.33585
103 / 500 :: 3264 / 15539 - CLASS_LOSS : 0.16414
103 / 500 :: 3904 / 15539 - CLASS_LOSS : 0.11244
103 / 500 :: 4544 / 15539 - CLASS_LOSS : 0.16441
103 / 500 :: 5184 / 15539 - CLASS_LOSS : 0.16806
103 / 500 :: 5824 / 15539 - CLASS_LOSS : 0.18119
103 / 500 :: 6464 / 15539 - CLASS_LOSS : 0.16534
103 / 500 :: 7104 / 15539 - CLASS_LOSS : 0.07666
103 / 500 :: 7744 / 15539 - CLASS_LOSS : 0.15419
103 / 500 :: 8384 / 15539 - CLASS_LOSS : 0.19548
103 / 500 :: 9024 / 15539 - CLASS_LOSS : 0.14997
103 / 500 :: 9664 / 15539 - CLASS_LOSS : 0.19038
103 / 500 :: 10304 / 15539 - CLASS_LOSS : 0.21855
103 / 500 :: 10944 / 15539 - CLASS_LOSS : 0.13162
103 / 500 :: 11584 / 15539 - CLASS_LOSS : 0.18729
103 / 500 :: 12224 / 15539 - CLASS_LOSS : 0.16447
103 / 500 :: 12864 / 15539 - CLASS_LOSS : 0.26372
103 / 500 :: 13504 / 15539 - CLASS_LOSS : 0.18823
103 / 500 :: 14144 / 15539 - CLASS_LOSS : 0.19325
103 / 500 :: 14784 / 15539 - CLASS_LOSS : 0.17241
103 / 500 :: 15424 / 15539 - CLASS_LOSS : 0.27587
104 / 500 :: 512 / 15539 - CLASS_LOSS : 0.08393
104 / 500 :: 1152 / 15539 - CLASS_LOSS : 0.1944
104 / 500 :: 1792 / 15539 - CLASS_LOSS : 0.23965
104 / 500 :: 2432 / 15539 - CLASS_LOSS : 0.15383
104 / 500 :: 3072 / 15539 - CLASS_LOSS : 0.18906
104 / 500 :: 3712 / 15539 - CLASS_LOSS : 0.10955
104 / 500 :: 4352 / 15539 - CLASS_LOSS : 0.16763
104 / 500 :: 4992 / 15539 - CLASS_LOSS : 0.15804
104 / 500 :: 5632 / 15539 - CLASS_LOSS : 0.15185
104 / 500 :: 6272 / 15539 - CLASS_LOSS : 0.0939
104 / 500 :: 6912 / 15539 - CLASS_LOSS : 0.16262
104 / 500 :: 7552 / 15539 - CLASS_LOSS : 0.17477
104 / 500 :: 8192 / 15539 - CLASS_LOSS : 0.17446
104 / 500 :: 8832 / 15539 - CLASS_LOSS : 0.16643
104 / 500 :: 9472 / 15539 - CLASS_LOSS : 0.2539
104 / 500 :: 10112 / 15539 - CLASS_LOSS : 0.18663
104 / 500 :: 10752 / 15539 - CLASS_LOSS : 0.16786
104 / 500 :: 11392 / 15539 - CLASS_LOSS : 0.16957
104 / 500 :: 12032 / 15539 - CLASS_LOSS : 0.27354
104 / 500 :: 12672 / 15539 - CLASS_LOSS : 0.14045
104 / 500 :: 13312 / 15539 - CLASS_LOSS : 0.24885
104 / 500 :: 13952 / 15539 - CLASS_LOSS : 0.17308
104 / 500 :: 14592 / 15539 - CLASS_LOSS : 0.1141
104 / 500 :: 15232 / 15539 - CLASS_LOSS : 0.14649
105 / 500 :: 320 / 15539 - CLASS_LOSS : 0.16762
105 / 500 :: 960 / 15539 - CLASS_LOSS : 0.19728
105 / 500 :: 1600 / 15539 - CLASS_LOSS : 0.16461
105 / 500 :: 2240 / 15539 - CLASS_LOSS : 0.18895
105 / 500 :: 2880 / 15539 - CLASS_LOSS : 0.12259
105 / 500 :: 3520 / 15539 - CLASS_LOSS : 0.14109
105 / 500 :: 4160 / 15539 - CLASS_LOSS : 0.118
105 / 500 :: 4800 / 15539 - CLASS_LOSS : 0.17193
105 / 500 :: 5440 / 15539 - CLASS_LOSS : 0.19487
105 / 500 :: 6080 / 15539 - CLASS_LOSS : 0.20943
105 / 500 :: 6720 / 15539 - CLASS_LOSS : 0.18534
105 / 500 :: 7360 / 15539 - CLASS_LOSS : 0.14145
105 / 500 :: 8000 / 15539 - CLASS_LOSS : 0.15252
105 / 500 :: 8640 / 15539 - CLASS_LOSS : 0.18811
105 / 500 :: 9280 / 15539 - CLASS_LOSS : 0.14066
105 / 500 :: 9920 / 15539 - CLASS_LOSS : 0.19236
105 / 500 :: 10560 / 15539 - CLASS_LOSS : 0.18367
105 / 500 :: 11200 / 15539 - CLASS_LOSS : 0.16473
105 / 500 :: 11840 / 15539 - CLASS_LOSS : 0.14043
105 / 500 :: 12480 / 15539 - CLASS_LOSS : 0.26678
105 / 500 :: 13120 / 15539 - CLASS_LOSS : 0.13287
105 / 500 :: 13760 / 15539 - CLASS_LOSS : 0.22728
105 / 500 :: 14400 / 15539 - CLASS_LOSS : 0.14367
105 / 500 :: 15040 / 15539 - CLASS_LOSS : 0.1887
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.49443336122015574 0.3983739837398374 0.3381684793101229
PSPrecision@1,3,5: 0.360080436641532 0.374021120183134 0.3894150903623257
testing....
Precision@1,3,5: 0.41716986085586766 0.32834514745777543 0.28170123391966395
PSPrecision@1,3,5: 0.25443376799150963 0.2695407238466623 0.28948375328622133
106 / 500 :: 128 / 15539 - CLASS_LOSS : 0.18438
106 / 500 :: 768 / 15539 - CLASS_LOSS : 0.11746
106 / 500 :: 1408 / 15539 - CLASS_LOSS : 0.14365
106 / 500 :: 2048 / 15539 - CLASS_LOSS : 0.2185
106 / 500 :: 2688 / 15539 - CLASS_LOSS : 0.17715
106 / 500 :: 3328 / 15539 - CLASS_LOSS : 0.18828
106 / 500 :: 3968 / 15539 - CLASS_LOSS : 0.18838
106 / 500 :: 4608 / 15539 - CLASS_LOSS : 0.21781
106 / 500 :: 5248 / 15539 - CLASS_LOSS : 0.16145
106 / 500 :: 5888 / 15539 - CLASS_LOSS : 0.14087
106 / 500 :: 6528 / 15539 - CLASS_LOSS : 0.24163
106 / 500 :: 7168 / 15539 - CLASS_LOSS : 0.12286
106 / 500 :: 7808 / 15539 - CLASS_LOSS : 0.2059
106 / 500 :: 8448 / 15539 - CLASS_LOSS : 0.24585
106 / 500 :: 9088 / 15539 - CLASS_LOSS : 0.08775
106 / 500 :: 9728 / 15539 - CLASS_LOSS : 0.14088
106 / 500 :: 10368 / 15539 - CLASS_LOSS : 0.23976
106 / 500 :: 11008 / 15539 - CLASS_LOSS : 0.10773
106 / 500 :: 11648 / 15539 - CLASS_LOSS : 0.21071
106 / 500 :: 12288 / 15539 - CLASS_LOSS : 0.12754
106 / 500 :: 12928 / 15539 - CLASS_LOSS : 0.15802
106 / 500 :: 13568 / 15539 - CLASS_LOSS : 0.25039
106 / 500 :: 14208 / 15539 - CLASS_LOSS : 0.1235
106 / 500 :: 14848 / 15539 - CLASS_LOSS : 0.17924
106 / 500 :: 15488 / 15539 - CLASS_LOSS : 0.13554
107 / 500 :: 576 / 15539 - CLASS_LOSS : 0.17476
107 / 500 :: 1216 / 15539 - CLASS_LOSS : 0.18878
107 / 500 :: 1856 / 15539 - CLASS_LOSS : 0.14584
107 / 500 :: 2496 / 15539 - CLASS_LOSS : 0.22328
107 / 500 :: 3136 / 15539 - CLASS_LOSS : 0.28255
107 / 500 :: 3776 / 15539 - CLASS_LOSS : 0.13147
107 / 500 :: 4416 / 15539 - CLASS_LOSS : 0.28878
107 / 500 :: 5056 / 15539 - CLASS_LOSS : 0.11004
107 / 500 :: 5696 / 15539 - CLASS_LOSS : 0.20294
107 / 500 :: 6336 / 15539 - CLASS_LOSS : 0.25716
107 / 500 :: 6976 / 15539 - CLASS_LOSS : 0.19139
107 / 500 :: 7616 / 15539 - CLASS_LOSS : 0.21717
107 / 500 :: 8256 / 15539 - CLASS_LOSS : 0.15939
107 / 500 :: 8896 / 15539 - CLASS_LOSS : 0.14436
107 / 500 :: 9536 / 15539 - CLASS_LOSS : 0.24936
107 / 500 :: 10176 / 15539 - CLASS_LOSS : 0.21481
107 / 500 :: 10816 / 15539 - CLASS_LOSS : 0.20221
107 / 500 :: 11456 / 15539 - CLASS_LOSS : 0.20451
107 / 500 :: 12096 / 15539 - CLASS_LOSS : 0.15387
107 / 500 :: 12736 / 15539 - CLASS_LOSS : 0.11892
107 / 500 :: 13376 / 15539 - CLASS_LOSS : 0.17576
107 / 500 :: 14016 / 15539 - CLASS_LOSS : 0.17699
107 / 500 :: 14656 / 15539 - CLASS_LOSS : 0.15968
107 / 500 :: 15296 / 15539 - CLASS_LOSS : 0.25677
108 / 500 :: 384 / 15539 - CLASS_LOSS : 0.20281
108 / 500 :: 1024 / 15539 - CLASS_LOSS : 0.21057
108 / 500 :: 1664 / 15539 - CLASS_LOSS : 0.26771
108 / 500 :: 2304 / 15539 - CLASS_LOSS : 0.17682
108 / 500 :: 2944 / 15539 - CLASS_LOSS : 0.15174
108 / 500 :: 3584 / 15539 - CLASS_LOSS : 0.15731
108 / 500 :: 4224 / 15539 - CLASS_LOSS : 0.17318
108 / 500 :: 4864 / 15539 - CLASS_LOSS : 0.13171
108 / 500 :: 5504 / 15539 - CLASS_LOSS : 0.12136
108 / 500 :: 6144 / 15539 - CLASS_LOSS : 0.17268
108 / 500 :: 6784 / 15539 - CLASS_LOSS : 0.16825
108 / 500 :: 7424 / 15539 - CLASS_LOSS : 0.14998
108 / 500 :: 8064 / 15539 - CLASS_LOSS : 0.13477
108 / 500 :: 8704 / 15539 - CLASS_LOSS : 0.25283
108 / 500 :: 9344 / 15539 - CLASS_LOSS : 0.07256
108 / 500 :: 9984 / 15539 - CLASS_LOSS : 0.22821
108 / 500 :: 10624 / 15539 - CLASS_LOSS : 0.18589
108 / 500 :: 11264 / 15539 - CLASS_LOSS : 0.2332
108 / 500 :: 11904 / 15539 - CLASS_LOSS : 0.15555
108 / 500 :: 12544 / 15539 - CLASS_LOSS : 0.23556
108 / 500 :: 13184 / 15539 - CLASS_LOSS : 0.16476
108 / 500 :: 13824 / 15539 - CLASS_LOSS : 0.1945
108 / 500 :: 14464 / 15539 - CLASS_LOSS : 0.13429
108 / 500 :: 15104 / 15539 - CLASS_LOSS : 0.06553
109 / 500 :: 192 / 15539 - CLASS_LOSS : 0.18988
109 / 500 :: 832 / 15539 - CLASS_LOSS : 0.18452
109 / 500 :: 1472 / 15539 - CLASS_LOSS : 0.17761
109 / 500 :: 2112 / 15539 - CLASS_LOSS : 0.15288
109 / 500 :: 2752 / 15539 - CLASS_LOSS : 0.1846
109 / 500 :: 3392 / 15539 - CLASS_LOSS : 0.14997
109 / 500 :: 4032 / 15539 - CLASS_LOSS : 0.181
109 / 500 :: 4672 / 15539 - CLASS_LOSS : 0.15608
109 / 500 :: 5312 / 15539 - CLASS_LOSS : 0.19007
109 / 500 :: 5952 / 15539 - CLASS_LOSS : 0.14752
109 / 500 :: 6592 / 15539 - CLASS_LOSS : 0.13861
109 / 500 :: 7232 / 15539 - CLASS_LOSS : 0.11419
109 / 500 :: 7872 / 15539 - CLASS_LOSS : 0.12109
109 / 500 :: 8512 / 15539 - CLASS_LOSS : 0.17537
109 / 500 :: 9152 / 15539 - CLASS_LOSS : 0.20282
109 / 500 :: 9792 / 15539 - CLASS_LOSS : 0.20347
109 / 500 :: 10432 / 15539 - CLASS_LOSS : 0.24065
109 / 500 :: 11072 / 15539 - CLASS_LOSS : 0.13032
109 / 500 :: 11712 / 15539 - CLASS_LOSS : 0.3065
109 / 500 :: 12352 / 15539 - CLASS_LOSS : 0.14747
109 / 500 :: 12992 / 15539 - CLASS_LOSS : 0.19351
109 / 500 :: 13632 / 15539 - CLASS_LOSS : 0.16174
109 / 500 :: 14272 / 15539 - CLASS_LOSS : 0.11003
109 / 500 :: 14912 / 15539 - CLASS_LOSS : 0.25127
109 / 500 :: 15539 / 15539 - CLASS_LOSS : 0.51724
110 / 500 :: 640 / 15539 - CLASS_LOSS : 0.14025
110 / 500 :: 1280 / 15539 - CLASS_LOSS : 0.11323
110 / 500 :: 1920 / 15539 - CLASS_LOSS : 0.1802
110 / 500 :: 2560 / 15539 - CLASS_LOSS : 0.1719
110 / 500 :: 3200 / 15539 - CLASS_LOSS : 0.12013
110 / 500 :: 3840 / 15539 - CLASS_LOSS : 0.15405
110 / 500 :: 4480 / 15539 - CLASS_LOSS : 0.21652
110 / 500 :: 5120 / 15539 - CLASS_LOSS : 0.18722
110 / 500 :: 5760 / 15539 - CLASS_LOSS : 0.0832
110 / 500 :: 6400 / 15539 - CLASS_LOSS : 0.17062
110 / 500 :: 7040 / 15539 - CLASS_LOSS : 0.23716
110 / 500 :: 7680 / 15539 - CLASS_LOSS : 0.20665
110 / 500 :: 8320 / 15539 - CLASS_LOSS : 0.21356
110 / 500 :: 8960 / 15539 - CLASS_LOSS : 0.18531
110 / 500 :: 9600 / 15539 - CLASS_LOSS : 0.21243
110 / 500 :: 10240 / 15539 - CLASS_LOSS : 0.16126
110 / 500 :: 10880 / 15539 - CLASS_LOSS : 0.19161
110 / 500 :: 11520 / 15539 - CLASS_LOSS : 0.16855
110 / 500 :: 12160 / 15539 - CLASS_LOSS : 0.17986
110 / 500 :: 12800 / 15539 - CLASS_LOSS : 0.25555
110 / 500 :: 13440 / 15539 - CLASS_LOSS : 0.25781
110 / 500 :: 14080 / 15539 - CLASS_LOSS : 0.12922
110 / 500 :: 14720 / 15539 - CLASS_LOSS : 0.14482
110 / 500 :: 15360 / 15539 - CLASS_LOSS : 0.15419
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.503764721024519 0.41195272111032455 0.35055022845742967
PSPrecision@1,3,5: 0.3630763590468011 0.38640517025847065 0.40157675472813426
testing....
Precision@1,3,5: 0.42819637700183777 0.3475977946967708 0.29052244683644
PSPrecision@1,3,5: 0.25224679488344026 0.28011429246747976 0.2942982984565721
111 / 500 :: 448 / 15539 - CLASS_LOSS : 0.17091
111 / 500 :: 1088 / 15539 - CLASS_LOSS : 0.21373
111 / 500 :: 1728 / 15539 - CLASS_LOSS : 0.14265
111 / 500 :: 2368 / 15539 - CLASS_LOSS : 0.16518
111 / 500 :: 3008 / 15539 - CLASS_LOSS : 0.0864
111 / 500 :: 3648 / 15539 - CLASS_LOSS : 0.11488
111 / 500 :: 4288 / 15539 - CLASS_LOSS : 0.19897
111 / 500 :: 4928 / 15539 - CLASS_LOSS : 0.32415
111 / 500 :: 5568 / 15539 - CLASS_LOSS : 0.25579
111 / 500 :: 6208 / 15539 - CLASS_LOSS : 0.20565
111 / 500 :: 6848 / 15539 - CLASS_LOSS : 0.17236
111 / 500 :: 7488 / 15539 - CLASS_LOSS : 0.11437
111 / 500 :: 8128 / 15539 - CLASS_LOSS : 0.2541
111 / 500 :: 8768 / 15539 - CLASS_LOSS : 0.15176
111 / 500 :: 9408 / 15539 - CLASS_LOSS : 0.1259
111 / 500 :: 10048 / 15539 - CLASS_LOSS : 0.2314
111 / 500 :: 10688 / 15539 - CLASS_LOSS : 0.15648
111 / 500 :: 11328 / 15539 - CLASS_LOSS : 0.17834
111 / 500 :: 11968 / 15539 - CLASS_LOSS : 0.20739
111 / 500 :: 12608 / 15539 - CLASS_LOSS : 0.20068
111 / 500 :: 13248 / 15539 - CLASS_LOSS : 0.16889
111 / 500 :: 13888 / 15539 - CLASS_LOSS : 0.22163
111 / 500 :: 14528 / 15539 - CLASS_LOSS : 0.15324
111 / 500 :: 15168 / 15539 - CLASS_LOSS : 0.15353
112 / 500 :: 256 / 15539 - CLASS_LOSS : 0.21566
112 / 500 :: 896 / 15539 - CLASS_LOSS : 0.40217
112 / 500 :: 1536 / 15539 - CLASS_LOSS : 0.27434
112 / 500 :: 2176 / 15539 - CLASS_LOSS : 0.15439
112 / 500 :: 2816 / 15539 - CLASS_LOSS : 0.14697
112 / 500 :: 3456 / 15539 - CLASS_LOSS : 0.08713
112 / 500 :: 4096 / 15539 - CLASS_LOSS : 0.21576
112 / 500 :: 4736 / 15539 - CLASS_LOSS : 0.12971
112 / 500 :: 5376 / 15539 - CLASS_LOSS : 0.22864
112 / 500 :: 6016 / 15539 - CLASS_LOSS : 0.08962
112 / 500 :: 6656 / 15539 - CLASS_LOSS : 0.12805
112 / 500 :: 7296 / 15539 - CLASS_LOSS : 0.11838
112 / 500 :: 7936 / 15539 - CLASS_LOSS : 0.17671
112 / 500 :: 8576 / 15539 - CLASS_LOSS : 0.16579
112 / 500 :: 9216 / 15539 - CLASS_LOSS : 0.26675
112 / 500 :: 9856 / 15539 - CLASS_LOSS : 0.15228
112 / 500 :: 10496 / 15539 - CLASS_LOSS : 0.20347
112 / 500 :: 11136 / 15539 - CLASS_LOSS : 0.27
112 / 500 :: 11776 / 15539 - CLASS_LOSS : 0.1812
112 / 500 :: 12416 / 15539 - CLASS_LOSS : 0.11536
112 / 500 :: 13056 / 15539 - CLASS_LOSS : 0.14129
112 / 500 :: 13696 / 15539 - CLASS_LOSS : 0.20983
112 / 500 :: 14336 / 15539 - CLASS_LOSS : 0.19661
112 / 500 :: 14976 / 15539 - CLASS_LOSS : 0.26558
113 / 500 :: 64 / 15539 - CLASS_LOSS : 0.17955
113 / 500 :: 704 / 15539 - CLASS_LOSS : 0.13453
113 / 500 :: 1344 / 15539 - CLASS_LOSS : 0.1495
113 / 500 :: 1984 / 15539 - CLASS_LOSS : 0.21069
113 / 500 :: 2624 / 15539 - CLASS_LOSS : 0.21493
113 / 500 :: 3264 / 15539 - CLASS_LOSS : 0.157
113 / 500 :: 3904 / 15539 - CLASS_LOSS : 0.18987
113 / 500 :: 4544 / 15539 - CLASS_LOSS : 0.16138
113 / 500 :: 5184 / 15539 - CLASS_LOSS : 0.14422
113 / 500 :: 5824 / 15539 - CLASS_LOSS : 0.2314
113 / 500 :: 6464 / 15539 - CLASS_LOSS : 0.17755
113 / 500 :: 7104 / 15539 - CLASS_LOSS : 0.19325
113 / 500 :: 7744 / 15539 - CLASS_LOSS : 0.22143
113 / 500 :: 8384 / 15539 - CLASS_LOSS : 0.13599
113 / 500 :: 9024 / 15539 - CLASS_LOSS : 0.1618
113 / 500 :: 9664 / 15539 - CLASS_LOSS : 0.19316
113 / 500 :: 10304 / 15539 - CLASS_LOSS : 0.27254
113 / 500 :: 10944 / 15539 - CLASS_LOSS : 0.13154
113 / 500 :: 11584 / 15539 - CLASS_LOSS : 0.22853
113 / 500 :: 12224 / 15539 - CLASS_LOSS : 0.14435
113 / 500 :: 12864 / 15539 - CLASS_LOSS : 0.17457
113 / 500 :: 13504 / 15539 - CLASS_LOSS : 0.11934
113 / 500 :: 14144 / 15539 - CLASS_LOSS : 0.16927
113 / 500 :: 14784 / 15539 - CLASS_LOSS : 0.21201
113 / 500 :: 15424 / 15539 - CLASS_LOSS : 0.226
114 / 500 :: 512 / 15539 - CLASS_LOSS : 0.1421
114 / 500 :: 1152 / 15539 - CLASS_LOSS : 0.1356
114 / 500 :: 1792 / 15539 - CLASS_LOSS : 0.27963
114 / 500 :: 2432 / 15539 - CLASS_LOSS : 0.12945
114 / 500 :: 3072 / 15539 - CLASS_LOSS : 0.12638
114 / 500 :: 3712 / 15539 - CLASS_LOSS : 0.18304
114 / 500 :: 4352 / 15539 - CLASS_LOSS : 0.16992
114 / 500 :: 4992 / 15539 - CLASS_LOSS : 0.24684
114 / 500 :: 5632 / 15539 - CLASS_LOSS : 0.18889
114 / 500 :: 6272 / 15539 - CLASS_LOSS : 0.24261
114 / 500 :: 6912 / 15539 - CLASS_LOSS : 0.20529
114 / 500 :: 7552 / 15539 - CLASS_LOSS : 0.21601
114 / 500 :: 8192 / 15539 - CLASS_LOSS : 0.24617
114 / 500 :: 8832 / 15539 - CLASS_LOSS : 0.14729
114 / 500 :: 9472 / 15539 - CLASS_LOSS : 0.15316
114 / 500 :: 10112 / 15539 - CLASS_LOSS : 0.14103
114 / 500 :: 10752 / 15539 - CLASS_LOSS : 0.50248
114 / 500 :: 11392 / 15539 - CLASS_LOSS : 0.19272
114 / 500 :: 12032 / 15539 - CLASS_LOSS : 0.31393
114 / 500 :: 12672 / 15539 - CLASS_LOSS : 0.20904
114 / 500 :: 13312 / 15539 - CLASS_LOSS : 0.26948
114 / 500 :: 13952 / 15539 - CLASS_LOSS : 0.10956
114 / 500 :: 14592 / 15539 - CLASS_LOSS : 0.23945
114 / 500 :: 15232 / 15539 - CLASS_LOSS : 0.20756
115 / 500 :: 320 / 15539 - CLASS_LOSS : 0.17521
115 / 500 :: 960 / 15539 - CLASS_LOSS : 0.1517
115 / 500 :: 1600 / 15539 - CLASS_LOSS : 0.14679
115 / 500 :: 2240 / 15539 - CLASS_LOSS : 0.21003
115 / 500 :: 2880 / 15539 - CLASS_LOSS : 0.18315
115 / 500 :: 3520 / 15539 - CLASS_LOSS : 0.2165
115 / 500 :: 4160 / 15539 - CLASS_LOSS : 0.23815
115 / 500 :: 4800 / 15539 - CLASS_LOSS : 0.18635
115 / 500 :: 5440 / 15539 - CLASS_LOSS : 0.08917
115 / 500 :: 6080 / 15539 - CLASS_LOSS : 0.25895
115 / 500 :: 6720 / 15539 - CLASS_LOSS : 0.21937
115 / 500 :: 7360 / 15539 - CLASS_LOSS : 0.09592
115 / 500 :: 8000 / 15539 - CLASS_LOSS : 0.25513
115 / 500 :: 8640 / 15539 - CLASS_LOSS : 0.25008
115 / 500 :: 9280 / 15539 - CLASS_LOSS : 0.11896
115 / 500 :: 9920 / 15539 - CLASS_LOSS : 0.16424
115 / 500 :: 10560 / 15539 - CLASS_LOSS : 0.21086
115 / 500 :: 11200 / 15539 - CLASS_LOSS : 0.13623
115 / 500 :: 11840 / 15539 - CLASS_LOSS : 0.13992
115 / 500 :: 12480 / 15539 - CLASS_LOSS : 0.18712
115 / 500 :: 13120 / 15539 - CLASS_LOSS : 0.19207
115 / 500 :: 13760 / 15539 - CLASS_LOSS : 0.1564
115 / 500 :: 14400 / 15539 - CLASS_LOSS : 0.15465
115 / 500 :: 15040 / 15539 - CLASS_LOSS : 0.11605
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.5069180770963383 0.4116738528862861 0.34645730098461935
PSPrecision@1,3,5: 0.3669290814237725 0.38645074308337324 0.40032194777351615
testing....
Precision@1,3,5: 0.43423470727224994 0.3418220005250722 0.2860068259385666
PSPrecision@1,3,5: 0.2552280453008423 0.27551115854307373 0.2907654042033922
116 / 500 :: 128 / 15539 - CLASS_LOSS : 0.12782
116 / 500 :: 768 / 15539 - CLASS_LOSS : 0.23089
116 / 500 :: 1408 / 15539 - CLASS_LOSS : 0.33423
116 / 500 :: 2048 / 15539 - CLASS_LOSS : 0.1624
116 / 500 :: 2688 / 15539 - CLASS_LOSS : 0.15619
116 / 500 :: 3328 / 15539 - CLASS_LOSS : 0.17283
116 / 500 :: 3968 / 15539 - CLASS_LOSS : 0.19531
116 / 500 :: 4608 / 15539 - CLASS_LOSS : 0.20642
116 / 500 :: 5248 / 15539 - CLASS_LOSS : 0.10405
116 / 500 :: 5888 / 15539 - CLASS_LOSS : 0.21891
116 / 500 :: 6528 / 15539 - CLASS_LOSS : 0.2491
116 / 500 :: 7168 / 15539 - CLASS_LOSS : 0.22289
116 / 500 :: 7808 / 15539 - CLASS_LOSS : 0.1995
116 / 500 :: 8448 / 15539 - CLASS_LOSS : 0.16362
116 / 500 :: 9088 / 15539 - CLASS_LOSS : 0.21244
116 / 500 :: 9728 / 15539 - CLASS_LOSS : 0.18262
116 / 500 :: 10368 / 15539 - CLASS_LOSS : 0.19162
116 / 500 :: 11008 / 15539 - CLASS_LOSS : 0.13925
116 / 500 :: 11648 / 15539 - CLASS_LOSS : 0.17385
116 / 500 :: 12288 / 15539 - CLASS_LOSS : 0.14439
116 / 500 :: 12928 / 15539 - CLASS_LOSS : 0.24714
116 / 500 :: 13568 / 15539 - CLASS_LOSS : 0.09547
116 / 500 :: 14208 / 15539 - CLASS_LOSS : 0.14422
116 / 500 :: 14848 / 15539 - CLASS_LOSS : 0.17926
116 / 500 :: 15488 / 15539 - CLASS_LOSS : 0.16574
117 / 500 :: 576 / 15539 - CLASS_LOSS : 0.17178
117 / 500 :: 1216 / 15539 - CLASS_LOSS : 0.10561
117 / 500 :: 1856 / 15539 - CLASS_LOSS : 0.20244
117 / 500 :: 2496 / 15539 - CLASS_LOSS : 0.23738
117 / 500 :: 3136 / 15539 - CLASS_LOSS : 0.14909
117 / 500 :: 3776 / 15539 - CLASS_LOSS : 0.17759
117 / 500 :: 4416 / 15539 - CLASS_LOSS : 0.17213
117 / 500 :: 5056 / 15539 - CLASS_LOSS : 0.06121
117 / 500 :: 5696 / 15539 - CLASS_LOSS : 0.17788
117 / 500 :: 6336 / 15539 - CLASS_LOSS : 0.20909
117 / 500 :: 6976 / 15539 - CLASS_LOSS : 0.21949
117 / 500 :: 7616 / 15539 - CLASS_LOSS : 0.12276
117 / 500 :: 8256 / 15539 - CLASS_LOSS : 0.21175
117 / 500 :: 8896 / 15539 - CLASS_LOSS : 0.13345
117 / 500 :: 9536 / 15539 - CLASS_LOSS : 0.15438
117 / 500 :: 10176 / 15539 - CLASS_LOSS : 0.20277
117 / 500 :: 10816 / 15539 - CLASS_LOSS : 0.14922
117 / 500 :: 11456 / 15539 - CLASS_LOSS : 0.19056
117 / 500 :: 12096 / 15539 - CLASS_LOSS : 0.11779
117 / 500 :: 12736 / 15539 - CLASS_LOSS : 0.14131
117 / 500 :: 13376 / 15539 - CLASS_LOSS : 0.20057
117 / 500 :: 14016 / 15539 - CLASS_LOSS : 0.17187
117 / 500 :: 14656 / 15539 - CLASS_LOSS : 0.14946
117 / 500 :: 15296 / 15539 - CLASS_LOSS : 0.1788
118 / 500 :: 384 / 15539 - CLASS_LOSS : 0.21407
118 / 500 :: 1024 / 15539 - CLASS_LOSS : 0.14762
118 / 500 :: 1664 / 15539 - CLASS_LOSS : 0.15362
118 / 500 :: 2304 / 15539 - CLASS_LOSS : 0.09633
118 / 500 :: 2944 / 15539 - CLASS_LOSS : 0.27542
118 / 500 :: 3584 / 15539 - CLASS_LOSS : 0.08339
118 / 500 :: 4224 / 15539 - CLASS_LOSS : 0.11232
118 / 500 :: 4864 / 15539 - CLASS_LOSS : 0.1175
118 / 500 :: 5504 / 15539 - CLASS_LOSS : 0.20085
118 / 500 :: 6144 / 15539 - CLASS_LOSS : 0.16857
118 / 500 :: 6784 / 15539 - CLASS_LOSS : 0.17121
118 / 500 :: 7424 / 15539 - CLASS_LOSS : 0.1215
118 / 500 :: 8064 / 15539 - CLASS_LOSS : 0.14296
118 / 500 :: 8704 / 15539 - CLASS_LOSS : 0.2266
118 / 500 :: 9344 / 15539 - CLASS_LOSS : 0.25561
118 / 500 :: 9984 / 15539 - CLASS_LOSS : 0.2101
118 / 500 :: 10624 / 15539 - CLASS_LOSS : 0.18579
118 / 500 :: 11264 / 15539 - CLASS_LOSS : 0.12916
118 / 500 :: 11904 / 15539 - CLASS_LOSS : 0.15336
118 / 500 :: 12544 / 15539 - CLASS_LOSS : 0.20947
118 / 500 :: 13184 / 15539 - CLASS_LOSS : 0.22613
118 / 500 :: 13824 / 15539 - CLASS_LOSS : 0.2002
118 / 500 :: 14464 / 15539 - CLASS_LOSS : 0.14254
118 / 500 :: 15104 / 15539 - CLASS_LOSS : 0.13189
119 / 500 :: 192 / 15539 - CLASS_LOSS : 0.13249
119 / 500 :: 832 / 15539 - CLASS_LOSS : 0.24093
119 / 500 :: 1472 / 15539 - CLASS_LOSS : 0.1408
119 / 500 :: 2112 / 15539 - CLASS_LOSS : 0.06497
119 / 500 :: 2752 / 15539 - CLASS_LOSS : 0.13857
119 / 500 :: 3392 / 15539 - CLASS_LOSS : 0.15265
119 / 500 :: 4032 / 15539 - CLASS_LOSS : 0.18845
119 / 500 :: 4672 / 15539 - CLASS_LOSS : 0.17493
119 / 500 :: 5312 / 15539 - CLASS_LOSS : 0.21605
119 / 500 :: 5952 / 15539 - CLASS_LOSS : 0.2347
119 / 500 :: 6592 / 15539 - CLASS_LOSS : 0.10621
119 / 500 :: 7232 / 15539 - CLASS_LOSS : 0.2446
119 / 500 :: 7872 / 15539 - CLASS_LOSS : 0.26168
119 / 500 :: 8512 / 15539 - CLASS_LOSS : 0.2074
119 / 500 :: 9152 / 15539 - CLASS_LOSS : 0.10206
119 / 500 :: 9792 / 15539 - CLASS_LOSS : 0.30491
119 / 500 :: 10432 / 15539 - CLASS_LOSS : 0.22119
119 / 500 :: 11072 / 15539 - CLASS_LOSS : 0.17051
119 / 500 :: 11712 / 15539 - CLASS_LOSS : 0.23451
119 / 500 :: 12352 / 15539 - CLASS_LOSS : 0.16237
119 / 500 :: 12992 / 15539 - CLASS_LOSS : 0.17121
119 / 500 :: 13632 / 15539 - CLASS_LOSS : 0.16473
119 / 500 :: 14272 / 15539 - CLASS_LOSS : 0.13435
119 / 500 :: 14912 / 15539 - CLASS_LOSS : 0.1622
119 / 500 :: 15539 / 15539 - CLASS_LOSS : 0.27984
120 / 500 :: 640 / 15539 - CLASS_LOSS : 0.2029
120 / 500 :: 1280 / 15539 - CLASS_LOSS : 0.21905
120 / 500 :: 1920 / 15539 - CLASS_LOSS : 0.12461
120 / 500 :: 2560 / 15539 - CLASS_LOSS : 0.12304
120 / 500 :: 3200 / 15539 - CLASS_LOSS : 0.1084
120 / 500 :: 3840 / 15539 - CLASS_LOSS : 0.21116
120 / 500 :: 4480 / 15539 - CLASS_LOSS : 0.15974
120 / 500 :: 5120 / 15539 - CLASS_LOSS : 0.05408
120 / 500 :: 5760 / 15539 - CLASS_LOSS : 0.17506
120 / 500 :: 6400 / 15539 - CLASS_LOSS : 0.21564
120 / 500 :: 7040 / 15539 - CLASS_LOSS : 0.19263
120 / 500 :: 7680 / 15539 - CLASS_LOSS : 0.14767
120 / 500 :: 8320 / 15539 - CLASS_LOSS : 0.21132
120 / 500 :: 8960 / 15539 - CLASS_LOSS : 0.22249
120 / 500 :: 9600 / 15539 - CLASS_LOSS : 0.15766
120 / 500 :: 10240 / 15539 - CLASS_LOSS : 0.14137
120 / 500 :: 10880 / 15539 - CLASS_LOSS : 0.20532
120 / 500 :: 11520 / 15539 - CLASS_LOSS : 0.13747
120 / 500 :: 12160 / 15539 - CLASS_LOSS : 0.20256
120 / 500 :: 12800 / 15539 - CLASS_LOSS : 0.09947
120 / 500 :: 13440 / 15539 - CLASS_LOSS : 0.12555
120 / 500 :: 14080 / 15539 - CLASS_LOSS : 0.21109
120 / 500 :: 14720 / 15539 - CLASS_LOSS : 0.14225
120 / 500 :: 15360 / 15539 - CLASS_LOSS : 0.11598
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.4977154257030697 0.40839178840337215 0.347744385095566
PSPrecision@1,3,5: 0.3614970179364751 0.3859892732766863 0.4025603627397722
testing....
Precision@1,3,5: 0.43318456287739565 0.3406843440973134 0.28626936203728015
PSPrecision@1,3,5: 0.25791484726893354 0.27780228914173755 0.2912053813276931
121 / 500 :: 448 / 15539 - CLASS_LOSS : 0.28094
121 / 500 :: 1088 / 15539 - CLASS_LOSS : 0.17075
121 / 500 :: 1728 / 15539 - CLASS_LOSS : 0.17777
121 / 500 :: 2368 / 15539 - CLASS_LOSS : 0.13308
121 / 500 :: 3008 / 15539 - CLASS_LOSS : 0.10004
121 / 500 :: 3648 / 15539 - CLASS_LOSS : 0.17529
121 / 500 :: 4288 / 15539 - CLASS_LOSS : 0.22646
121 / 500 :: 4928 / 15539 - CLASS_LOSS : 0.20527
121 / 500 :: 5568 / 15539 - CLASS_LOSS : 0.17525
121 / 500 :: 6208 / 15539 - CLASS_LOSS : 0.16112
121 / 500 :: 6848 / 15539 - CLASS_LOSS : 0.13682
121 / 500 :: 7488 / 15539 - CLASS_LOSS : 0.22052
121 / 500 :: 8128 / 15539 - CLASS_LOSS : 0.14386
121 / 500 :: 8768 / 15539 - CLASS_LOSS : 0.20718
121 / 500 :: 9408 / 15539 - CLASS_LOSS : 0.22777
121 / 500 :: 10048 / 15539 - CLASS_LOSS : 0.14412
121 / 500 :: 10688 / 15539 - CLASS_LOSS : 0.1919
121 / 500 :: 11328 / 15539 - CLASS_LOSS : 0.20825
121 / 500 :: 11968 / 15539 - CLASS_LOSS : 0.18603
121 / 500 :: 12608 / 15539 - CLASS_LOSS : 0.14127
121 / 500 :: 13248 / 15539 - CLASS_LOSS : 0.18101
121 / 500 :: 13888 / 15539 - CLASS_LOSS : 0.20265
121 / 500 :: 14528 / 15539 - CLASS_LOSS : 0.15492
121 / 500 :: 15168 / 15539 - CLASS_LOSS : 0.21881
122 / 500 :: 256 / 15539 - CLASS_LOSS : 0.17122
122 / 500 :: 896 / 15539 - CLASS_LOSS : 0.22045
122 / 500 :: 1536 / 15539 - CLASS_LOSS : 0.15521
122 / 500 :: 2176 / 15539 - CLASS_LOSS : 0.12153
122 / 500 :: 2816 / 15539 - CLASS_LOSS : 0.21565
122 / 500 :: 3456 / 15539 - CLASS_LOSS : 0.13076
122 / 500 :: 4096 / 15539 - CLASS_LOSS : 0.23067
122 / 500 :: 4736 / 15539 - CLASS_LOSS : 0.22775
122 / 500 :: 5376 / 15539 - CLASS_LOSS : 0.21351
122 / 500 :: 6016 / 15539 - CLASS_LOSS : 0.19607
122 / 500 :: 6656 / 15539 - CLASS_LOSS : 0.15204
122 / 500 :: 7296 / 15539 - CLASS_LOSS : 0.17431
122 / 500 :: 7936 / 15539 - CLASS_LOSS : 0.15698
122 / 500 :: 8576 / 15539 - CLASS_LOSS : 0.11307
122 / 500 :: 9216 / 15539 - CLASS_LOSS : 0.27184
122 / 500 :: 9856 / 15539 - CLASS_LOSS : 0.17799
122 / 500 :: 10496 / 15539 - CLASS_LOSS : 0.1183
122 / 500 :: 11136 / 15539 - CLASS_LOSS : 0.13625
122 / 500 :: 11776 / 15539 - CLASS_LOSS : 0.189
122 / 500 :: 12416 / 15539 - CLASS_LOSS : 0.25483
122 / 500 :: 13056 / 15539 - CLASS_LOSS : 0.21991
122 / 500 :: 13696 / 15539 - CLASS_LOSS : 0.15132
122 / 500 :: 14336 / 15539 - CLASS_LOSS : 0.13739
122 / 500 :: 14976 / 15539 - CLASS_LOSS : 0.1343
123 / 500 :: 64 / 15539 - CLASS_LOSS : 0.15201
123 / 500 :: 704 / 15539 - CLASS_LOSS : 0.18285
123 / 500 :: 1344 / 15539 - CLASS_LOSS : 0.14357
123 / 500 :: 1984 / 15539 - CLASS_LOSS : 0.28576
123 / 500 :: 2624 / 15539 - CLASS_LOSS : 0.10004
123 / 500 :: 3264 / 15539 - CLASS_LOSS : 0.13958
123 / 500 :: 3904 / 15539 - CLASS_LOSS : 0.16273
123 / 500 :: 4544 / 15539 - CLASS_LOSS : 0.19373
123 / 500 :: 5184 / 15539 - CLASS_LOSS : 0.22649
123 / 500 :: 5824 / 15539 - CLASS_LOSS : 0.19711
123 / 500 :: 6464 / 15539 - CLASS_LOSS : 0.196
123 / 500 :: 7104 / 15539 - CLASS_LOSS : 0.14559
123 / 500 :: 7744 / 15539 - CLASS_LOSS : 0.11354
123 / 500 :: 8384 / 15539 - CLASS_LOSS : 0.22461
123 / 500 :: 9024 / 15539 - CLASS_LOSS : 0.18369
123 / 500 :: 9664 / 15539 - CLASS_LOSS : 0.15719
123 / 500 :: 10304 / 15539 - CLASS_LOSS : 0.1163
123 / 500 :: 10944 / 15539 - CLASS_LOSS : 0.18379
123 / 500 :: 11584 / 15539 - CLASS_LOSS : 0.10533
123 / 500 :: 12224 / 15539 - CLASS_LOSS : 0.17618
123 / 500 :: 12864 / 15539 - CLASS_LOSS : 0.13288
123 / 500 :: 13504 / 15539 - CLASS_LOSS : 0.26495
123 / 500 :: 14144 / 15539 - CLASS_LOSS : 0.18681
123 / 500 :: 14784 / 15539 - CLASS_LOSS : 0.14985
123 / 500 :: 15424 / 15539 - CLASS_LOSS : 0.11638
124 / 500 :: 512 / 15539 - CLASS_LOSS : 0.23897
124 / 500 :: 1152 / 15539 - CLASS_LOSS : 0.18224
124 / 500 :: 1792 / 15539 - CLASS_LOSS : 0.15613
124 / 500 :: 2432 / 15539 - CLASS_LOSS : 0.17292
124 / 500 :: 3072 / 15539 - CLASS_LOSS : 0.22152
124 / 500 :: 3712 / 15539 - CLASS_LOSS : 0.15694
124 / 500 :: 4352 / 15539 - CLASS_LOSS : 0.09466
124 / 500 :: 4992 / 15539 - CLASS_LOSS : 0.16476
124 / 500 :: 5632 / 15539 - CLASS_LOSS : 0.15403
124 / 500 :: 6272 / 15539 - CLASS_LOSS : 0.10797
124 / 500 :: 6912 / 15539 - CLASS_LOSS : 0.17416
124 / 500 :: 7552 / 15539 - CLASS_LOSS : 0.1133
124 / 500 :: 8192 / 15539 - CLASS_LOSS : 0.08239
124 / 500 :: 8832 / 15539 - CLASS_LOSS : 0.13479
124 / 500 :: 9472 / 15539 - CLASS_LOSS : 0.24895
124 / 500 :: 10112 / 15539 - CLASS_LOSS : 0.17602
124 / 500 :: 10752 / 15539 - CLASS_LOSS : 0.18601
124 / 500 :: 11392 / 15539 - CLASS_LOSS : 0.20342
124 / 500 :: 12032 / 15539 - CLASS_LOSS : 0.25612
124 / 500 :: 12672 / 15539 - CLASS_LOSS : 0.16873
124 / 500 :: 13312 / 15539 - CLASS_LOSS : 0.12181
124 / 500 :: 13952 / 15539 - CLASS_LOSS : 0.18428
124 / 500 :: 14592 / 15539 - CLASS_LOSS : 0.24727
124 / 500 :: 15232 / 15539 - CLASS_LOSS : 0.22235
125 / 500 :: 320 / 15539 - CLASS_LOSS : 0.12286
125 / 500 :: 960 / 15539 - CLASS_LOSS : 0.192
125 / 500 :: 1600 / 15539 - CLASS_LOSS : 0.1818
125 / 500 :: 2240 / 15539 - CLASS_LOSS : 0.23723
125 / 500 :: 2880 / 15539 - CLASS_LOSS : 0.12772
125 / 500 :: 3520 / 15539 - CLASS_LOSS : 0.13169
125 / 500 :: 4160 / 15539 - CLASS_LOSS : 0.09398
125 / 500 :: 4800 / 15539 - CLASS_LOSS : 0.22696
125 / 500 :: 5440 / 15539 - CLASS_LOSS : 0.27901
125 / 500 :: 6080 / 15539 - CLASS_LOSS : 0.13703
125 / 500 :: 6720 / 15539 - CLASS_LOSS : 0.34089
125 / 500 :: 7360 / 15539 - CLASS_LOSS : 0.21628
125 / 500 :: 8000 / 15539 - CLASS_LOSS : 0.18807
125 / 500 :: 8640 / 15539 - CLASS_LOSS : 0.13955
125 / 500 :: 9280 / 15539 - CLASS_LOSS : 0.33156
125 / 500 :: 9920 / 15539 - CLASS_LOSS : 0.18172
125 / 500 :: 10560 / 15539 - CLASS_LOSS : 0.1712
125 / 500 :: 11200 / 15539 - CLASS_LOSS : 0.22242
125 / 500 :: 11840 / 15539 - CLASS_LOSS : 0.13745
125 / 500 :: 12480 / 15539 - CLASS_LOSS : 0.16001
125 / 500 :: 13120 / 15539 - CLASS_LOSS : 0.25223
125 / 500 :: 13760 / 15539 - CLASS_LOSS : 0.22776
125 / 500 :: 14400 / 15539 - CLASS_LOSS : 0.16406
125 / 500 :: 15040 / 15539 - CLASS_LOSS : 0.23735
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.49121565094278913 0.40955016410322415 0.3488126649076517
PSPrecision@1,3,5: 0.35913296203777384 0.3853245598830969 0.40311372888457403
testing....
Precision@1,3,5: 0.43318456287739565 0.34120941629474055 0.28632186925702285
PSPrecision@1,3,5: 0.2576469296522631 0.2781675161215236 0.2910882575933783
126 / 500 :: 128 / 15539 - CLASS_LOSS : 0.21606
126 / 500 :: 768 / 15539 - CLASS_LOSS : 0.22181
126 / 500 :: 1408 / 15539 - CLASS_LOSS : 0.3382
126 / 500 :: 2048 / 15539 - CLASS_LOSS : 0.17913
126 / 500 :: 2688 / 15539 - CLASS_LOSS : 0.12923
126 / 500 :: 3328 / 15539 - CLASS_LOSS : 0.23633
126 / 500 :: 3968 / 15539 - CLASS_LOSS : 0.21807
126 / 500 :: 4608 / 15539 - CLASS_LOSS : 0.15415
126 / 500 :: 5248 / 15539 - CLASS_LOSS : 0.16672
126 / 500 :: 5888 / 15539 - CLASS_LOSS : 0.12073
126 / 500 :: 6528 / 15539 - CLASS_LOSS : 0.21121
126 / 500 :: 7168 / 15539 - CLASS_LOSS : 0.19979
126 / 500 :: 7808 / 15539 - CLASS_LOSS : 0.16628
126 / 500 :: 8448 / 15539 - CLASS_LOSS : 0.10452
126 / 500 :: 9088 / 15539 - CLASS_LOSS : 0.13917
126 / 500 :: 9728 / 15539 - CLASS_LOSS : 0.18092
126 / 500 :: 10368 / 15539 - CLASS_LOSS : 0.15656
126 / 500 :: 11008 / 15539 - CLASS_LOSS : 0.14033
126 / 500 :: 11648 / 15539 - CLASS_LOSS : 0.1722
126 / 500 :: 12288 / 15539 - CLASS_LOSS : 0.15523
126 / 500 :: 12928 / 15539 - CLASS_LOSS : 0.16152
126 / 500 :: 13568 / 15539 - CLASS_LOSS : 0.10519
126 / 500 :: 14208 / 15539 - CLASS_LOSS : 0.21572
126 / 500 :: 14848 / 15539 - CLASS_LOSS : 0.25397
126 / 500 :: 15488 / 15539 - CLASS_LOSS : 0.11712
127 / 500 :: 576 / 15539 - CLASS_LOSS : 0.13794
127 / 500 :: 1216 / 15539 - CLASS_LOSS : 0.16941
127 / 500 :: 1856 / 15539 - CLASS_LOSS : 0.21573
127 / 500 :: 2496 / 15539 - CLASS_LOSS : 0.15128
127 / 500 :: 3136 / 15539 - CLASS_LOSS : 0.13728
127 / 500 :: 3776 / 15539 - CLASS_LOSS : 0.19797
127 / 500 :: 4416 / 15539 - CLASS_LOSS : 0.33219
127 / 500 :: 5056 / 15539 - CLASS_LOSS : 0.12018
127 / 500 :: 5696 / 15539 - CLASS_LOSS : 0.07836
127 / 500 :: 6336 / 15539 - CLASS_LOSS : 0.13922
127 / 500 :: 6976 / 15539 - CLASS_LOSS : 0.22739
127 / 500 :: 7616 / 15539 - CLASS_LOSS : 0.12769
127 / 500 :: 8256 / 15539 - CLASS_LOSS : 0.25251
127 / 500 :: 8896 / 15539 - CLASS_LOSS : 0.14389
127 / 500 :: 9536 / 15539 - CLASS_LOSS : 0.14789
127 / 500 :: 10176 / 15539 - CLASS_LOSS : 0.126
127 / 500 :: 10816 / 15539 - CLASS_LOSS : 0.08692
127 / 500 :: 11456 / 15539 - CLASS_LOSS : 0.1879
127 / 500 :: 12096 / 15539 - CLASS_LOSS : 0.18553
127 / 500 :: 12736 / 15539 - CLASS_LOSS : 0.22884
127 / 500 :: 13376 / 15539 - CLASS_LOSS : 0.23999
127 / 500 :: 14016 / 15539 - CLASS_LOSS : 0.1668
127 / 500 :: 14656 / 15539 - CLASS_LOSS : 0.18066
127 / 500 :: 15296 / 15539 - CLASS_LOSS : 0.15826
128 / 500 :: 384 / 15539 - CLASS_LOSS : 0.17463
128 / 500 :: 1024 / 15539 - CLASS_LOSS : 0.22173
128 / 500 :: 1664 / 15539 - CLASS_LOSS : 0.24709
128 / 500 :: 2304 / 15539 - CLASS_LOSS : 0.17727
128 / 500 :: 2944 / 15539 - CLASS_LOSS : 0.26714
128 / 500 :: 3584 / 15539 - CLASS_LOSS : 0.16296
128 / 500 :: 4224 / 15539 - CLASS_LOSS : 0.19139
128 / 500 :: 4864 / 15539 - CLASS_LOSS : 0.12985
128 / 500 :: 5504 / 15539 - CLASS_LOSS : 0.11406
128 / 500 :: 6144 / 15539 - CLASS_LOSS : 0.13767
128 / 500 :: 6784 / 15539 - CLASS_LOSS : 0.15069
128 / 500 :: 7424 / 15539 - CLASS_LOSS : 0.18371
128 / 500 :: 8064 / 15539 - CLASS_LOSS : 0.19306
128 / 500 :: 8704 / 15539 - CLASS_LOSS : 0.13226
128 / 500 :: 9344 / 15539 - CLASS_LOSS : 0.20067
128 / 500 :: 9984 / 15539 - CLASS_LOSS : 0.10069
128 / 500 :: 10624 / 15539 - CLASS_LOSS : 0.21046
128 / 500 :: 11264 / 15539 - CLASS_LOSS : 0.16022
128 / 500 :: 11904 / 15539 - CLASS_LOSS : 0.17404
128 / 500 :: 12544 / 15539 - CLASS_LOSS : 0.1484
128 / 500 :: 13184 / 15539 - CLASS_LOSS : 0.11618
128 / 500 :: 13824 / 15539 - CLASS_LOSS : 0.15626
128 / 500 :: 14464 / 15539 - CLASS_LOSS : 0.15151
128 / 500 :: 15104 / 15539 - CLASS_LOSS : 0.15793
129 / 500 :: 192 / 15539 - CLASS_LOSS : 0.23397
129 / 500 :: 832 / 15539 - CLASS_LOSS : 0.15955
129 / 500 :: 1472 / 15539 - CLASS_LOSS : 0.36006
129 / 500 :: 2112 / 15539 - CLASS_LOSS : 0.15154
129 / 500 :: 2752 / 15539 - CLASS_LOSS : 0.15004
129 / 500 :: 3392 / 15539 - CLASS_LOSS : 0.09006
129 / 500 :: 4032 / 15539 - CLASS_LOSS : 0.24127
129 / 500 :: 4672 / 15539 - CLASS_LOSS : 0.20515
129 / 500 :: 5312 / 15539 - CLASS_LOSS : 0.11283
129 / 500 :: 5952 / 15539 - CLASS_LOSS : 0.16872
129 / 500 :: 6592 / 15539 - CLASS_LOSS : 0.15849
129 / 500 :: 7232 / 15539 - CLASS_LOSS : 0.48052
129 / 500 :: 7872 / 15539 - CLASS_LOSS : 0.23856
129 / 500 :: 8512 / 15539 - CLASS_LOSS : 0.13668
129 / 500 :: 9152 / 15539 - CLASS_LOSS : 0.11641
129 / 500 :: 9792 / 15539 - CLASS_LOSS : 0.18521
129 / 500 :: 10432 / 15539 - CLASS_LOSS : 0.23871
129 / 500 :: 11072 / 15539 - CLASS_LOSS : 0.17554
129 / 500 :: 11712 / 15539 - CLASS_LOSS : 0.14395
129 / 500 :: 12352 / 15539 - CLASS_LOSS : 0.22487
129 / 500 :: 12992 / 15539 - CLASS_LOSS : 0.20201
129 / 500 :: 13632 / 15539 - CLASS_LOSS : 0.1126
129 / 500 :: 14272 / 15539 - CLASS_LOSS : 0.13767
129 / 500 :: 14912 / 15539 - CLASS_LOSS : 0.26348
129 / 500 :: 15539 / 15539 - CLASS_LOSS : 0.20755
130 / 500 :: 640 / 15539 - CLASS_LOSS : 0.23019
130 / 500 :: 1280 / 15539 - CLASS_LOSS : 0.11141
130 / 500 :: 1920 / 15539 - CLASS_LOSS : 0.13523
130 / 500 :: 2560 / 15539 - CLASS_LOSS : 0.2486
130 / 500 :: 3200 / 15539 - CLASS_LOSS : 0.09202
130 / 500 :: 3840 / 15539 - CLASS_LOSS : 0.13574
130 / 500 :: 4480 / 15539 - CLASS_LOSS : 0.13898
130 / 500 :: 5120 / 15539 - CLASS_LOSS : 0.11769
130 / 500 :: 5760 / 15539 - CLASS_LOSS : 0.14144
130 / 500 :: 6400 / 15539 - CLASS_LOSS : 0.16962
130 / 500 :: 7040 / 15539 - CLASS_LOSS : 0.1526
130 / 500 :: 7680 / 15539 - CLASS_LOSS : 0.16135
130 / 500 :: 8320 / 15539 - CLASS_LOSS : 0.08812
130 / 500 :: 8960 / 15539 - CLASS_LOSS : 0.20293
130 / 500 :: 9600 / 15539 - CLASS_LOSS : 0.13586
130 / 500 :: 10240 / 15539 - CLASS_LOSS : 0.13086
130 / 500 :: 10880 / 15539 - CLASS_LOSS : 0.19127
130 / 500 :: 11520 / 15539 - CLASS_LOSS : 0.22832
130 / 500 :: 12160 / 15539 - CLASS_LOSS : 0.19348
130 / 500 :: 12800 / 15539 - CLASS_LOSS : 0.16033
130 / 500 :: 13440 / 15539 - CLASS_LOSS : 0.18797
130 / 500 :: 14080 / 15539 - CLASS_LOSS : 0.16046
130 / 500 :: 14720 / 15539 - CLASS_LOSS : 0.196
130 / 500 :: 15360 / 15539 - CLASS_LOSS : 0.18663
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.5130960808288821 0.42585322950854837 0.36125876826050585
PSPrecision@1,3,5: 0.3714528466835988 0.3986999266402662 0.4155386330414134
testing....
Precision@1,3,5: 0.43817274875295353 0.34812286689419797 0.2955631399317406
PSPrecision@1,3,5: 0.2643169913879675 0.282496161102918 0.29752448923520414
131 / 500 :: 448 / 15539 - CLASS_LOSS : 0.21871
131 / 500 :: 1088 / 15539 - CLASS_LOSS : 0.19741
131 / 500 :: 1728 / 15539 - CLASS_LOSS : 0.12023
131 / 500 :: 2368 / 15539 - CLASS_LOSS : 0.2345
131 / 500 :: 3008 / 15539 - CLASS_LOSS : 0.23066
131 / 500 :: 3648 / 15539 - CLASS_LOSS : 0.17307
131 / 500 :: 4288 / 15539 - CLASS_LOSS : 0.17081
131 / 500 :: 4928 / 15539 - CLASS_LOSS : 0.21786
131 / 500 :: 5568 / 15539 - CLASS_LOSS : 0.25389
131 / 500 :: 6208 / 15539 - CLASS_LOSS : 0.14607
131 / 500 :: 6848 / 15539 - CLASS_LOSS : 0.18119
131 / 500 :: 7488 / 15539 - CLASS_LOSS : 0.26189
131 / 500 :: 8128 / 15539 - CLASS_LOSS : 0.16184
131 / 500 :: 8768 / 15539 - CLASS_LOSS : 0.15896
131 / 500 :: 9408 / 15539 - CLASS_LOSS : 0.15377
131 / 500 :: 10048 / 15539 - CLASS_LOSS : 0.19526
131 / 500 :: 10688 / 15539 - CLASS_LOSS : 0.14727
131 / 500 :: 11328 / 15539 - CLASS_LOSS : 0.20308
131 / 500 :: 11968 / 15539 - CLASS_LOSS : 0.14591
131 / 500 :: 12608 / 15539 - CLASS_LOSS : 0.15562
131 / 500 :: 13248 / 15539 - CLASS_LOSS : 0.1565
131 / 500 :: 13888 / 15539 - CLASS_LOSS : 0.20015
131 / 500 :: 14528 / 15539 - CLASS_LOSS : 0.24521
131 / 500 :: 15168 / 15539 - CLASS_LOSS : 0.17486
132 / 500 :: 256 / 15539 - CLASS_LOSS : 0.16853
132 / 500 :: 896 / 15539 - CLASS_LOSS : 0.1377
132 / 500 :: 1536 / 15539 - CLASS_LOSS : 0.18061
132 / 500 :: 2176 / 15539 - CLASS_LOSS : 0.17953
132 / 500 :: 2816 / 15539 - CLASS_LOSS : 0.23501
132 / 500 :: 3456 / 15539 - CLASS_LOSS : 0.14709
132 / 500 :: 4096 / 15539 - CLASS_LOSS : 0.1487
132 / 500 :: 4736 / 15539 - CLASS_LOSS : 0.1482
132 / 500 :: 5376 / 15539 - CLASS_LOSS : 0.11856
132 / 500 :: 6016 / 15539 - CLASS_LOSS : 0.16672
132 / 500 :: 6656 / 15539 - CLASS_LOSS : 0.14781
132 / 500 :: 7296 / 15539 - CLASS_LOSS : 0.12295
132 / 500 :: 7936 / 15539 - CLASS_LOSS : 0.15313
132 / 500 :: 8576 / 15539 - CLASS_LOSS : 0.09416
132 / 500 :: 9216 / 15539 - CLASS_LOSS : 0.22031
132 / 500 :: 9856 / 15539 - CLASS_LOSS : 0.19878
132 / 500 :: 10496 / 15539 - CLASS_LOSS : 0.14845
132 / 500 :: 11136 / 15539 - CLASS_LOSS : 0.2012
132 / 500 :: 11776 / 15539 - CLASS_LOSS : 0.15496
132 / 500 :: 12416 / 15539 - CLASS_LOSS : 0.15471
132 / 500 :: 13056 / 15539 - CLASS_LOSS : 0.14193
132 / 500 :: 13696 / 15539 - CLASS_LOSS : 0.22433
132 / 500 :: 14336 / 15539 - CLASS_LOSS : 0.27823
132 / 500 :: 14976 / 15539 - CLASS_LOSS : 0.1152
133 / 500 :: 64 / 15539 - CLASS_LOSS : 0.17998
133 / 500 :: 704 / 15539 - CLASS_LOSS : 0.10583
133 / 500 :: 1344 / 15539 - CLASS_LOSS : 0.13433
133 / 500 :: 1984 / 15539 - CLASS_LOSS : 0.18885
133 / 500 :: 2624 / 15539 - CLASS_LOSS : 0.28452
133 / 500 :: 3264 / 15539 - CLASS_LOSS : 0.18325
133 / 500 :: 3904 / 15539 - CLASS_LOSS : 0.13927
133 / 500 :: 4544 / 15539 - CLASS_LOSS : 0.1206
133 / 500 :: 5184 / 15539 - CLASS_LOSS : 0.14033
133 / 500 :: 5824 / 15539 - CLASS_LOSS : 0.13841
133 / 500 :: 6464 / 15539 - CLASS_LOSS : 0.19168
133 / 500 :: 7104 / 15539 - CLASS_LOSS : 0.23239
133 / 500 :: 7744 / 15539 - CLASS_LOSS : 0.21277
133 / 500 :: 8384 / 15539 - CLASS_LOSS : 0.13971
133 / 500 :: 9024 / 15539 - CLASS_LOSS : 0.13621
133 / 500 :: 9664 / 15539 - CLASS_LOSS : 0.18664
133 / 500 :: 10304 / 15539 - CLASS_LOSS : 0.14199
133 / 500 :: 10944 / 15539 - CLASS_LOSS : 0.13054
133 / 500 :: 11584 / 15539 - CLASS_LOSS : 0.17556
133 / 500 :: 12224 / 15539 - CLASS_LOSS : 0.14078
133 / 500 :: 12864 / 15539 - CLASS_LOSS : 0.17418
133 / 500 :: 13504 / 15539 - CLASS_LOSS : 0.19296
133 / 500 :: 14144 / 15539 - CLASS_LOSS : 0.12125
133 / 500 :: 14784 / 15539 - CLASS_LOSS : 0.21983
133 / 500 :: 15424 / 15539 - CLASS_LOSS : 0.18586
134 / 500 :: 512 / 15539 - CLASS_LOSS : 0.12432
134 / 500 :: 1152 / 15539 - CLASS_LOSS : 0.17298
134 / 500 :: 1792 / 15539 - CLASS_LOSS : 0.14949
134 / 500 :: 2432 / 15539 - CLASS_LOSS : 0.19436
134 / 500 :: 3072 / 15539 - CLASS_LOSS : 0.08421
134 / 500 :: 3712 / 15539 - CLASS_LOSS : 0.18893
134 / 500 :: 4352 / 15539 - CLASS_LOSS : 0.18397
134 / 500 :: 4992 / 15539 - CLASS_LOSS : 0.1845
134 / 500 :: 5632 / 15539 - CLASS_LOSS : 0.2105
134 / 500 :: 6272 / 15539 - CLASS_LOSS : 0.44614
134 / 500 :: 6912 / 15539 - CLASS_LOSS : 0.13676
134 / 500 :: 7552 / 15539 - CLASS_LOSS : 0.29143
134 / 500 :: 8192 / 15539 - CLASS_LOSS : 0.2453
134 / 500 :: 8832 / 15539 - CLASS_LOSS : 0.28829
134 / 500 :: 9472 / 15539 - CLASS_LOSS : 0.10704
134 / 500 :: 10112 / 15539 - CLASS_LOSS : 0.23926
134 / 500 :: 10752 / 15539 - CLASS_LOSS : 0.17356
134 / 500 :: 11392 / 15539 - CLASS_LOSS : 0.20551
134 / 500 :: 12032 / 15539 - CLASS_LOSS : 0.16738
134 / 500 :: 12672 / 15539 - CLASS_LOSS : 0.15549
134 / 500 :: 13312 / 15539 - CLASS_LOSS : 0.13307
134 / 500 :: 13952 / 15539 - CLASS_LOSS : 0.13739
134 / 500 :: 14592 / 15539 - CLASS_LOSS : 0.21456
134 / 500 :: 15232 / 15539 - CLASS_LOSS : 0.11702
135 / 500 :: 320 / 15539 - CLASS_LOSS : 0.15813
135 / 500 :: 960 / 15539 - CLASS_LOSS : 0.18264
135 / 500 :: 1600 / 15539 - CLASS_LOSS : 0.16687
135 / 500 :: 2240 / 15539 - CLASS_LOSS : 0.11894
135 / 500 :: 2880 / 15539 - CLASS_LOSS : 0.20262
135 / 500 :: 3520 / 15539 - CLASS_LOSS : 0.21347
135 / 500 :: 4160 / 15539 - CLASS_LOSS : 0.26135
135 / 500 :: 4800 / 15539 - CLASS_LOSS : 0.14943
135 / 500 :: 5440 / 15539 - CLASS_LOSS : 0.27274
135 / 500 :: 6080 / 15539 - CLASS_LOSS : 0.1222
135 / 500 :: 6720 / 15539 - CLASS_LOSS : 0.19181
135 / 500 :: 7360 / 15539 - CLASS_LOSS : 0.24821
135 / 500 :: 8000 / 15539 - CLASS_LOSS : 0.25349
135 / 500 :: 8640 / 15539 - CLASS_LOSS : 0.13608
135 / 500 :: 9280 / 15539 - CLASS_LOSS : 0.20281
135 / 500 :: 9920 / 15539 - CLASS_LOSS : 0.17766
135 / 500 :: 10560 / 15539 - CLASS_LOSS : 0.11597
135 / 500 :: 11200 / 15539 - CLASS_LOSS : 0.25456
135 / 500 :: 11840 / 15539 - CLASS_LOSS : 0.18285
135 / 500 :: 12480 / 15539 - CLASS_LOSS : 0.29684
135 / 500 :: 13120 / 15539 - CLASS_LOSS : 0.20743
135 / 500 :: 13760 / 15539 - CLASS_LOSS : 0.13638
135 / 500 :: 14400 / 15539 - CLASS_LOSS : 0.14302
135 / 500 :: 15040 / 15539 - CLASS_LOSS : 0.26173
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.526031276143896 0.4360211939850269 0.36786150974966214
PSPrecision@1,3,5: 0.38093488633853195 0.40805629980759 0.42371314207392285
testing....
Precision@1,3,5: 0.4337096350748228 0.3559114378227006 0.29598319768968234
PSPrecision@1,3,5: 0.25894303492256043 0.28857606051133994 0.3003781445060708
136 / 500 :: 128 / 15539 - CLASS_LOSS : 0.23257
136 / 500 :: 768 / 15539 - CLASS_LOSS : 0.14515
136 / 500 :: 1408 / 15539 - CLASS_LOSS : 0.21405
136 / 500 :: 2048 / 15539 - CLASS_LOSS : 0.07717
136 / 500 :: 2688 / 15539 - CLASS_LOSS : 0.17178
136 / 500 :: 3328 / 15539 - CLASS_LOSS : 0.19008
136 / 500 :: 3968 / 15539 - CLASS_LOSS : 0.27398
136 / 500 :: 4608 / 15539 - CLASS_LOSS : 0.15981
136 / 500 :: 5248 / 15539 - CLASS_LOSS : 0.19749
136 / 500 :: 5888 / 15539 - CLASS_LOSS : 0.14509
136 / 500 :: 6528 / 15539 - CLASS_LOSS : 0.16846
136 / 500 :: 7168 / 15539 - CLASS_LOSS : 0.16363
136 / 500 :: 7808 / 15539 - CLASS_LOSS : 0.14724
136 / 500 :: 8448 / 15539 - CLASS_LOSS : 0.18429
136 / 500 :: 9088 / 15539 - CLASS_LOSS : 0.12547
136 / 500 :: 9728 / 15539 - CLASS_LOSS : 0.21589
136 / 500 :: 10368 / 15539 - CLASS_LOSS : 0.11938
136 / 500 :: 11008 / 15539 - CLASS_LOSS : 0.19135
136 / 500 :: 11648 / 15539 - CLASS_LOSS : 0.11223
136 / 500 :: 12288 / 15539 - CLASS_LOSS : 0.16276
136 / 500 :: 12928 / 15539 - CLASS_LOSS : 0.13078
136 / 500 :: 13568 / 15539 - CLASS_LOSS : 0.15464
136 / 500 :: 14208 / 15539 - CLASS_LOSS : 0.14851
136 / 500 :: 14848 / 15539 - CLASS_LOSS : 0.17817
136 / 500 :: 15488 / 15539 - CLASS_LOSS : 0.12116
137 / 500 :: 576 / 15539 - CLASS_LOSS : 0.16539
137 / 500 :: 1216 / 15539 - CLASS_LOSS : 0.12103
137 / 500 :: 1856 / 15539 - CLASS_LOSS : 0.20647
137 / 500 :: 2496 / 15539 - CLASS_LOSS : 0.17146
137 / 500 :: 3136 / 15539 - CLASS_LOSS : 0.20173
137 / 500 :: 3776 / 15539 - CLASS_LOSS : 0.09802
137 / 500 :: 4416 / 15539 - CLASS_LOSS : 0.16883
137 / 500 :: 5056 / 15539 - CLASS_LOSS : 0.2322
137 / 500 :: 5696 / 15539 - CLASS_LOSS : 0.12866
137 / 500 :: 6336 / 15539 - CLASS_LOSS : 0.0902
137 / 500 :: 6976 / 15539 - CLASS_LOSS : 0.21736
137 / 500 :: 7616 / 15539 - CLASS_LOSS : 0.27002
137 / 500 :: 8256 / 15539 - CLASS_LOSS : 0.23888
137 / 500 :: 8896 / 15539 - CLASS_LOSS : 0.10797
137 / 500 :: 9536 / 15539 - CLASS_LOSS : 0.2064
137 / 500 :: 10176 / 15539 - CLASS_LOSS : 0.18197
137 / 500 :: 10816 / 15539 - CLASS_LOSS : 0.21569
137 / 500 :: 11456 / 15539 - CLASS_LOSS : 0.19636
137 / 500 :: 12096 / 15539 - CLASS_LOSS : 0.1773
137 / 500 :: 12736 / 15539 - CLASS_LOSS : 0.22561
137 / 500 :: 13376 / 15539 - CLASS_LOSS : 0.17893
137 / 500 :: 14016 / 15539 - CLASS_LOSS : 0.16556
137 / 500 :: 14656 / 15539 - CLASS_LOSS : 0.12604
137 / 500 :: 15296 / 15539 - CLASS_LOSS : 0.10621
138 / 500 :: 384 / 15539 - CLASS_LOSS : 0.18187
138 / 500 :: 1024 / 15539 - CLASS_LOSS : 0.17896
138 / 500 :: 1664 / 15539 - CLASS_LOSS : 0.14241
138 / 500 :: 2304 / 15539 - CLASS_LOSS : 0.24416
138 / 500 :: 2944 / 15539 - CLASS_LOSS : 0.20469
138 / 500 :: 3584 / 15539 - CLASS_LOSS : 0.11226
138 / 500 :: 4224 / 15539 - CLASS_LOSS : 0.16517
138 / 500 :: 4864 / 15539 - CLASS_LOSS : 0.22507
138 / 500 :: 5504 / 15539 - CLASS_LOSS : 0.21573
138 / 500 :: 6144 / 15539 - CLASS_LOSS : 0.17054
138 / 500 :: 6784 / 15539 - CLASS_LOSS : 0.17469
138 / 500 :: 7424 / 15539 - CLASS_LOSS : 0.15988
138 / 500 :: 8064 / 15539 - CLASS_LOSS : 0.14828
138 / 500 :: 8704 / 15539 - CLASS_LOSS : 0.15508
138 / 500 :: 9344 / 15539 - CLASS_LOSS : 0.1733
138 / 500 :: 9984 / 15539 - CLASS_LOSS : 0.14183
138 / 500 :: 10624 / 15539 - CLASS_LOSS : 0.19754
138 / 500 :: 11264 / 15539 - CLASS_LOSS : 0.24837
138 / 500 :: 11904 / 15539 - CLASS_LOSS : 0.32037
138 / 500 :: 12544 / 15539 - CLASS_LOSS : 0.21479
138 / 500 :: 13184 / 15539 - CLASS_LOSS : 0.14099
138 / 500 :: 13824 / 15539 - CLASS_LOSS : 0.22405
138 / 500 :: 14464 / 15539 - CLASS_LOSS : 0.1565
138 / 500 :: 15104 / 15539 - CLASS_LOSS : 0.18664
139 / 500 :: 192 / 15539 - CLASS_LOSS : 0.25424
139 / 500 :: 832 / 15539 - CLASS_LOSS : 0.19442
139 / 500 :: 1472 / 15539 - CLASS_LOSS : 0.23815
139 / 500 :: 2112 / 15539 - CLASS_LOSS : 0.15132
139 / 500 :: 2752 / 15539 - CLASS_LOSS : 0.14529
139 / 500 :: 3392 / 15539 - CLASS_LOSS : 0.13091
139 / 500 :: 4032 / 15539 - CLASS_LOSS : 0.23921
139 / 500 :: 4672 / 15539 - CLASS_LOSS : 0.1673
139 / 500 :: 5312 / 15539 - CLASS_LOSS : 0.1634
139 / 500 :: 5952 / 15539 - CLASS_LOSS : 0.1722
139 / 500 :: 6592 / 15539 - CLASS_LOSS : 0.15988
139 / 500 :: 7232 / 15539 - CLASS_LOSS : 0.21711
139 / 500 :: 7872 / 15539 - CLASS_LOSS : 0.20095
139 / 500 :: 8512 / 15539 - CLASS_LOSS : 0.14092
139 / 500 :: 9152 / 15539 - CLASS_LOSS : 0.16956
139 / 500 :: 9792 / 15539 - CLASS_LOSS : 0.1843
139 / 500 :: 10432 / 15539 - CLASS_LOSS : 0.13162
139 / 500 :: 11072 / 15539 - CLASS_LOSS : 0.11327
139 / 500 :: 11712 / 15539 - CLASS_LOSS : 0.15467
139 / 500 :: 12352 / 15539 - CLASS_LOSS : 0.17445
139 / 500 :: 12992 / 15539 - CLASS_LOSS : 0.19303
139 / 500 :: 13632 / 15539 - CLASS_LOSS : 0.11041
139 / 500 :: 14272 / 15539 - CLASS_LOSS : 0.2974
139 / 500 :: 14912 / 15539 - CLASS_LOSS : 0.20617
139 / 500 :: 15539 / 15539 - CLASS_LOSS : 0.30118
140 / 500 :: 640 / 15539 - CLASS_LOSS : 0.12666
140 / 500 :: 1280 / 15539 - CLASS_LOSS : 0.2758
140 / 500 :: 1920 / 15539 - CLASS_LOSS : 0.19149
140 / 500 :: 2560 / 15539 - CLASS_LOSS : 0.16846
140 / 500 :: 3200 / 15539 - CLASS_LOSS : 0.19811
140 / 500 :: 3840 / 15539 - CLASS_LOSS : 0.12383
140 / 500 :: 4480 / 15539 - CLASS_LOSS : 0.2193
140 / 500 :: 5120 / 15539 - CLASS_LOSS : 0.12343
140 / 500 :: 5760 / 15539 - CLASS_LOSS : 0.18352
140 / 500 :: 6400 / 15539 - CLASS_LOSS : 0.19098
140 / 500 :: 7040 / 15539 - CLASS_LOSS : 0.1593
140 / 500 :: 7680 / 15539 - CLASS_LOSS : 0.14433
140 / 500 :: 8320 / 15539 - CLASS_LOSS : 0.32256
140 / 500 :: 8960 / 15539 - CLASS_LOSS : 0.17403
140 / 500 :: 9600 / 15539 - CLASS_LOSS : 0.19438
140 / 500 :: 10240 / 15539 - CLASS_LOSS : 0.11115
140 / 500 :: 10880 / 15539 - CLASS_LOSS : 0.21659
140 / 500 :: 11520 / 15539 - CLASS_LOSS : 0.18655
140 / 500 :: 12160 / 15539 - CLASS_LOSS : 0.1517
140 / 500 :: 12800 / 15539 - CLASS_LOSS : 0.14896
140 / 500 :: 13440 / 15539 - CLASS_LOSS : 0.37094
140 / 500 :: 14080 / 15539 - CLASS_LOSS : 0.29076
140 / 500 :: 14720 / 15539 - CLASS_LOSS : 0.14346
140 / 500 :: 15360 / 15539 - CLASS_LOSS : 0.13929
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.5128386640066929 0.4280841753008559 0.36293197760473644
PSPrecision@1,3,5: 0.37042728626671206 0.40117485980150375 0.41753986525595815
testing....
Precision@1,3,5: 0.4365975321606721 0.3525859805723287 0.29608821212916775
PSPrecision@1,3,5: 0.25867921357993073 0.2865590181660263 0.2993491600096941
141 / 500 :: 448 / 15539 - CLASS_LOSS : 0.14475
141 / 500 :: 1088 / 15539 - CLASS_LOSS : 0.15035
141 / 500 :: 1728 / 15539 - CLASS_LOSS : 0.14382
141 / 500 :: 2368 / 15539 - CLASS_LOSS : 0.2002
141 / 500 :: 3008 / 15539 - CLASS_LOSS : 0.13762
141 / 500 :: 3648 / 15539 - CLASS_LOSS : 0.14362
141 / 500 :: 4288 / 15539 - CLASS_LOSS : 0.22372
141 / 500 :: 4928 / 15539 - CLASS_LOSS : 0.10668
141 / 500 :: 5568 / 15539 - CLASS_LOSS : 0.17214
141 / 500 :: 6208 / 15539 - CLASS_LOSS : 0.14562
141 / 500 :: 6848 / 15539 - CLASS_LOSS : 0.19664
141 / 500 :: 7488 / 15539 - CLASS_LOSS : 0.15005
141 / 500 :: 8128 / 15539 - CLASS_LOSS : 0.16886
141 / 500 :: 8768 / 15539 - CLASS_LOSS : 0.20454
141 / 500 :: 9408 / 15539 - CLASS_LOSS : 0.20252
141 / 500 :: 10048 / 15539 - CLASS_LOSS : 0.16526
141 / 500 :: 10688 / 15539 - CLASS_LOSS : 0.2231
141 / 500 :: 11328 / 15539 - CLASS_LOSS : 0.15921
141 / 500 :: 11968 / 15539 - CLASS_LOSS : 0.07596
141 / 500 :: 12608 / 15539 - CLASS_LOSS : 0.14329
141 / 500 :: 13248 / 15539 - CLASS_LOSS : 0.24823
141 / 500 :: 13888 / 15539 - CLASS_LOSS : 0.15265
141 / 500 :: 14528 / 15539 - CLASS_LOSS : 0.29695
141 / 500 :: 15168 / 15539 - CLASS_LOSS : 0.13585
142 / 500 :: 256 / 15539 - CLASS_LOSS : 0.17838
142 / 500 :: 896 / 15539 - CLASS_LOSS : 0.15084
142 / 500 :: 1536 / 15539 - CLASS_LOSS : 0.20761
142 / 500 :: 2176 / 15539 - CLASS_LOSS : 0.24686
142 / 500 :: 2816 / 15539 - CLASS_LOSS : 0.09646
142 / 500 :: 3456 / 15539 - CLASS_LOSS : 0.12101
142 / 500 :: 4096 / 15539 - CLASS_LOSS : 0.13356
142 / 500 :: 4736 / 15539 - CLASS_LOSS : 0.20516
142 / 500 :: 5376 / 15539 - CLASS_LOSS : 0.18945
142 / 500 :: 6016 / 15539 - CLASS_LOSS : 0.31587
142 / 500 :: 6656 / 15539 - CLASS_LOSS : 0.23363
142 / 500 :: 7296 / 15539 - CLASS_LOSS : 0.13772
142 / 500 :: 7936 / 15539 - CLASS_LOSS : 0.24087
142 / 500 :: 8576 / 15539 - CLASS_LOSS : 0.18388
142 / 500 :: 9216 / 15539 - CLASS_LOSS : 0.17944
142 / 500 :: 9856 / 15539 - CLASS_LOSS : 0.1787
142 / 500 :: 10496 / 15539 - CLASS_LOSS : 0.17438
142 / 500 :: 11136 / 15539 - CLASS_LOSS : 0.20558
142 / 500 :: 11776 / 15539 - CLASS_LOSS : 0.15665
142 / 500 :: 12416 / 15539 - CLASS_LOSS : 0.16543
142 / 500 :: 13056 / 15539 - CLASS_LOSS : 0.11752
142 / 500 :: 13696 / 15539 - CLASS_LOSS : 0.13065
142 / 500 :: 14336 / 15539 - CLASS_LOSS : 0.21918
142 / 500 :: 14976 / 15539 - CLASS_LOSS : 0.25197
143 / 500 :: 64 / 15539 - CLASS_LOSS : 0.18409
143 / 500 :: 704 / 15539 - CLASS_LOSS : 0.10408
143 / 500 :: 1344 / 15539 - CLASS_LOSS : 0.21938
143 / 500 :: 1984 / 15539 - CLASS_LOSS : 0.30263
143 / 500 :: 2624 / 15539 - CLASS_LOSS : 0.24662
143 / 500 :: 3264 / 15539 - CLASS_LOSS : 0.1223
143 / 500 :: 3904 / 15539 - CLASS_LOSS : 0.15791
143 / 500 :: 4544 / 15539 - CLASS_LOSS : 0.22254
143 / 500 :: 5184 / 15539 - CLASS_LOSS : 0.2098
143 / 500 :: 5824 / 15539 - CLASS_LOSS : 0.23987
143 / 500 :: 6464 / 15539 - CLASS_LOSS : 0.19529
143 / 500 :: 7104 / 15539 - CLASS_LOSS : 0.1847
143 / 500 :: 7744 / 15539 - CLASS_LOSS : 0.11327
143 / 500 :: 8384 / 15539 - CLASS_LOSS : 0.15037
143 / 500 :: 9024 / 15539 - CLASS_LOSS : 0.17128
143 / 500 :: 9664 / 15539 - CLASS_LOSS : 0.13463
143 / 500 :: 10304 / 15539 - CLASS_LOSS : 0.10478
143 / 500 :: 10944 / 15539 - CLASS_LOSS : 0.1976
143 / 500 :: 11584 / 15539 - CLASS_LOSS : 0.12967
143 / 500 :: 12224 / 15539 - CLASS_LOSS : 0.14872
143 / 500 :: 12864 / 15539 - CLASS_LOSS : 0.33174
143 / 500 :: 13504 / 15539 - CLASS_LOSS : 0.25878
143 / 500 :: 14144 / 15539 - CLASS_LOSS : 0.20077
143 / 500 :: 14784 / 15539 - CLASS_LOSS : 0.33882
143 / 500 :: 15424 / 15539 - CLASS_LOSS : 0.2039
144 / 500 :: 512 / 15539 - CLASS_LOSS : 0.24766
144 / 500 :: 1152 / 15539 - CLASS_LOSS : 0.10734
144 / 500 :: 1792 / 15539 - CLASS_LOSS : 0.19332
144 / 500 :: 2432 / 15539 - CLASS_LOSS : 0.20372
144 / 500 :: 3072 / 15539 - CLASS_LOSS : 0.15483
144 / 500 :: 3712 / 15539 - CLASS_LOSS : 0.2688
144 / 500 :: 4352 / 15539 - CLASS_LOSS : 0.09965
144 / 500 :: 4992 / 15539 - CLASS_LOSS : 0.14754
144 / 500 :: 5632 / 15539 - CLASS_LOSS : 0.15305
144 / 500 :: 6272 / 15539 - CLASS_LOSS : 0.27895
144 / 500 :: 6912 / 15539 - CLASS_LOSS : 0.12269
144 / 500 :: 7552 / 15539 - CLASS_LOSS : 0.22179
144 / 500 :: 8192 / 15539 - CLASS_LOSS : 0.27021
144 / 500 :: 8832 / 15539 - CLASS_LOSS : 0.18742
144 / 500 :: 9472 / 15539 - CLASS_LOSS : 0.32919
144 / 500 :: 10112 / 15539 - CLASS_LOSS : 0.17591
144 / 500 :: 10752 / 15539 - CLASS_LOSS : 0.21556
144 / 500 :: 11392 / 15539 - CLASS_LOSS : 0.19013
144 / 500 :: 12032 / 15539 - CLASS_LOSS : 0.2318
144 / 500 :: 12672 / 15539 - CLASS_LOSS : 0.11307
144 / 500 :: 13312 / 15539 - CLASS_LOSS : 0.11426
144 / 500 :: 13952 / 15539 - CLASS_LOSS : 0.12475
144 / 500 :: 14592 / 15539 - CLASS_LOSS : 0.10942
144 / 500 :: 15232 / 15539 - CLASS_LOSS : 0.17101
145 / 500 :: 320 / 15539 - CLASS_LOSS : 0.22957
145 / 500 :: 960 / 15539 - CLASS_LOSS : 0.20369
145 / 500 :: 1600 / 15539 - CLASS_LOSS : 0.15663
145 / 500 :: 2240 / 15539 - CLASS_LOSS : 0.13469
145 / 500 :: 2880 / 15539 - CLASS_LOSS : 0.16977
145 / 500 :: 3520 / 15539 - CLASS_LOSS : 0.19079
145 / 500 :: 4160 / 15539 - CLASS_LOSS : 0.24706
145 / 500 :: 4800 / 15539 - CLASS_LOSS : 0.17189
145 / 500 :: 5440 / 15539 - CLASS_LOSS : 0.18851
145 / 500 :: 6080 / 15539 - CLASS_LOSS : 0.17003
145 / 500 :: 6720 / 15539 - CLASS_LOSS : 0.1419
145 / 500 :: 7360 / 15539 - CLASS_LOSS : 0.22474
145 / 500 :: 8000 / 15539 - CLASS_LOSS : 0.13719
145 / 500 :: 8640 / 15539 - CLASS_LOSS : 0.23246
145 / 500 :: 9280 / 15539 - CLASS_LOSS : 0.13787
145 / 500 :: 9920 / 15539 - CLASS_LOSS : 0.1277
145 / 500 :: 10560 / 15539 - CLASS_LOSS : 0.2083
145 / 500 :: 11200 / 15539 - CLASS_LOSS : 0.2492
145 / 500 :: 11840 / 15539 - CLASS_LOSS : 0.20735
145 / 500 :: 12480 / 15539 - CLASS_LOSS : 0.22746
145 / 500 :: 13120 / 15539 - CLASS_LOSS : 0.29447
145 / 500 :: 13760 / 15539 - CLASS_LOSS : 0.18921
145 / 500 :: 14400 / 15539 - CLASS_LOSS : 0.23138
145 / 500 :: 15040 / 15539 - CLASS_LOSS : 0.22378
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.504923096724371 0.42501662483643304 0.3616448934937898
PSPrecision@1,3,5: 0.36740761402422883 0.39873994778929056 0.4165611381510992
testing....
Precision@1,3,5: 0.4289839852979785 0.35634899798722325 0.3011289052244684
PSPrecision@1,3,5: 0.2566035097031504 0.28942564481547217 0.3053203639077998
146 / 500 :: 128 / 15539 - CLASS_LOSS : 0.16775
146 / 500 :: 768 / 15539 - CLASS_LOSS : 0.16561
146 / 500 :: 1408 / 15539 - CLASS_LOSS : 0.13406
146 / 500 :: 2048 / 15539 - CLASS_LOSS : 0.27961
146 / 500 :: 2688 / 15539 - CLASS_LOSS : 0.14603
146 / 500 :: 3328 / 15539 - CLASS_LOSS : 0.19393
146 / 500 :: 3968 / 15539 - CLASS_LOSS : 0.16188
146 / 500 :: 4608 / 15539 - CLASS_LOSS : 0.18724
146 / 500 :: 5248 / 15539 - CLASS_LOSS : 0.15621
146 / 500 :: 5888 / 15539 - CLASS_LOSS : 0.20313
146 / 500 :: 6528 / 15539 - CLASS_LOSS : 0.10873
146 / 500 :: 7168 / 15539 - CLASS_LOSS : 0.22054
146 / 500 :: 7808 / 15539 - CLASS_LOSS : 0.14312
146 / 500 :: 8448 / 15539 - CLASS_LOSS : 0.18808
146 / 500 :: 9088 / 15539 - CLASS_LOSS : 0.22374
146 / 500 :: 9728 / 15539 - CLASS_LOSS : 0.10594
146 / 500 :: 10368 / 15539 - CLASS_LOSS : 0.22357
146 / 500 :: 11008 / 15539 - CLASS_LOSS : 0.14964
146 / 500 :: 11648 / 15539 - CLASS_LOSS : 0.13507
146 / 500 :: 12288 / 15539 - CLASS_LOSS : 0.12804
146 / 500 :: 12928 / 15539 - CLASS_LOSS : 0.24502
146 / 500 :: 13568 / 15539 - CLASS_LOSS : 0.13436
146 / 500 :: 14208 / 15539 - CLASS_LOSS : 0.17272
146 / 500 :: 14848 / 15539 - CLASS_LOSS : 0.14908
146 / 500 :: 15488 / 15539 - CLASS_LOSS : 0.18739
147 / 500 :: 576 / 15539 - CLASS_LOSS : 0.25784
147 / 500 :: 1216 / 15539 - CLASS_LOSS : 0.1989
147 / 500 :: 1856 / 15539 - CLASS_LOSS : 0.20847
147 / 500 :: 2496 / 15539 - CLASS_LOSS : 0.16579
147 / 500 :: 3136 / 15539 - CLASS_LOSS : 0.16044
147 / 500 :: 3776 / 15539 - CLASS_LOSS : 0.37003
147 / 500 :: 4416 / 15539 - CLASS_LOSS : 0.18858
147 / 500 :: 5056 / 15539 - CLASS_LOSS : 0.10189
147 / 500 :: 5696 / 15539 - CLASS_LOSS : 0.24249
147 / 500 :: 6336 / 15539 - CLASS_LOSS : 0.30215
147 / 500 :: 6976 / 15539 - CLASS_LOSS : 0.18706
147 / 500 :: 7616 / 15539 - CLASS_LOSS : 0.23601
147 / 500 :: 8256 / 15539 - CLASS_LOSS : 0.18912
147 / 500 :: 8896 / 15539 - CLASS_LOSS : 0.13837
147 / 500 :: 9536 / 15539 - CLASS_LOSS : 0.10887
147 / 500 :: 10176 / 15539 - CLASS_LOSS : 0.14489
147 / 500 :: 10816 / 15539 - CLASS_LOSS : 0.13376
147 / 500 :: 11456 / 15539 - CLASS_LOSS : 0.19135
147 / 500 :: 12096 / 15539 - CLASS_LOSS : 0.18147
147 / 500 :: 12736 / 15539 - CLASS_LOSS : 0.10281
147 / 500 :: 13376 / 15539 - CLASS_LOSS : 0.21675
147 / 500 :: 14016 / 15539 - CLASS_LOSS : 0.18425
147 / 500 :: 14656 / 15539 - CLASS_LOSS : 0.37745
147 / 500 :: 15296 / 15539 - CLASS_LOSS : 0.15322
148 / 500 :: 384 / 15539 - CLASS_LOSS : 0.12435
148 / 500 :: 1024 / 15539 - CLASS_LOSS : 0.27377
148 / 500 :: 1664 / 15539 - CLASS_LOSS : 0.1875
148 / 500 :: 2304 / 15539 - CLASS_LOSS : 0.11502
148 / 500 :: 2944 / 15539 - CLASS_LOSS : 0.1984
148 / 500 :: 3584 / 15539 - CLASS_LOSS : 0.11835
148 / 500 :: 4224 / 15539 - CLASS_LOSS : 0.15899
148 / 500 :: 4864 / 15539 - CLASS_LOSS : 0.19431
148 / 500 :: 5504 / 15539 - CLASS_LOSS : 0.2033
148 / 500 :: 6144 / 15539 - CLASS_LOSS : 0.2058
148 / 500 :: 6784 / 15539 - CLASS_LOSS : 0.20053
148 / 500 :: 7424 / 15539 - CLASS_LOSS : 0.19495
148 / 500 :: 8064 / 15539 - CLASS_LOSS : 0.11595
148 / 500 :: 8704 / 15539 - CLASS_LOSS : 0.17578
148 / 500 :: 9344 / 15539 - CLASS_LOSS : 0.1419
148 / 500 :: 9984 / 15539 - CLASS_LOSS : 0.20049
148 / 500 :: 10624 / 15539 - CLASS_LOSS : 0.13065
148 / 500 :: 11264 / 15539 - CLASS_LOSS : 0.14539
148 / 500 :: 11904 / 15539 - CLASS_LOSS : 0.21526
148 / 500 :: 12544 / 15539 - CLASS_LOSS : 0.14933
148 / 500 :: 13184 / 15539 - CLASS_LOSS : 0.1559
148 / 500 :: 13824 / 15539 - CLASS_LOSS : 0.15353
148 / 500 :: 14464 / 15539 - CLASS_LOSS : 0.13904
148 / 500 :: 15104 / 15539 - CLASS_LOSS : 0.14031
149 / 500 :: 192 / 15539 - CLASS_LOSS : 0.14958
149 / 500 :: 832 / 15539 - CLASS_LOSS : 0.14372
149 / 500 :: 1472 / 15539 - CLASS_LOSS : 0.15085
149 / 500 :: 2112 / 15539 - CLASS_LOSS : 0.17305
149 / 500 :: 2752 / 15539 - CLASS_LOSS : 0.13391
149 / 500 :: 3392 / 15539 - CLASS_LOSS : 0.13283
149 / 500 :: 4032 / 15539 - CLASS_LOSS : 0.17882
149 / 500 :: 4672 / 15539 - CLASS_LOSS : 0.17503
149 / 500 :: 5312 / 15539 - CLASS_LOSS : 0.15466
149 / 500 :: 5952 / 15539 - CLASS_LOSS : 0.29556
149 / 500 :: 6592 / 15539 - CLASS_LOSS : 0.13259
149 / 500 :: 7232 / 15539 - CLASS_LOSS : 0.10693
149 / 500 :: 7872 / 15539 - CLASS_LOSS : 0.2093
149 / 500 :: 8512 / 15539 - CLASS_LOSS : 0.142
149 / 500 :: 9152 / 15539 - CLASS_LOSS : 0.14726
149 / 500 :: 9792 / 15539 - CLASS_LOSS : 0.15916
149 / 500 :: 10432 / 15539 - CLASS_LOSS : 0.13203
149 / 500 :: 11072 / 15539 - CLASS_LOSS : 0.20522
149 / 500 :: 11712 / 15539 - CLASS_LOSS : 0.1514
149 / 500 :: 12352 / 15539 - CLASS_LOSS : 0.21587
149 / 500 :: 12992 / 15539 - CLASS_LOSS : 0.21777
149 / 500 :: 13632 / 15539 - CLASS_LOSS : 0.18579
149 / 500 :: 14272 / 15539 - CLASS_LOSS : 0.21672
149 / 500 :: 14912 / 15539 - CLASS_LOSS : 0.27614
149 / 500 :: 15539 / 15539 - CLASS_LOSS : 0.16353
150 / 500 :: 640 / 15539 - CLASS_LOSS : 0.12629
150 / 500 :: 1280 / 15539 - CLASS_LOSS : 0.18695
150 / 500 :: 1920 / 15539 - CLASS_LOSS : 0.11343
150 / 500 :: 2560 / 15539 - CLASS_LOSS : 0.18464
150 / 500 :: 3200 / 15539 - CLASS_LOSS : 0.14792
150 / 500 :: 3840 / 15539 - CLASS_LOSS : 0.15746
150 / 500 :: 4480 / 15539 - CLASS_LOSS : 0.11581
150 / 500 :: 5120 / 15539 - CLASS_LOSS : 0.14705
150 / 500 :: 5760 / 15539 - CLASS_LOSS : 0.16326
150 / 500 :: 6400 / 15539 - CLASS_LOSS : 0.23074
150 / 500 :: 7040 / 15539 - CLASS_LOSS : 0.11961
150 / 500 :: 7680 / 15539 - CLASS_LOSS : 0.17154
150 / 500 :: 8320 / 15539 - CLASS_LOSS : 0.09626
150 / 500 :: 8960 / 15539 - CLASS_LOSS : 0.1815
150 / 500 :: 9600 / 15539 - CLASS_LOSS : 0.13806
150 / 500 :: 10240 / 15539 - CLASS_LOSS : 0.17287
150 / 500 :: 10880 / 15539 - CLASS_LOSS : 0.12142
150 / 500 :: 11520 / 15539 - CLASS_LOSS : 0.18581
150 / 500 :: 12160 / 15539 - CLASS_LOSS : 0.2249
150 / 500 :: 12800 / 15539 - CLASS_LOSS : 0.15114
150 / 500 :: 13440 / 15539 - CLASS_LOSS : 0.13478
150 / 500 :: 14080 / 15539 - CLASS_LOSS : 0.13503
150 / 500 :: 14720 / 15539 - CLASS_LOSS : 0.11705
150 / 500 :: 15360 / 15539 - CLASS_LOSS : 0.19687
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.5102001415792522 0.430229315485767 0.3675011261985971
PSPrecision@1,3,5: 0.37355028666388823 0.40374106942240734 0.42345388146415786
testing....
Precision@1,3,5: 0.43134681018640064 0.3515358361774744 0.30175899186138094
PSPrecision@1,3,5: 0.2569168872056808 0.2825538800834251 0.3047392129128098
151 / 500 :: 448 / 15539 - CLASS_LOSS : 0.23095
151 / 500 :: 1088 / 15539 - CLASS_LOSS : 0.37992
151 / 500 :: 1728 / 15539 - CLASS_LOSS : 0.14097
151 / 500 :: 2368 / 15539 - CLASS_LOSS : 0.18052
151 / 500 :: 3008 / 15539 - CLASS_LOSS : 0.13329
151 / 500 :: 3648 / 15539 - CLASS_LOSS : 0.26715
151 / 500 :: 4288 / 15539 - CLASS_LOSS : 0.13291
151 / 500 :: 4928 / 15539 - CLASS_LOSS : 0.13063
151 / 500 :: 5568 / 15539 - CLASS_LOSS : 0.15043
151 / 500 :: 6208 / 15539 - CLASS_LOSS : 0.18998
151 / 500 :: 6848 / 15539 - CLASS_LOSS : 0.19413
151 / 500 :: 7488 / 15539 - CLASS_LOSS : 0.12942
151 / 500 :: 8128 / 15539 - CLASS_LOSS : 0.11772
151 / 500 :: 8768 / 15539 - CLASS_LOSS : 0.19929
151 / 500 :: 9408 / 15539 - CLASS_LOSS : 0.21616
151 / 500 :: 10048 / 15539 - CLASS_LOSS : 0.1554
151 / 500 :: 10688 / 15539 - CLASS_LOSS : 0.11531
151 / 500 :: 11328 / 15539 - CLASS_LOSS : 0.1721
151 / 500 :: 11968 / 15539 - CLASS_LOSS : 0.18888
151 / 500 :: 12608 / 15539 - CLASS_LOSS : 0.2222
151 / 500 :: 13248 / 15539 - CLASS_LOSS : 0.18832
151 / 500 :: 13888 / 15539 - CLASS_LOSS : 0.33055
151 / 500 :: 14528 / 15539 - CLASS_LOSS : 0.25638
151 / 500 :: 15168 / 15539 - CLASS_LOSS : 0.2191
152 / 500 :: 256 / 15539 - CLASS_LOSS : 0.23157
152 / 500 :: 896 / 15539 - CLASS_LOSS : 0.20777
152 / 500 :: 1536 / 15539 - CLASS_LOSS : 0.16696
152 / 500 :: 2176 / 15539 - CLASS_LOSS : 0.19056
152 / 500 :: 2816 / 15539 - CLASS_LOSS : 0.13934
152 / 500 :: 3456 / 15539 - CLASS_LOSS : 0.16299
152 / 500 :: 4096 / 15539 - CLASS_LOSS : 0.17529
152 / 500 :: 4736 / 15539 - CLASS_LOSS : 0.13168
152 / 500 :: 5376 / 15539 - CLASS_LOSS : 0.11033
152 / 500 :: 6016 / 15539 - CLASS_LOSS : 0.16399
152 / 500 :: 6656 / 15539 - CLASS_LOSS : 0.13937
152 / 500 :: 7296 / 15539 - CLASS_LOSS : 0.17254
152 / 500 :: 7936 / 15539 - CLASS_LOSS : 0.16286
152 / 500 :: 8576 / 15539 - CLASS_LOSS : 0.09832
152 / 500 :: 9216 / 15539 - CLASS_LOSS : 0.21223
152 / 500 :: 9856 / 15539 - CLASS_LOSS : 0.25314
152 / 500 :: 10496 / 15539 - CLASS_LOSS : 0.13978
152 / 500 :: 11136 / 15539 - CLASS_LOSS : 0.15935
152 / 500 :: 11776 / 15539 - CLASS_LOSS : 0.11407
152 / 500 :: 12416 / 15539 - CLASS_LOSS : 0.22955
152 / 500 :: 13056 / 15539 - CLASS_LOSS : 0.11973
152 / 500 :: 13696 / 15539 - CLASS_LOSS : 0.36377
152 / 500 :: 14336 / 15539 - CLASS_LOSS : 0.23909
152 / 500 :: 14976 / 15539 - CLASS_LOSS : 0.17575
153 / 500 :: 64 / 15539 - CLASS_LOSS : 0.11497
153 / 500 :: 704 / 15539 - CLASS_LOSS : 0.1275
153 / 500 :: 1344 / 15539 - CLASS_LOSS : 0.12311
153 / 500 :: 1984 / 15539 - CLASS_LOSS : 0.14958
153 / 500 :: 2624 / 15539 - CLASS_LOSS : 0.12684
153 / 500 :: 3264 / 15539 - CLASS_LOSS : 0.24991
153 / 500 :: 3904 / 15539 - CLASS_LOSS : 0.18352
153 / 500 :: 4544 / 15539 - CLASS_LOSS : 0.2134
153 / 500 :: 5184 / 15539 - CLASS_LOSS : 0.22355
153 / 500 :: 5824 / 15539 - CLASS_LOSS : 0.19014
153 / 500 :: 6464 / 15539 - CLASS_LOSS : 0.15361
153 / 500 :: 7104 / 15539 - CLASS_LOSS : 0.13354
153 / 500 :: 7744 / 15539 - CLASS_LOSS : 0.13634
153 / 500 :: 8384 / 15539 - CLASS_LOSS : 0.13122
153 / 500 :: 9024 / 15539 - CLASS_LOSS : 0.19171
153 / 500 :: 9664 / 15539 - CLASS_LOSS : 0.12698
153 / 500 :: 10304 / 15539 - CLASS_LOSS : 0.25586
153 / 500 :: 10944 / 15539 - CLASS_LOSS : 0.16186
153 / 500 :: 11584 / 15539 - CLASS_LOSS : 0.18295
153 / 500 :: 12224 / 15539 - CLASS_LOSS : 0.16077
153 / 500 :: 12864 / 15539 - CLASS_LOSS : 0.19315
153 / 500 :: 13504 / 15539 - CLASS_LOSS : 0.11393
153 / 500 :: 14144 / 15539 - CLASS_LOSS : 0.11813
153 / 500 :: 14784 / 15539 - CLASS_LOSS : 0.20085
153 / 500 :: 15424 / 15539 - CLASS_LOSS : 0.31142
154 / 500 :: 512 / 15539 - CLASS_LOSS : 0.19532
154 / 500 :: 1152 / 15539 - CLASS_LOSS : 0.13206
154 / 500 :: 1792 / 15539 - CLASS_LOSS : 0.14114
154 / 500 :: 2432 / 15539 - CLASS_LOSS : 0.13399
154 / 500 :: 3072 / 15539 - CLASS_LOSS : 0.16202
154 / 500 :: 3712 / 15539 - CLASS_LOSS : 0.17142
154 / 500 :: 4352 / 15539 - CLASS_LOSS : 0.14138
154 / 500 :: 4992 / 15539 - CLASS_LOSS : 0.13409
154 / 500 :: 5632 / 15539 - CLASS_LOSS : 0.13547
154 / 500 :: 6272 / 15539 - CLASS_LOSS : 0.2811
154 / 500 :: 6912 / 15539 - CLASS_LOSS : 0.23009
154 / 500 :: 7552 / 15539 - CLASS_LOSS : 0.13183
154 / 500 :: 8192 / 15539 - CLASS_LOSS : 0.09766
154 / 500 :: 8832 / 15539 - CLASS_LOSS : 0.10993
154 / 500 :: 9472 / 15539 - CLASS_LOSS : 0.16205
154 / 500 :: 10112 / 15539 - CLASS_LOSS : 0.13135
154 / 500 :: 10752 / 15539 - CLASS_LOSS : 0.10626
154 / 500 :: 11392 / 15539 - CLASS_LOSS : 0.15629
154 / 500 :: 12032 / 15539 - CLASS_LOSS : 0.11731
154 / 500 :: 12672 / 15539 - CLASS_LOSS : 0.20039
154 / 500 :: 13312 / 15539 - CLASS_LOSS : 0.1897
154 / 500 :: 13952 / 15539 - CLASS_LOSS : 0.15433
154 / 500 :: 14592 / 15539 - CLASS_LOSS : 0.16098
154 / 500 :: 15232 / 15539 - CLASS_LOSS : 0.22869
155 / 500 :: 320 / 15539 - CLASS_LOSS : 0.4
155 / 500 :: 960 / 15539 - CLASS_LOSS : 0.10241
155 / 500 :: 1600 / 15539 - CLASS_LOSS : 0.2781
155 / 500 :: 2240 / 15539 - CLASS_LOSS : 0.11027
155 / 500 :: 2880 / 15539 - CLASS_LOSS : 0.15699
155 / 500 :: 3520 / 15539 - CLASS_LOSS : 0.11268
155 / 500 :: 4160 / 15539 - CLASS_LOSS : 0.32288
155 / 500 :: 4800 / 15539 - CLASS_LOSS : 0.12801
155 / 500 :: 5440 / 15539 - CLASS_LOSS : 0.27927
155 / 500 :: 6080 / 15539 - CLASS_LOSS : 0.18183
155 / 500 :: 6720 / 15539 - CLASS_LOSS : 0.24578
155 / 500 :: 7360 / 15539 - CLASS_LOSS : 0.13513
155 / 500 :: 8000 / 15539 - CLASS_LOSS : 0.13872
155 / 500 :: 8640 / 15539 - CLASS_LOSS : 0.12642
155 / 500 :: 9280 / 15539 - CLASS_LOSS : 0.14045
155 / 500 :: 9920 / 15539 - CLASS_LOSS : 0.18074
155 / 500 :: 10560 / 15539 - CLASS_LOSS : 0.20894
155 / 500 :: 11200 / 15539 - CLASS_LOSS : 0.14216
155 / 500 :: 11840 / 15539 - CLASS_LOSS : 0.09205
155 / 500 :: 12480 / 15539 - CLASS_LOSS : 0.17179
155 / 500 :: 13120 / 15539 - CLASS_LOSS : 0.12435
155 / 500 :: 13760 / 15539 - CLASS_LOSS : 0.15813
155 / 500 :: 14400 / 15539 - CLASS_LOSS : 0.14267
155 / 500 :: 15040 / 15539 - CLASS_LOSS : 0.12235
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.5130317266233348 0.4292425510007079 0.36620117124654095
PSPrecision@1,3,5: 0.3755554576256772 0.403446836962575 0.422211077959528
testing....
Precision@1,3,5: 0.4308217379889735 0.3482103789271025 0.2984510370175899
PSPrecision@1,3,5: 0.25512629326983033 0.28167121327261424 0.3003761044348568
156 / 500 :: 128 / 15539 - CLASS_LOSS : 0.13592
156 / 500 :: 768 / 15539 - CLASS_LOSS : 0.13113
156 / 500 :: 1408 / 15539 - CLASS_LOSS : 0.21784
156 / 500 :: 2048 / 15539 - CLASS_LOSS : 0.22628
156 / 500 :: 2688 / 15539 - CLASS_LOSS : 0.20109
156 / 500 :: 3328 / 15539 - CLASS_LOSS : 0.13562
156 / 500 :: 3968 / 15539 - CLASS_LOSS : 0.12866
156 / 500 :: 4608 / 15539 - CLASS_LOSS : 0.18195
156 / 500 :: 5248 / 15539 - CLASS_LOSS : 0.12842
156 / 500 :: 5888 / 15539 - CLASS_LOSS : 0.16872
156 / 500 :: 6528 / 15539 - CLASS_LOSS : 0.15708
156 / 500 :: 7168 / 15539 - CLASS_LOSS : 0.26787
156 / 500 :: 7808 / 15539 - CLASS_LOSS : 0.22282
156 / 500 :: 8448 / 15539 - CLASS_LOSS : 0.12568
156 / 500 :: 9088 / 15539 - CLASS_LOSS : 0.15246
156 / 500 :: 9728 / 15539 - CLASS_LOSS : 0.11938
156 / 500 :: 10368 / 15539 - CLASS_LOSS : 0.1875
156 / 500 :: 11008 / 15539 - CLASS_LOSS : 0.22027
156 / 500 :: 11648 / 15539 - CLASS_LOSS : 0.15782
156 / 500 :: 12288 / 15539 - CLASS_LOSS : 0.166
156 / 500 :: 12928 / 15539 - CLASS_LOSS : 0.20768
156 / 500 :: 13568 / 15539 - CLASS_LOSS : 0.16195
156 / 500 :: 14208 / 15539 - CLASS_LOSS : 0.18047
156 / 500 :: 14848 / 15539 - CLASS_LOSS : 0.14675
156 / 500 :: 15488 / 15539 - CLASS_LOSS : 0.12314
157 / 500 :: 576 / 15539 - CLASS_LOSS : 0.19134
157 / 500 :: 1216 / 15539 - CLASS_LOSS : 0.2168
157 / 500 :: 1856 / 15539 - CLASS_LOSS : 0.16094
157 / 500 :: 2496 / 15539 - CLASS_LOSS : 0.18933
157 / 500 :: 3136 / 15539 - CLASS_LOSS : 0.10532
157 / 500 :: 3776 / 15539 - CLASS_LOSS : 0.35603
157 / 500 :: 4416 / 15539 - CLASS_LOSS : 0.168
157 / 500 :: 5056 / 15539 - CLASS_LOSS : 0.09965
157 / 500 :: 5696 / 15539 - CLASS_LOSS : 0.16378
157 / 500 :: 6336 / 15539 - CLASS_LOSS : 0.13185
157 / 500 :: 6976 / 15539 - CLASS_LOSS : 0.1763
157 / 500 :: 7616 / 15539 - CLASS_LOSS : 0.12242
157 / 500 :: 8256 / 15539 - CLASS_LOSS : 0.21735
157 / 500 :: 8896 / 15539 - CLASS_LOSS : 0.17663
157 / 500 :: 9536 / 15539 - CLASS_LOSS : 0.08185
157 / 500 :: 10176 / 15539 - CLASS_LOSS : 0.14833
157 / 500 :: 10816 / 15539 - CLASS_LOSS : 0.2171
157 / 500 :: 11456 / 15539 - CLASS_LOSS : 0.15377
157 / 500 :: 12096 / 15539 - CLASS_LOSS : 0.14822
157 / 500 :: 12736 / 15539 - CLASS_LOSS : 0.1402
157 / 500 :: 13376 / 15539 - CLASS_LOSS : 0.11179
157 / 500 :: 14016 / 15539 - CLASS_LOSS : 0.14811
157 / 500 :: 14656 / 15539 - CLASS_LOSS : 0.27736
157 / 500 :: 15296 / 15539 - CLASS_LOSS : 0.24389
158 / 500 :: 384 / 15539 - CLASS_LOSS : 0.1652
158 / 500 :: 1024 / 15539 - CLASS_LOSS : 0.23968
158 / 500 :: 1664 / 15539 - CLASS_LOSS : 0.20447
158 / 500 :: 2304 / 15539 - CLASS_LOSS : 0.1457
158 / 500 :: 2944 / 15539 - CLASS_LOSS : 0.16448
158 / 500 :: 3584 / 15539 - CLASS_LOSS : 0.24007
158 / 500 :: 4224 / 15539 - CLASS_LOSS : 0.16019
158 / 500 :: 4864 / 15539 - CLASS_LOSS : 0.12592
158 / 500 :: 5504 / 15539 - CLASS_LOSS : 0.29925
158 / 500 :: 6144 / 15539 - CLASS_LOSS : 0.12143
158 / 500 :: 6784 / 15539 - CLASS_LOSS : 0.15718
158 / 500 :: 7424 / 15539 - CLASS_LOSS : 0.11225
158 / 500 :: 8064 / 15539 - CLASS_LOSS : 0.07644
158 / 500 :: 8704 / 15539 - CLASS_LOSS : 0.11077
158 / 500 :: 9344 / 15539 - CLASS_LOSS : 0.15872
158 / 500 :: 9984 / 15539 - CLASS_LOSS : 0.24618
158 / 500 :: 10624 / 15539 - CLASS_LOSS : 0.19216
158 / 500 :: 11264 / 15539 - CLASS_LOSS : 0.13375
158 / 500 :: 11904 / 15539 - CLASS_LOSS : 0.16797
158 / 500 :: 12544 / 15539 - CLASS_LOSS : 0.20468
158 / 500 :: 13184 / 15539 - CLASS_LOSS : 0.18368
158 / 500 :: 13824 / 15539 - CLASS_LOSS : 0.1715
158 / 500 :: 14464 / 15539 - CLASS_LOSS : 0.16098
158 / 500 :: 15104 / 15539 - CLASS_LOSS : 0.16857
159 / 500 :: 192 / 15539 - CLASS_LOSS : 0.13614
159 / 500 :: 832 / 15539 - CLASS_LOSS : 0.11006
159 / 500 :: 1472 / 15539 - CLASS_LOSS : 0.17239
159 / 500 :: 2112 / 15539 - CLASS_LOSS : 0.20316
159 / 500 :: 2752 / 15539 - CLASS_LOSS : 0.29612
159 / 500 :: 3392 / 15539 - CLASS_LOSS : 0.15088
159 / 500 :: 4032 / 15539 - CLASS_LOSS : 0.11373
159 / 500 :: 4672 / 15539 - CLASS_LOSS : 0.15612
159 / 500 :: 5312 / 15539 - CLASS_LOSS : 0.24975
159 / 500 :: 5952 / 15539 - CLASS_LOSS : 0.2147
159 / 500 :: 6592 / 15539 - CLASS_LOSS : 0.16828
159 / 500 :: 7232 / 15539 - CLASS_LOSS : 0.16697
159 / 500 :: 7872 / 15539 - CLASS_LOSS : 0.16114
159 / 500 :: 8512 / 15539 - CLASS_LOSS : 0.22055
159 / 500 :: 9152 / 15539 - CLASS_LOSS : 0.18318
159 / 500 :: 9792 / 15539 - CLASS_LOSS : 0.11606
159 / 500 :: 10432 / 15539 - CLASS_LOSS : 0.15538
159 / 500 :: 11072 / 15539 - CLASS_LOSS : 0.15071
159 / 500 :: 11712 / 15539 - CLASS_LOSS : 0.17118
159 / 500 :: 12352 / 15539 - CLASS_LOSS : 0.13693
159 / 500 :: 12992 / 15539 - CLASS_LOSS : 0.12454
159 / 500 :: 13632 / 15539 - CLASS_LOSS : 0.1813
159 / 500 :: 14272 / 15539 - CLASS_LOSS : 0.15763
159 / 500 :: 14912 / 15539 - CLASS_LOSS : 0.16883
159 / 500 :: 15539 / 15539 - CLASS_LOSS : 0.16254
160 / 500 :: 640 / 15539 - CLASS_LOSS : 0.14655
160 / 500 :: 1280 / 15539 - CLASS_LOSS : 0.12597
160 / 500 :: 1920 / 15539 - CLASS_LOSS : 0.22893
160 / 500 :: 2560 / 15539 - CLASS_LOSS : 0.12871
160 / 500 :: 3200 / 15539 - CLASS_LOSS : 0.13825
160 / 500 :: 3840 / 15539 - CLASS_LOSS : 0.14287
160 / 500 :: 4480 / 15539 - CLASS_LOSS : 0.16744
160 / 500 :: 5120 / 15539 - CLASS_LOSS : 0.27011
160 / 500 :: 5760 / 15539 - CLASS_LOSS : 0.18655
160 / 500 :: 6400 / 15539 - CLASS_LOSS : 0.14958
160 / 500 :: 7040 / 15539 - CLASS_LOSS : 0.10935
160 / 500 :: 7680 / 15539 - CLASS_LOSS : 0.21628
160 / 500 :: 8320 / 15539 - CLASS_LOSS : 0.21459
160 / 500 :: 8960 / 15539 - CLASS_LOSS : 0.22366
160 / 500 :: 9600 / 15539 - CLASS_LOSS : 0.21318
160 / 500 :: 10240 / 15539 - CLASS_LOSS : 0.16834
160 / 500 :: 10880 / 15539 - CLASS_LOSS : 0.15099
160 / 500 :: 11520 / 15539 - CLASS_LOSS : 0.17325
160 / 500 :: 12160 / 15539 - CLASS_LOSS : 0.14731
160 / 500 :: 12800 / 15539 - CLASS_LOSS : 0.08457
160 / 500 :: 13440 / 15539 - CLASS_LOSS : 0.21316
160 / 500 :: 14080 / 15539 - CLASS_LOSS : 0.10695
160 / 500 :: 14720 / 15539 - CLASS_LOSS : 0.14031
160 / 500 :: 15360 / 15539 - CLASS_LOSS : 0.18993
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.525259025677328 0.4375013407126156 0.37447712207992795
PSPrecision@1,3,5: 0.37955392990652115 0.4087017456112716 0.4297207632497896
testing....
Precision@1,3,5: 0.44946180099763716 0.3601120154021178 0.3060120766605408
PSPrecision@1,3,5: 0.26710551016886613 0.2885155495165539 0.30717729980522834
161 / 500 :: 448 / 15539 - CLASS_LOSS : 0.16056
161 / 500 :: 1088 / 15539 - CLASS_LOSS : 0.13206
161 / 500 :: 1728 / 15539 - CLASS_LOSS : 0.13505
161 / 500 :: 2368 / 15539 - CLASS_LOSS : 0.1787
161 / 500 :: 3008 / 15539 - CLASS_LOSS : 0.25238
161 / 500 :: 3648 / 15539 - CLASS_LOSS : 0.24583
161 / 500 :: 4288 / 15539 - CLASS_LOSS : 0.11375
161 / 500 :: 4928 / 15539 - CLASS_LOSS : 0.16895
161 / 500 :: 5568 / 15539 - CLASS_LOSS : 0.19167
161 / 500 :: 6208 / 15539 - CLASS_LOSS : 0.1425
161 / 500 :: 6848 / 15539 - CLASS_LOSS : 0.38043
161 / 500 :: 7488 / 15539 - CLASS_LOSS : 0.16341
161 / 500 :: 8128 / 15539 - CLASS_LOSS : 0.18532
161 / 500 :: 8768 / 15539 - CLASS_LOSS : 0.11268
161 / 500 :: 9408 / 15539 - CLASS_LOSS : 0.2331
161 / 500 :: 10048 / 15539 - CLASS_LOSS : 0.2291
161 / 500 :: 10688 / 15539 - CLASS_LOSS : 0.17018
161 / 500 :: 11328 / 15539 - CLASS_LOSS : 0.13688
161 / 500 :: 11968 / 15539 - CLASS_LOSS : 0.21308
161 / 500 :: 12608 / 15539 - CLASS_LOSS : 0.2406
161 / 500 :: 13248 / 15539 - CLASS_LOSS : 0.15362
161 / 500 :: 13888 / 15539 - CLASS_LOSS : 0.14346
161 / 500 :: 14528 / 15539 - CLASS_LOSS : 0.13891
161 / 500 :: 15168 / 15539 - CLASS_LOSS : 0.18685
162 / 500 :: 256 / 15539 - CLASS_LOSS : 0.19546
162 / 500 :: 896 / 15539 - CLASS_LOSS : 0.12214
162 / 500 :: 1536 / 15539 - CLASS_LOSS : 0.21179
162 / 500 :: 2176 / 15539 - CLASS_LOSS : 0.25502
162 / 500 :: 2816 / 15539 - CLASS_LOSS : 0.16016
162 / 500 :: 3456 / 15539 - CLASS_LOSS : 0.14378
162 / 500 :: 4096 / 15539 - CLASS_LOSS : 0.19559
162 / 500 :: 4736 / 15539 - CLASS_LOSS : 0.14165
162 / 500 :: 5376 / 15539 - CLASS_LOSS : 0.07831
162 / 500 :: 6016 / 15539 - CLASS_LOSS : 0.21566
162 / 500 :: 6656 / 15539 - CLASS_LOSS : 0.14242
162 / 500 :: 7296 / 15539 - CLASS_LOSS : 0.06421
162 / 500 :: 7936 / 15539 - CLASS_LOSS : 0.2006
162 / 500 :: 8576 / 15539 - CLASS_LOSS : 0.14298
162 / 500 :: 9216 / 15539 - CLASS_LOSS : 0.18744
162 / 500 :: 9856 / 15539 - CLASS_LOSS : 0.167
162 / 500 :: 10496 / 15539 - CLASS_LOSS : 0.16297
162 / 500 :: 11136 / 15539 - CLASS_LOSS : 0.182
162 / 500 :: 11776 / 15539 - CLASS_LOSS : 0.25677
162 / 500 :: 12416 / 15539 - CLASS_LOSS : 0.15367
162 / 500 :: 13056 / 15539 - CLASS_LOSS : 0.14075
162 / 500 :: 13696 / 15539 - CLASS_LOSS : 0.20671
162 / 500 :: 14336 / 15539 - CLASS_LOSS : 0.15506
162 / 500 :: 14976 / 15539 - CLASS_LOSS : 0.20042
163 / 500 :: 64 / 15539 - CLASS_LOSS : 0.18795
163 / 500 :: 704 / 15539 - CLASS_LOSS : 0.11891
163 / 500 :: 1344 / 15539 - CLASS_LOSS : 0.2142
163 / 500 :: 1984 / 15539 - CLASS_LOSS : 0.16175
163 / 500 :: 2624 / 15539 - CLASS_LOSS : 0.14505
163 / 500 :: 3264 / 15539 - CLASS_LOSS : 0.13992
163 / 500 :: 3904 / 15539 - CLASS_LOSS : 0.23277
163 / 500 :: 4544 / 15539 - CLASS_LOSS : 0.11028
163 / 500 :: 5184 / 15539 - CLASS_LOSS : 0.21266
163 / 500 :: 5824 / 15539 - CLASS_LOSS : 0.12218
163 / 500 :: 6464 / 15539 - CLASS_LOSS : 0.19392
163 / 500 :: 7104 / 15539 - CLASS_LOSS : 0.13501
163 / 500 :: 7744 / 15539 - CLASS_LOSS : 0.13957
163 / 500 :: 8384 / 15539 - CLASS_LOSS : 0.17437
163 / 500 :: 9024 / 15539 - CLASS_LOSS : 0.1279
163 / 500 :: 9664 / 15539 - CLASS_LOSS : 0.18806
163 / 500 :: 10304 / 15539 - CLASS_LOSS : 0.16016
163 / 500 :: 10944 / 15539 - CLASS_LOSS : 0.13138
163 / 500 :: 11584 / 15539 - CLASS_LOSS : 0.20414
163 / 500 :: 12224 / 15539 - CLASS_LOSS : 0.27183
163 / 500 :: 12864 / 15539 - CLASS_LOSS : 0.12199
163 / 500 :: 13504 / 15539 - CLASS_LOSS : 0.14983
163 / 500 :: 14144 / 15539 - CLASS_LOSS : 0.25116
163 / 500 :: 14784 / 15539 - CLASS_LOSS : 0.211
163 / 500 :: 15424 / 15539 - CLASS_LOSS : 0.1627
164 / 500 :: 512 / 15539 - CLASS_LOSS : 0.0961
164 / 500 :: 1152 / 15539 - CLASS_LOSS : 0.28006
164 / 500 :: 1792 / 15539 - CLASS_LOSS : 0.21952
164 / 500 :: 2432 / 15539 - CLASS_LOSS : 0.17463
164 / 500 :: 3072 / 15539 - CLASS_LOSS : 0.23593
164 / 500 :: 3712 / 15539 - CLASS_LOSS : 0.14115
164 / 500 :: 4352 / 15539 - CLASS_LOSS : 0.12884
164 / 500 :: 4992 / 15539 - CLASS_LOSS : 0.24367
164 / 500 :: 5632 / 15539 - CLASS_LOSS : 0.19416
164 / 500 :: 6272 / 15539 - CLASS_LOSS : 0.10394
164 / 500 :: 6912 / 15539 - CLASS_LOSS : 0.24981
164 / 500 :: 7552 / 15539 - CLASS_LOSS : 0.09797
164 / 500 :: 8192 / 15539 - CLASS_LOSS : 0.13085
164 / 500 :: 8832 / 15539 - CLASS_LOSS : 0.26034
164 / 500 :: 9472 / 15539 - CLASS_LOSS : 0.21244
164 / 500 :: 10112 / 15539 - CLASS_LOSS : 0.09563
164 / 500 :: 10752 / 15539 - CLASS_LOSS : 0.12906
164 / 500 :: 11392 / 15539 - CLASS_LOSS : 0.18371
164 / 500 :: 12032 / 15539 - CLASS_LOSS : 0.20265
164 / 500 :: 12672 / 15539 - CLASS_LOSS : 0.13279
164 / 500 :: 13312 / 15539 - CLASS_LOSS : 0.22374
164 / 500 :: 13952 / 15539 - CLASS_LOSS : 0.10599
164 / 500 :: 14592 / 15539 - CLASS_LOSS : 0.11715
164 / 500 :: 15232 / 15539 - CLASS_LOSS : 0.36442
165 / 500 :: 320 / 15539 - CLASS_LOSS : 0.12967
165 / 500 :: 960 / 15539 - CLASS_LOSS : 0.2552
165 / 500 :: 1600 / 15539 - CLASS_LOSS : 0.12867
165 / 500 :: 2240 / 15539 - CLASS_LOSS : 0.0996
165 / 500 :: 2880 / 15539 - CLASS_LOSS : 0.19782
165 / 500 :: 3520 / 15539 - CLASS_LOSS : 0.19016
165 / 500 :: 4160 / 15539 - CLASS_LOSS : 0.26847
165 / 500 :: 4800 / 15539 - CLASS_LOSS : 0.09037
165 / 500 :: 5440 / 15539 - CLASS_LOSS : 0.14347
165 / 500 :: 6080 / 15539 - CLASS_LOSS : 0.15077
165 / 500 :: 6720 / 15539 - CLASS_LOSS : 0.11943
165 / 500 :: 7360 / 15539 - CLASS_LOSS : 0.18132
165 / 500 :: 8000 / 15539 - CLASS_LOSS : 0.13223
165 / 500 :: 8640 / 15539 - CLASS_LOSS : 0.10139
165 / 500 :: 9280 / 15539 - CLASS_LOSS : 0.15498
165 / 500 :: 9920 / 15539 - CLASS_LOSS : 0.10491
165 / 500 :: 10560 / 15539 - CLASS_LOSS : 0.19293
165 / 500 :: 11200 / 15539 - CLASS_LOSS : 0.14993
165 / 500 :: 11840 / 15539 - CLASS_LOSS : 0.14501
165 / 500 :: 12480 / 15539 - CLASS_LOSS : 0.18281
165 / 500 :: 13120 / 15539 - CLASS_LOSS : 0.25644
165 / 500 :: 13760 / 15539 - CLASS_LOSS : 0.1785
165 / 500 :: 14400 / 15539 - CLASS_LOSS : 0.33201
165 / 500 :: 15040 / 15539 - CLASS_LOSS : 0.16108
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.5291202780101679 0.43567797155544113 0.3713366368492181
PSPrecision@1,3,5: 0.3835966223368052 0.40997035047132285 0.4282996316223714
testing....
Precision@1,3,5: 0.4602257810448937 0.355473877658178 0.30181149908112365
PSPrecision@1,3,5: 0.2747146889951463 0.2886691179557245 0.30400299861994834
166 / 500 :: 128 / 15539 - CLASS_LOSS : 0.11402
166 / 500 :: 768 / 15539 - CLASS_LOSS : 0.17146
166 / 500 :: 1408 / 15539 - CLASS_LOSS : 0.13119
166 / 500 :: 2048 / 15539 - CLASS_LOSS : 0.12508
166 / 500 :: 2688 / 15539 - CLASS_LOSS : 0.17438
166 / 500 :: 3328 / 15539 - CLASS_LOSS : 0.13638
166 / 500 :: 3968 / 15539 - CLASS_LOSS : 0.12687
166 / 500 :: 4608 / 15539 - CLASS_LOSS : 0.1287
166 / 500 :: 5248 / 15539 - CLASS_LOSS : 0.10051
166 / 500 :: 5888 / 15539 - CLASS_LOSS : 0.19507
166 / 500 :: 6528 / 15539 - CLASS_LOSS : 0.11855
166 / 500 :: 7168 / 15539 - CLASS_LOSS : 0.22038
166 / 500 :: 7808 / 15539 - CLASS_LOSS : 0.20203
166 / 500 :: 8448 / 15539 - CLASS_LOSS : 0.1767
166 / 500 :: 9088 / 15539 - CLASS_LOSS : 0.15574
166 / 500 :: 9728 / 15539 - CLASS_LOSS : 0.26817
166 / 500 :: 10368 / 15539 - CLASS_LOSS : 0.0912
166 / 500 :: 11008 / 15539 - CLASS_LOSS : 0.13192
166 / 500 :: 11648 / 15539 - CLASS_LOSS : 0.36015
166 / 500 :: 12288 / 15539 - CLASS_LOSS : 0.21253
166 / 500 :: 12928 / 15539 - CLASS_LOSS : 0.21601
166 / 500 :: 13568 / 15539 - CLASS_LOSS : 0.18696
166 / 500 :: 14208 / 15539 - CLASS_LOSS : 0.10175
166 / 500 :: 14848 / 15539 - CLASS_LOSS : 0.17729
166 / 500 :: 15488 / 15539 - CLASS_LOSS : 0.11939
167 / 500 :: 576 / 15539 - CLASS_LOSS : 0.2032
167 / 500 :: 1216 / 15539 - CLASS_LOSS : 0.10943
167 / 500 :: 1856 / 15539 - CLASS_LOSS : 0.14848
167 / 500 :: 2496 / 15539 - CLASS_LOSS : 0.13452
167 / 500 :: 3136 / 15539 - CLASS_LOSS : 0.20561
167 / 500 :: 3776 / 15539 - CLASS_LOSS : 0.20693
167 / 500 :: 4416 / 15539 - CLASS_LOSS : 0.12016
167 / 500 :: 5056 / 15539 - CLASS_LOSS : 0.1468
167 / 500 :: 5696 / 15539 - CLASS_LOSS : 0.12307
167 / 500 :: 6336 / 15539 - CLASS_LOSS : 0.1416
167 / 500 :: 6976 / 15539 - CLASS_LOSS : 0.19437
167 / 500 :: 7616 / 15539 - CLASS_LOSS : 0.11683
167 / 500 :: 8256 / 15539 - CLASS_LOSS : 0.14074
167 / 500 :: 8896 / 15539 - CLASS_LOSS : 0.15815
167 / 500 :: 9536 / 15539 - CLASS_LOSS : 0.18805
167 / 500 :: 10176 / 15539 - CLASS_LOSS : 0.10029
167 / 500 :: 10816 / 15539 - CLASS_LOSS : 0.1414
167 / 500 :: 11456 / 15539 - CLASS_LOSS : 0.18169
167 / 500 :: 12096 / 15539 - CLASS_LOSS : 0.16229
167 / 500 :: 12736 / 15539 - CLASS_LOSS : 0.16882
167 / 500 :: 13376 / 15539 - CLASS_LOSS : 0.23586
167 / 500 :: 14016 / 15539 - CLASS_LOSS : 0.18618
167 / 500 :: 14656 / 15539 - CLASS_LOSS : 0.11601
167 / 500 :: 15296 / 15539 - CLASS_LOSS : 0.15364
168 / 500 :: 384 / 15539 - CLASS_LOSS : 0.22237
168 / 500 :: 1024 / 15539 - CLASS_LOSS : 0.21742
168 / 500 :: 1664 / 15539 - CLASS_LOSS : 0.14162
168 / 500 :: 2304 / 15539 - CLASS_LOSS : 0.16746
168 / 500 :: 2944 / 15539 - CLASS_LOSS : 0.19141
168 / 500 :: 3584 / 15539 - CLASS_LOSS : 0.23455
168 / 500 :: 4224 / 15539 - CLASS_LOSS : 0.08733
168 / 500 :: 4864 / 15539 - CLASS_LOSS : 0.15816
168 / 500 :: 5504 / 15539 - CLASS_LOSS : 0.33825
168 / 500 :: 6144 / 15539 - CLASS_LOSS : 0.17198
168 / 500 :: 6784 / 15539 - CLASS_LOSS : 0.11428
168 / 500 :: 7424 / 15539 - CLASS_LOSS : 0.14529
168 / 500 :: 8064 / 15539 - CLASS_LOSS : 0.22165
168 / 500 :: 8704 / 15539 - CLASS_LOSS : 0.1208
168 / 500 :: 9344 / 15539 - CLASS_LOSS : 0.18257
168 / 500 :: 9984 / 15539 - CLASS_LOSS : 0.11059
168 / 500 :: 10624 / 15539 - CLASS_LOSS : 0.24958
168 / 500 :: 11264 / 15539 - CLASS_LOSS : 0.13708
168 / 500 :: 11904 / 15539 - CLASS_LOSS : 0.21635
168 / 500 :: 12544 / 15539 - CLASS_LOSS : 0.25947
168 / 500 :: 13184 / 15539 - CLASS_LOSS : 0.21059
168 / 500 :: 13824 / 15539 - CLASS_LOSS : 0.21561
168 / 500 :: 14464 / 15539 - CLASS_LOSS : 0.20672
168 / 500 :: 15104 / 15539 - CLASS_LOSS : 0.2044
169 / 500 :: 192 / 15539 - CLASS_LOSS : 0.11249
169 / 500 :: 832 / 15539 - CLASS_LOSS : 0.18922
169 / 500 :: 1472 / 15539 - CLASS_LOSS : 0.15372
169 / 500 :: 2112 / 15539 - CLASS_LOSS : 0.15453
169 / 500 :: 2752 / 15539 - CLASS_LOSS : 0.21877
169 / 500 :: 3392 / 15539 - CLASS_LOSS : 0.16111
169 / 500 :: 4032 / 15539 - CLASS_LOSS : 0.15662
169 / 500 :: 4672 / 15539 - CLASS_LOSS : 0.14919
169 / 500 :: 5312 / 15539 - CLASS_LOSS : 0.12498
169 / 500 :: 5952 / 15539 - CLASS_LOSS : 0.20207
169 / 500 :: 6592 / 15539 - CLASS_LOSS : 0.13513
169 / 500 :: 7232 / 15539 - CLASS_LOSS : 0.16048
169 / 500 :: 7872 / 15539 - CLASS_LOSS : 0.10813
169 / 500 :: 8512 / 15539 - CLASS_LOSS : 0.13975
169 / 500 :: 9152 / 15539 - CLASS_LOSS : 0.11036
169 / 500 :: 9792 / 15539 - CLASS_LOSS : 0.17751
169 / 500 :: 10432 / 15539 - CLASS_LOSS : 0.1986
169 / 500 :: 11072 / 15539 - CLASS_LOSS : 0.23526
169 / 500 :: 11712 / 15539 - CLASS_LOSS : 0.1977
169 / 500 :: 12352 / 15539 - CLASS_LOSS : 0.13251
169 / 500 :: 12992 / 15539 - CLASS_LOSS : 0.19512
169 / 500 :: 13632 / 15539 - CLASS_LOSS : 0.08766
169 / 500 :: 14272 / 15539 - CLASS_LOSS : 0.23788
169 / 500 :: 14912 / 15539 - CLASS_LOSS : 0.16211
169 / 500 :: 15539 / 15539 - CLASS_LOSS : 0.23457
170 / 500 :: 640 / 15539 - CLASS_LOSS : 0.16985
170 / 500 :: 1280 / 15539 - CLASS_LOSS : 0.12595
170 / 500 :: 1920 / 15539 - CLASS_LOSS : 0.12034
170 / 500 :: 2560 / 15539 - CLASS_LOSS : 0.12123
170 / 500 :: 3200 / 15539 - CLASS_LOSS : 0.23351
170 / 500 :: 3840 / 15539 - CLASS_LOSS : 0.11852
170 / 500 :: 4480 / 15539 - CLASS_LOSS : 0.20566
170 / 500 :: 5120 / 15539 - CLASS_LOSS : 0.21967
170 / 500 :: 5760 / 15539 - CLASS_LOSS : 0.14737
170 / 500 :: 6400 / 15539 - CLASS_LOSS : 0.22944
170 / 500 :: 7040 / 15539 - CLASS_LOSS : 0.12525
170 / 500 :: 7680 / 15539 - CLASS_LOSS : 0.23498
170 / 500 :: 8320 / 15539 - CLASS_LOSS : 0.14757
170 / 500 :: 8960 / 15539 - CLASS_LOSS : 0.15055
170 / 500 :: 9600 / 15539 - CLASS_LOSS : 0.18669
170 / 500 :: 10240 / 15539 - CLASS_LOSS : 0.13409
170 / 500 :: 10880 / 15539 - CLASS_LOSS : 0.17111
170 / 500 :: 11520 / 15539 - CLASS_LOSS : 0.22103
170 / 500 :: 12160 / 15539 - CLASS_LOSS : 0.16555
170 / 500 :: 12800 / 15539 - CLASS_LOSS : 0.25934
170 / 500 :: 13440 / 15539 - CLASS_LOSS : 0.19875
170 / 500 :: 14080 / 15539 - CLASS_LOSS : 0.14855
170 / 500 :: 14720 / 15539 - CLASS_LOSS : 0.30822
170 / 500 :: 15360 / 15539 - CLASS_LOSS : 0.1237
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.5439860994916018 0.449192354720381 0.38095115515798955
PSPrecision@1,3,5: 0.38979571529036955 0.41930243860271804 0.4379474619263457
testing....
Precision@1,3,5: 0.47151483328957733 0.371663603745515 0.3108427408768706
PSPrecision@1,3,5: 0.27801928167830725 0.30099144898996827 0.3131030568303424
171 / 500 :: 448 / 15539 - CLASS_LOSS : 0.10459
171 / 500 :: 1088 / 15539 - CLASS_LOSS : 0.14132
171 / 500 :: 1728 / 15539 - CLASS_LOSS : 0.17015
171 / 500 :: 2368 / 15539 - CLASS_LOSS : 0.1692
171 / 500 :: 3008 / 15539 - CLASS_LOSS : 0.17262
171 / 500 :: 3648 / 15539 - CLASS_LOSS : 0.12212
171 / 500 :: 4288 / 15539 - CLASS_LOSS : 0.19624
171 / 500 :: 4928 / 15539 - CLASS_LOSS : 0.16929
171 / 500 :: 5568 / 15539 - CLASS_LOSS : 0.11073
171 / 500 :: 6208 / 15539 - CLASS_LOSS : 0.15594
171 / 500 :: 6848 / 15539 - CLASS_LOSS : 0.18177
171 / 500 :: 7488 / 15539 - CLASS_LOSS : 0.19226
171 / 500 :: 8128 / 15539 - CLASS_LOSS : 0.13644
171 / 500 :: 8768 / 15539 - CLASS_LOSS : 0.17824
171 / 500 :: 9408 / 15539 - CLASS_LOSS : 0.16134
171 / 500 :: 10048 / 15539 - CLASS_LOSS : 0.19257
171 / 500 :: 10688 / 15539 - CLASS_LOSS : 0.23268
171 / 500 :: 11328 / 15539 - CLASS_LOSS : 0.18124
171 / 500 :: 11968 / 15539 - CLASS_LOSS : 0.23952
171 / 500 :: 12608 / 15539 - CLASS_LOSS : 0.14534
171 / 500 :: 13248 / 15539 - CLASS_LOSS : 0.10162
171 / 500 :: 13888 / 15539 - CLASS_LOSS : 0.15489
171 / 500 :: 14528 / 15539 - CLASS_LOSS : 0.10102
171 / 500 :: 15168 / 15539 - CLASS_LOSS : 0.27581
172 / 500 :: 256 / 15539 - CLASS_LOSS : 0.14415
172 / 500 :: 896 / 15539 - CLASS_LOSS : 0.21459
172 / 500 :: 1536 / 15539 - CLASS_LOSS : 0.19108
172 / 500 :: 2176 / 15539 - CLASS_LOSS : 0.1259
172 / 500 :: 2816 / 15539 - CLASS_LOSS : 0.1229
172 / 500 :: 3456 / 15539 - CLASS_LOSS : 0.19757
172 / 500 :: 4096 / 15539 - CLASS_LOSS : 0.18411
172 / 500 :: 4736 / 15539 - CLASS_LOSS : 0.17552
172 / 500 :: 5376 / 15539 - CLASS_LOSS : 0.11311
172 / 500 :: 6016 / 15539 - CLASS_LOSS : 0.09153
172 / 500 :: 6656 / 15539 - CLASS_LOSS : 0.22421
172 / 500 :: 7296 / 15539 - CLASS_LOSS : 0.28496
172 / 500 :: 7936 / 15539 - CLASS_LOSS : 0.14294
172 / 500 :: 8576 / 15539 - CLASS_LOSS : 0.20582
172 / 500 :: 9216 / 15539 - CLASS_LOSS : 0.19135
172 / 500 :: 9856 / 15539 - CLASS_LOSS : 0.20308
172 / 500 :: 10496 / 15539 - CLASS_LOSS : 0.09177
172 / 500 :: 11136 / 15539 - CLASS_LOSS : 0.23776
172 / 500 :: 11776 / 15539 - CLASS_LOSS : 0.14609
172 / 500 :: 12416 / 15539 - CLASS_LOSS : 0.30864
172 / 500 :: 13056 / 15539 - CLASS_LOSS : 0.146
172 / 500 :: 13696 / 15539 - CLASS_LOSS : 0.14211
172 / 500 :: 14336 / 15539 - CLASS_LOSS : 0.14857
172 / 500 :: 14976 / 15539 - CLASS_LOSS : 0.24296
173 / 500 :: 64 / 15539 - CLASS_LOSS : 0.20436
173 / 500 :: 704 / 15539 - CLASS_LOSS : 0.2122
173 / 500 :: 1344 / 15539 - CLASS_LOSS : 0.12734
173 / 500 :: 1984 / 15539 - CLASS_LOSS : 0.13757
173 / 500 :: 2624 / 15539 - CLASS_LOSS : 0.16488
173 / 500 :: 3264 / 15539 - CLASS_LOSS : 0.22616
173 / 500 :: 3904 / 15539 - CLASS_LOSS : 0.16409
173 / 500 :: 4544 / 15539 - CLASS_LOSS : 0.14516
173 / 500 :: 5184 / 15539 - CLASS_LOSS : 0.10867
173 / 500 :: 5824 / 15539 - CLASS_LOSS : 0.11836
173 / 500 :: 6464 / 15539 - CLASS_LOSS : 0.15277
173 / 500 :: 7104 / 15539 - CLASS_LOSS : 0.21779
173 / 500 :: 7744 / 15539 - CLASS_LOSS : 0.21087
173 / 500 :: 8384 / 15539 - CLASS_LOSS : 0.41496
173 / 500 :: 9024 / 15539 - CLASS_LOSS : 0.29757
173 / 500 :: 9664 / 15539 - CLASS_LOSS : 0.09538
173 / 500 :: 10304 / 15539 - CLASS_LOSS : 0.27825
173 / 500 :: 10944 / 15539 - CLASS_LOSS : 0.14388
173 / 500 :: 11584 / 15539 - CLASS_LOSS : 0.12865
173 / 500 :: 12224 / 15539 - CLASS_LOSS : 0.23801
173 / 500 :: 12864 / 15539 - CLASS_LOSS : 0.20209
173 / 500 :: 13504 / 15539 - CLASS_LOSS : 0.24625
173 / 500 :: 14144 / 15539 - CLASS_LOSS : 0.09508
173 / 500 :: 14784 / 15539 - CLASS_LOSS : 0.13307
173 / 500 :: 15424 / 15539 - CLASS_LOSS : 0.16952
174 / 500 :: 512 / 15539 - CLASS_LOSS : 0.12017
174 / 500 :: 1152 / 15539 - CLASS_LOSS : 0.17176
174 / 500 :: 1792 / 15539 - CLASS_LOSS : 0.17078
174 / 500 :: 2432 / 15539 - CLASS_LOSS : 0.17355
174 / 500 :: 3072 / 15539 - CLASS_LOSS : 0.10948
174 / 500 :: 3712 / 15539 - CLASS_LOSS : 0.18983
174 / 500 :: 4352 / 15539 - CLASS_LOSS : 0.16365
174 / 500 :: 4992 / 15539 - CLASS_LOSS : 0.14879
174 / 500 :: 5632 / 15539 - CLASS_LOSS : 0.30122
174 / 500 :: 6272 / 15539 - CLASS_LOSS : 0.16585
174 / 500 :: 6912 / 15539 - CLASS_LOSS : 0.16227
174 / 500 :: 7552 / 15539 - CLASS_LOSS : 0.17227
174 / 500 :: 8192 / 15539 - CLASS_LOSS : 0.13854
174 / 500 :: 8832 / 15539 - CLASS_LOSS : 0.11908
174 / 500 :: 9472 / 15539 - CLASS_LOSS : 0.22497
174 / 500 :: 10112 / 15539 - CLASS_LOSS : 0.1416
174 / 500 :: 10752 / 15539 - CLASS_LOSS : 0.09835
174 / 500 :: 11392 / 15539 - CLASS_LOSS : 0.11269
174 / 500 :: 12032 / 15539 - CLASS_LOSS : 0.08307
174 / 500 :: 12672 / 15539 - CLASS_LOSS : 0.18768
174 / 500 :: 13312 / 15539 - CLASS_LOSS : 0.11888
174 / 500 :: 13952 / 15539 - CLASS_LOSS : 0.11953
174 / 500 :: 14592 / 15539 - CLASS_LOSS : 0.24686
174 / 500 :: 15232 / 15539 - CLASS_LOSS : 0.20289
175 / 500 :: 320 / 15539 - CLASS_LOSS : 0.12636
175 / 500 :: 960 / 15539 - CLASS_LOSS : 0.1317
175 / 500 :: 1600 / 15539 - CLASS_LOSS : 0.18459
175 / 500 :: 2240 / 15539 - CLASS_LOSS : 0.14317
175 / 500 :: 2880 / 15539 - CLASS_LOSS : 0.1875
175 / 500 :: 3520 / 15539 - CLASS_LOSS : 0.18158
175 / 500 :: 4160 / 15539 - CLASS_LOSS : 0.14507
175 / 500 :: 4800 / 15539 - CLASS_LOSS : 0.165
175 / 500 :: 5440 / 15539 - CLASS_LOSS : 0.13786
175 / 500 :: 6080 / 15539 - CLASS_LOSS : 0.16901
175 / 500 :: 6720 / 15539 - CLASS_LOSS : 0.17368
175 / 500 :: 7360 / 15539 - CLASS_LOSS : 0.20675
175 / 500 :: 8000 / 15539 - CLASS_LOSS : 0.14571
175 / 500 :: 8640 / 15539 - CLASS_LOSS : 0.17094
175 / 500 :: 9280 / 15539 - CLASS_LOSS : 0.21381
175 / 500 :: 9920 / 15539 - CLASS_LOSS : 0.1602
175 / 500 :: 10560 / 15539 - CLASS_LOSS : 0.16128
175 / 500 :: 11200 / 15539 - CLASS_LOSS : 0.14376
175 / 500 :: 11840 / 15539 - CLASS_LOSS : 0.14187
175 / 500 :: 12480 / 15539 - CLASS_LOSS : 0.17507
175 / 500 :: 13120 / 15539 - CLASS_LOSS : 0.19387
175 / 500 :: 13760 / 15539 - CLASS_LOSS : 0.12197
175 / 500 :: 14400 / 15539 - CLASS_LOSS : 0.15134
175 / 500 :: 15040 / 15539 - CLASS_LOSS : 0.18483
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.5356844069759958 0.4444730463135766 0.38012742132698374
PSPrecision@1,3,5: 0.38576601224949353 0.41550514417211226 0.43523933701649603
testing....
Precision@1,3,5: 0.4678393279075873 0.3735888684694145 0.31331058020477814
PSPrecision@1,3,5: 0.2815487175845458 0.3006102568107956 0.3143728054153524
176 / 500 :: 128 / 15539 - CLASS_LOSS : 0.16824
176 / 500 :: 768 / 15539 - CLASS_LOSS : 0.13064
176 / 500 :: 1408 / 15539 - CLASS_LOSS : 0.19161
176 / 500 :: 2048 / 15539 - CLASS_LOSS : 0.21253
176 / 500 :: 2688 / 15539 - CLASS_LOSS : 0.13211
176 / 500 :: 3328 / 15539 - CLASS_LOSS : 0.15268
176 / 500 :: 3968 / 15539 - CLASS_LOSS : 0.34389
176 / 500 :: 4608 / 15539 - CLASS_LOSS : 0.10291
176 / 500 :: 5248 / 15539 - CLASS_LOSS : 0.23765
176 / 500 :: 5888 / 15539 - CLASS_LOSS : 0.17956
176 / 500 :: 6528 / 15539 - CLASS_LOSS : 0.11393
176 / 500 :: 7168 / 15539 - CLASS_LOSS : 0.15104
176 / 500 :: 7808 / 15539 - CLASS_LOSS : 0.21375
176 / 500 :: 8448 / 15539 - CLASS_LOSS : 0.09777
176 / 500 :: 9088 / 15539 - CLASS_LOSS : 0.11162
176 / 500 :: 9728 / 15539 - CLASS_LOSS : 0.24784
176 / 500 :: 10368 / 15539 - CLASS_LOSS : 0.18696
176 / 500 :: 11008 / 15539 - CLASS_LOSS : 0.16002
176 / 500 :: 11648 / 15539 - CLASS_LOSS : 0.22608
176 / 500 :: 12288 / 15539 - CLASS_LOSS : 0.2939
176 / 500 :: 12928 / 15539 - CLASS_LOSS : 0.19046
176 / 500 :: 13568 / 15539 - CLASS_LOSS : 0.16017
176 / 500 :: 14208 / 15539 - CLASS_LOSS : 0.13994
176 / 500 :: 14848 / 15539 - CLASS_LOSS : 0.29298
176 / 500 :: 15488 / 15539 - CLASS_LOSS : 0.14966
177 / 500 :: 576 / 15539 - CLASS_LOSS : 0.18403
177 / 500 :: 1216 / 15539 - CLASS_LOSS : 0.06566
177 / 500 :: 1856 / 15539 - CLASS_LOSS : 0.21038
177 / 500 :: 2496 / 15539 - CLASS_LOSS : 0.06595
177 / 500 :: 3136 / 15539 - CLASS_LOSS : 0.19075
177 / 500 :: 3776 / 15539 - CLASS_LOSS : 0.12545
177 / 500 :: 4416 / 15539 - CLASS_LOSS : 0.15265
177 / 500 :: 5056 / 15539 - CLASS_LOSS : 0.13657
177 / 500 :: 5696 / 15539 - CLASS_LOSS : 0.17206
177 / 500 :: 6336 / 15539 - CLASS_LOSS : 0.15451
177 / 500 :: 6976 / 15539 - CLASS_LOSS : 0.26509
177 / 500 :: 7616 / 15539 - CLASS_LOSS : 0.137
177 / 500 :: 8256 / 15539 - CLASS_LOSS : 0.13349
177 / 500 :: 8896 / 15539 - CLASS_LOSS : 0.12764
177 / 500 :: 9536 / 15539 - CLASS_LOSS : 0.14987
177 / 500 :: 10176 / 15539 - CLASS_LOSS : 0.14973
177 / 500 :: 10816 / 15539 - CLASS_LOSS : 0.2076
177 / 500 :: 11456 / 15539 - CLASS_LOSS : 0.11531
177 / 500 :: 12096 / 15539 - CLASS_LOSS : 0.08023
177 / 500 :: 12736 / 15539 - CLASS_LOSS : 0.18074
177 / 500 :: 13376 / 15539 - CLASS_LOSS : 0.24378
177 / 500 :: 14016 / 15539 - CLASS_LOSS : 0.2058
177 / 500 :: 14656 / 15539 - CLASS_LOSS : 0.09918
177 / 500 :: 15296 / 15539 - CLASS_LOSS : 0.16972
178 / 500 :: 384 / 15539 - CLASS_LOSS : 0.1503
178 / 500 :: 1024 / 15539 - CLASS_LOSS : 0.13759
178 / 500 :: 1664 / 15539 - CLASS_LOSS : 0.15569
178 / 500 :: 2304 / 15539 - CLASS_LOSS : 0.11326
178 / 500 :: 2944 / 15539 - CLASS_LOSS : 0.14482
178 / 500 :: 3584 / 15539 - CLASS_LOSS : 0.21157
178 / 500 :: 4224 / 15539 - CLASS_LOSS : 0.1701
178 / 500 :: 4864 / 15539 - CLASS_LOSS : 0.31042
178 / 500 :: 5504 / 15539 - CLASS_LOSS : 0.19417
178 / 500 :: 6144 / 15539 - CLASS_LOSS : 0.16563
178 / 500 :: 6784 / 15539 - CLASS_LOSS : 0.10464
178 / 500 :: 7424 / 15539 - CLASS_LOSS : 0.23412
178 / 500 :: 8064 / 15539 - CLASS_LOSS : 0.16132
178 / 500 :: 8704 / 15539 - CLASS_LOSS : 0.19167
178 / 500 :: 9344 / 15539 - CLASS_LOSS : 0.11831
178 / 500 :: 9984 / 15539 - CLASS_LOSS : 0.20762
178 / 500 :: 10624 / 15539 - CLASS_LOSS : 0.12334
178 / 500 :: 11264 / 15539 - CLASS_LOSS : 0.2744
178 / 500 :: 11904 / 15539 - CLASS_LOSS : 0.13365
178 / 500 :: 12544 / 15539 - CLASS_LOSS : 0.26892
178 / 500 :: 13184 / 15539 - CLASS_LOSS : 0.26479
178 / 500 :: 13824 / 15539 - CLASS_LOSS : 0.1934
178 / 500 :: 14464 / 15539 - CLASS_LOSS : 0.20016
178 / 500 :: 15104 / 15539 - CLASS_LOSS : 0.14037
179 / 500 :: 192 / 15539 - CLASS_LOSS : 0.15642
179 / 500 :: 832 / 15539 - CLASS_LOSS : 0.16965
179 / 500 :: 1472 / 15539 - CLASS_LOSS : 0.19295
179 / 500 :: 2112 / 15539 - CLASS_LOSS : 0.13683
179 / 500 :: 2752 / 15539 - CLASS_LOSS : 0.13998
179 / 500 :: 3392 / 15539 - CLASS_LOSS : 0.12312
179 / 500 :: 4032 / 15539 - CLASS_LOSS : 0.19445
179 / 500 :: 4672 / 15539 - CLASS_LOSS : 0.24485
179 / 500 :: 5312 / 15539 - CLASS_LOSS : 0.21878
179 / 500 :: 5952 / 15539 - CLASS_LOSS : 0.15405
179 / 500 :: 6592 / 15539 - CLASS_LOSS : 0.19238
179 / 500 :: 7232 / 15539 - CLASS_LOSS : 0.17687
179 / 500 :: 7872 / 15539 - CLASS_LOSS : 0.20493
179 / 500 :: 8512 / 15539 - CLASS_LOSS : 0.17
179 / 500 :: 9152 / 15539 - CLASS_LOSS : 0.15965
179 / 500 :: 9792 / 15539 - CLASS_LOSS : 0.20723
179 / 500 :: 10432 / 15539 - CLASS_LOSS : 0.12914
179 / 500 :: 11072 / 15539 - CLASS_LOSS : 0.16391
179 / 500 :: 11712 / 15539 - CLASS_LOSS : 0.16466
179 / 500 :: 12352 / 15539 - CLASS_LOSS : 0.12701
179 / 500 :: 12992 / 15539 - CLASS_LOSS : 0.14944
179 / 500 :: 13632 / 15539 - CLASS_LOSS : 0.23191
179 / 500 :: 14272 / 15539 - CLASS_LOSS : 0.21997
179 / 500 :: 14912 / 15539 - CLASS_LOSS : 0.21076
179 / 500 :: 15539 / 15539 - CLASS_LOSS : 0.29458
180 / 500 :: 640 / 15539 - CLASS_LOSS : 0.11849
180 / 500 :: 1280 / 15539 - CLASS_LOSS : 0.19295
180 / 500 :: 1920 / 15539 - CLASS_LOSS : 0.17269
180 / 500 :: 2560 / 15539 - CLASS_LOSS : 0.15821
180 / 500 :: 3200 / 15539 - CLASS_LOSS : 0.18887
180 / 500 :: 3840 / 15539 - CLASS_LOSS : 0.13166
180 / 500 :: 4480 / 15539 - CLASS_LOSS : 0.1443
180 / 500 :: 5120 / 15539 - CLASS_LOSS : 0.09567
180 / 500 :: 5760 / 15539 - CLASS_LOSS : 0.13639
180 / 500 :: 6400 / 15539 - CLASS_LOSS : 0.20515
180 / 500 :: 7040 / 15539 - CLASS_LOSS : 0.15307
180 / 500 :: 7680 / 15539 - CLASS_LOSS : 0.24459
180 / 500 :: 8320 / 15539 - CLASS_LOSS : 0.17541
180 / 500 :: 8960 / 15539 - CLASS_LOSS : 0.171
180 / 500 :: 9600 / 15539 - CLASS_LOSS : 0.08083
180 / 500 :: 10240 / 15539 - CLASS_LOSS : 0.14951
180 / 500 :: 10880 / 15539 - CLASS_LOSS : 0.17182
180 / 500 :: 11520 / 15539 - CLASS_LOSS : 0.16633
180 / 500 :: 12160 / 15539 - CLASS_LOSS : 0.19677
180 / 500 :: 12800 / 15539 - CLASS_LOSS : 0.27536
180 / 500 :: 13440 / 15539 - CLASS_LOSS : 0.14138
180 / 500 :: 14080 / 15539 - CLASS_LOSS : 0.11191
180 / 500 :: 14720 / 15539 - CLASS_LOSS : 0.21952
180 / 500 :: 15360 / 15539 - CLASS_LOSS : 0.11913
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.5257738593217067 0.44260677435270396 0.3795868460003861
PSPrecision@1,3,5: 0.38109547306136354 0.4150336686388767 0.4348420672405439
testing....
Precision@1,3,5: 0.44867419270149644 0.3622123041918264 0.3136781307429772
PSPrecision@1,3,5: 0.27156958786983504 0.2945538599406239 0.31585546396633357
181 / 500 :: 448 / 15539 - CLASS_LOSS : 0.22793
181 / 500 :: 1088 / 15539 - CLASS_LOSS : 0.15379
181 / 500 :: 1728 / 15539 - CLASS_LOSS : 0.17894
181 / 500 :: 2368 / 15539 - CLASS_LOSS : 0.10707
181 / 500 :: 3008 / 15539 - CLASS_LOSS : 0.2112
181 / 500 :: 3648 / 15539 - CLASS_LOSS : 0.10291
181 / 500 :: 4288 / 15539 - CLASS_LOSS : 0.16051
181 / 500 :: 4928 / 15539 - CLASS_LOSS : 0.16189
181 / 500 :: 5568 / 15539 - CLASS_LOSS : 0.13297
181 / 500 :: 6208 / 15539 - CLASS_LOSS : 0.19996
181 / 500 :: 6848 / 15539 - CLASS_LOSS : 0.25136
181 / 500 :: 7488 / 15539 - CLASS_LOSS : 0.13532
181 / 500 :: 8128 / 15539 - CLASS_LOSS : 0.09754
181 / 500 :: 8768 / 15539 - CLASS_LOSS : 0.17053
181 / 500 :: 9408 / 15539 - CLASS_LOSS : 0.18787
181 / 500 :: 10048 / 15539 - CLASS_LOSS : 0.19315
181 / 500 :: 10688 / 15539 - CLASS_LOSS : 0.22174
181 / 500 :: 11328 / 15539 - CLASS_LOSS : 0.08006
181 / 500 :: 11968 / 15539 - CLASS_LOSS : 0.23436
181 / 500 :: 12608 / 15539 - CLASS_LOSS : 0.17676
181 / 500 :: 13248 / 15539 - CLASS_LOSS : 0.20032
181 / 500 :: 13888 / 15539 - CLASS_LOSS : 0.24929
181 / 500 :: 14528 / 15539 - CLASS_LOSS : 0.14118
181 / 500 :: 15168 / 15539 - CLASS_LOSS : 0.14093
182 / 500 :: 256 / 15539 - CLASS_LOSS : 0.17024
182 / 500 :: 896 / 15539 - CLASS_LOSS : 0.22655
182 / 500 :: 1536 / 15539 - CLASS_LOSS : 0.15537
182 / 500 :: 2176 / 15539 - CLASS_LOSS : 0.08749
182 / 500 :: 2816 / 15539 - CLASS_LOSS : 0.17751
182 / 500 :: 3456 / 15539 - CLASS_LOSS : 0.0938
182 / 500 :: 4096 / 15539 - CLASS_LOSS : 0.11529
182 / 500 :: 4736 / 15539 - CLASS_LOSS : 0.16048
182 / 500 :: 5376 / 15539 - CLASS_LOSS : 0.10077
182 / 500 :: 6016 / 15539 - CLASS_LOSS : 0.11521
182 / 500 :: 6656 / 15539 - CLASS_LOSS : 0.18695
182 / 500 :: 7296 / 15539 - CLASS_LOSS : 0.15306
182 / 500 :: 7936 / 15539 - CLASS_LOSS : 0.14868
182 / 500 :: 8576 / 15539 - CLASS_LOSS : 0.20256
182 / 500 :: 9216 / 15539 - CLASS_LOSS : 0.17422
182 / 500 :: 9856 / 15539 - CLASS_LOSS : 0.17377
182 / 500 :: 10496 / 15539 - CLASS_LOSS : 0.12833
182 / 500 :: 11136 / 15539 - CLASS_LOSS : 0.21357
182 / 500 :: 11776 / 15539 - CLASS_LOSS : 0.16667
182 / 500 :: 12416 / 15539 - CLASS_LOSS : 0.12241
182 / 500 :: 13056 / 15539 - CLASS_LOSS : 0.23015
182 / 500 :: 13696 / 15539 - CLASS_LOSS : 0.17662
182 / 500 :: 14336 / 15539 - CLASS_LOSS : 0.16012
182 / 500 :: 14976 / 15539 - CLASS_LOSS : 0.2195
183 / 500 :: 64 / 15539 - CLASS_LOSS : 0.18165
183 / 500 :: 704 / 15539 - CLASS_LOSS : 0.11609
183 / 500 :: 1344 / 15539 - CLASS_LOSS : 0.08229
183 / 500 :: 1984 / 15539 - CLASS_LOSS : 0.16463
183 / 500 :: 2624 / 15539 - CLASS_LOSS : 0.13907
183 / 500 :: 3264 / 15539 - CLASS_LOSS : 0.18056
183 / 500 :: 3904 / 15539 - CLASS_LOSS : 0.21874
183 / 500 :: 4544 / 15539 - CLASS_LOSS : 0.20323
183 / 500 :: 5184 / 15539 - CLASS_LOSS : 0.17789
183 / 500 :: 5824 / 15539 - CLASS_LOSS : 0.17935
183 / 500 :: 6464 / 15539 - CLASS_LOSS : 0.11605
183 / 500 :: 7104 / 15539 - CLASS_LOSS : 0.21731
183 / 500 :: 7744 / 15539 - CLASS_LOSS : 0.08702
183 / 500 :: 8384 / 15539 - CLASS_LOSS : 0.10628
183 / 500 :: 9024 / 15539 - CLASS_LOSS : 0.18198
183 / 500 :: 9664 / 15539 - CLASS_LOSS : 0.2817
183 / 500 :: 10304 / 15539 - CLASS_LOSS : 0.121
183 / 500 :: 10944 / 15539 - CLASS_LOSS : 0.24892
183 / 500 :: 11584 / 15539 - CLASS_LOSS : 0.20061
183 / 500 :: 12224 / 15539 - CLASS_LOSS : 0.15173
183 / 500 :: 12864 / 15539 - CLASS_LOSS : 0.14778
183 / 500 :: 13504 / 15539 - CLASS_LOSS : 0.22472
183 / 500 :: 14144 / 15539 - CLASS_LOSS : 0.14903
183 / 500 :: 14784 / 15539 - CLASS_LOSS : 0.20229
183 / 500 :: 15424 / 15539 - CLASS_LOSS : 0.19272
184 / 500 :: 512 / 15539 - CLASS_LOSS : 0.21611
184 / 500 :: 1152 / 15539 - CLASS_LOSS : 0.13142
184 / 500 :: 1792 / 15539 - CLASS_LOSS : 0.18485
184 / 500 :: 2432 / 15539 - CLASS_LOSS : 0.08492
184 / 500 :: 3072 / 15539 - CLASS_LOSS : 0.12973
184 / 500 :: 3712 / 15539 - CLASS_LOSS : 0.10491
184 / 500 :: 4352 / 15539 - CLASS_LOSS : 0.14402
184 / 500 :: 4992 / 15539 - CLASS_LOSS : 0.24748
184 / 500 :: 5632 / 15539 - CLASS_LOSS : 0.13959
184 / 500 :: 6272 / 15539 - CLASS_LOSS : 0.174
184 / 500 :: 6912 / 15539 - CLASS_LOSS : 0.16437
184 / 500 :: 7552 / 15539 - CLASS_LOSS : 0.12279
184 / 500 :: 8192 / 15539 - CLASS_LOSS : 0.13314
184 / 500 :: 8832 / 15539 - CLASS_LOSS : 0.1588
184 / 500 :: 9472 / 15539 - CLASS_LOSS : 0.13762
184 / 500 :: 10112 / 15539 - CLASS_LOSS : 0.20215
184 / 500 :: 10752 / 15539 - CLASS_LOSS : 0.18382
184 / 500 :: 11392 / 15539 - CLASS_LOSS : 0.20581
184 / 500 :: 12032 / 15539 - CLASS_LOSS : 0.1977
184 / 500 :: 12672 / 15539 - CLASS_LOSS : 0.18649
184 / 500 :: 13312 / 15539 - CLASS_LOSS : 0.24149
184 / 500 :: 13952 / 15539 - CLASS_LOSS : 0.16599
184 / 500 :: 14592 / 15539 - CLASS_LOSS : 0.19765
184 / 500 :: 15232 / 15539 - CLASS_LOSS : 0.1854
185 / 500 :: 320 / 15539 - CLASS_LOSS : 0.1496
185 / 500 :: 960 / 15539 - CLASS_LOSS : 0.10837
185 / 500 :: 1600 / 15539 - CLASS_LOSS : 0.19971
185 / 500 :: 2240 / 15539 - CLASS_LOSS : 0.19168
185 / 500 :: 2880 / 15539 - CLASS_LOSS : 0.1372
185 / 500 :: 3520 / 15539 - CLASS_LOSS : 0.24112
185 / 500 :: 4160 / 15539 - CLASS_LOSS : 0.14315
185 / 500 :: 4800 / 15539 - CLASS_LOSS : 0.13176
185 / 500 :: 5440 / 15539 - CLASS_LOSS : 0.17582
185 / 500 :: 6080 / 15539 - CLASS_LOSS : 0.12422
185 / 500 :: 6720 / 15539 - CLASS_LOSS : 0.1622
185 / 500 :: 7360 / 15539 - CLASS_LOSS : 0.24258
185 / 500 :: 8000 / 15539 - CLASS_LOSS : 0.17552
185 / 500 :: 8640 / 15539 - CLASS_LOSS : 0.19937
185 / 500 :: 9280 / 15539 - CLASS_LOSS : 0.16494
185 / 500 :: 9920 / 15539 - CLASS_LOSS : 0.1272
185 / 500 :: 10560 / 15539 - CLASS_LOSS : 0.18572
185 / 500 :: 11200 / 15539 - CLASS_LOSS : 0.15258
185 / 500 :: 11840 / 15539 - CLASS_LOSS : 0.13857
185 / 500 :: 12480 / 15539 - CLASS_LOSS : 0.22178
185 / 500 :: 13120 / 15539 - CLASS_LOSS : 0.19082
185 / 500 :: 13760 / 15539 - CLASS_LOSS : 0.13811
185 / 500 :: 14400 / 15539 - CLASS_LOSS : 0.15427
185 / 500 :: 15040 / 15539 - CLASS_LOSS : 0.21571
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.5375506789368685 0.4504150846257803 0.3855460454340691
PSPrecision@1,3,5: 0.3886869801806226 0.4207829889593012 0.4432744990724734
testing....
Precision@1,3,5: 0.4749278025728538 0.37035092325194713 0.3144657390391179
PSPrecision@1,3,5: 0.2832103961518973 0.2983054767652514 0.31443495808871486
186 / 500 :: 128 / 15539 - CLASS_LOSS : 0.24697
186 / 500 :: 768 / 15539 - CLASS_LOSS : 0.18381
186 / 500 :: 1408 / 15539 - CLASS_LOSS : 0.25273
186 / 500 :: 2048 / 15539 - CLASS_LOSS : 0.16052
186 / 500 :: 2688 / 15539 - CLASS_LOSS : 0.18758
186 / 500 :: 3328 / 15539 - CLASS_LOSS : 0.22312
186 / 500 :: 3968 / 15539 - CLASS_LOSS : 0.20177
186 / 500 :: 4608 / 15539 - CLASS_LOSS : 0.15758
186 / 500 :: 5248 / 15539 - CLASS_LOSS : 0.11417
186 / 500 :: 5888 / 15539 - CLASS_LOSS : 0.14903
186 / 500 :: 6528 / 15539 - CLASS_LOSS : 0.16766
186 / 500 :: 7168 / 15539 - CLASS_LOSS : 0.22056
186 / 500 :: 7808 / 15539 - CLASS_LOSS : 0.17471
186 / 500 :: 8448 / 15539 - CLASS_LOSS : 0.20835
186 / 500 :: 9088 / 15539 - CLASS_LOSS : 0.13626
186 / 500 :: 9728 / 15539 - CLASS_LOSS : 0.12356
186 / 500 :: 10368 / 15539 - CLASS_LOSS : 0.20247
186 / 500 :: 11008 / 15539 - CLASS_LOSS : 0.17188
186 / 500 :: 11648 / 15539 - CLASS_LOSS : 0.15571
186 / 500 :: 12288 / 15539 - CLASS_LOSS : 0.13926
186 / 500 :: 12928 / 15539 - CLASS_LOSS : 0.2234
186 / 500 :: 13568 / 15539 - CLASS_LOSS : 0.0869
186 / 500 :: 14208 / 15539 - CLASS_LOSS : 0.18273
186 / 500 :: 14848 / 15539 - CLASS_LOSS : 0.12559
186 / 500 :: 15488 / 15539 - CLASS_LOSS : 0.20254
187 / 500 :: 576 / 15539 - CLASS_LOSS : 0.1937
187 / 500 :: 1216 / 15539 - CLASS_LOSS : 0.13875
187 / 500 :: 1856 / 15539 - CLASS_LOSS : 0.12594
187 / 500 :: 2496 / 15539 - CLASS_LOSS : 0.12962
187 / 500 :: 3136 / 15539 - CLASS_LOSS : 0.12714
187 / 500 :: 3776 / 15539 - CLASS_LOSS : 0.1358
187 / 500 :: 4416 / 15539 - CLASS_LOSS : 0.17225
187 / 500 :: 5056 / 15539 - CLASS_LOSS : 0.2195
187 / 500 :: 5696 / 15539 - CLASS_LOSS : 0.11231
187 / 500 :: 6336 / 15539 - CLASS_LOSS : 0.20732
187 / 500 :: 6976 / 15539 - CLASS_LOSS : 0.20382
187 / 500 :: 7616 / 15539 - CLASS_LOSS : 0.30706
187 / 500 :: 8256 / 15539 - CLASS_LOSS : 0.26588
187 / 500 :: 8896 / 15539 - CLASS_LOSS : 0.1542
187 / 500 :: 9536 / 15539 - CLASS_LOSS : 0.13284
187 / 500 :: 10176 / 15539 - CLASS_LOSS : 0.18599
187 / 500 :: 10816 / 15539 - CLASS_LOSS : 0.28488
187 / 500 :: 11456 / 15539 - CLASS_LOSS : 0.18489
187 / 500 :: 12096 / 15539 - CLASS_LOSS : 0.13567
187 / 500 :: 12736 / 15539 - CLASS_LOSS : 0.16546
187 / 500 :: 13376 / 15539 - CLASS_LOSS : 0.1572
187 / 500 :: 14016 / 15539 - CLASS_LOSS : 0.1387
187 / 500 :: 14656 / 15539 - CLASS_LOSS : 0.13007
187 / 500 :: 15296 / 15539 - CLASS_LOSS : 0.18772
188 / 500 :: 384 / 15539 - CLASS_LOSS : 0.24001
188 / 500 :: 1024 / 15539 - CLASS_LOSS : 0.12343
188 / 500 :: 1664 / 15539 - CLASS_LOSS : 0.16939
188 / 500 :: 2304 / 15539 - CLASS_LOSS : 0.16881
188 / 500 :: 2944 / 15539 - CLASS_LOSS : 0.09724
188 / 500 :: 3584 / 15539 - CLASS_LOSS : 0.17937
188 / 500 :: 4224 / 15539 - CLASS_LOSS : 0.18609
188 / 500 :: 4864 / 15539 - CLASS_LOSS : 0.23941
188 / 500 :: 5504 / 15539 - CLASS_LOSS : 0.2401
188 / 500 :: 6144 / 15539 - CLASS_LOSS : 0.14191
188 / 500 :: 6784 / 15539 - CLASS_LOSS : 0.16512
188 / 500 :: 7424 / 15539 - CLASS_LOSS : 0.17541
188 / 500 :: 8064 / 15539 - CLASS_LOSS : 0.16828
188 / 500 :: 8704 / 15539 - CLASS_LOSS : 0.09844
188 / 500 :: 9344 / 15539 - CLASS_LOSS : 0.15285
188 / 500 :: 9984 / 15539 - CLASS_LOSS : 0.19557
188 / 500 :: 10624 / 15539 - CLASS_LOSS : 0.23183
188 / 500 :: 11264 / 15539 - CLASS_LOSS : 0.16732
188 / 500 :: 11904 / 15539 - CLASS_LOSS : 0.14104
188 / 500 :: 12544 / 15539 - CLASS_LOSS : 0.13027
188 / 500 :: 13184 / 15539 - CLASS_LOSS : 0.18491
188 / 500 :: 13824 / 15539 - CLASS_LOSS : 0.15417
188 / 500 :: 14464 / 15539 - CLASS_LOSS : 0.17988
188 / 500 :: 15104 / 15539 - CLASS_LOSS : 0.16502
189 / 500 :: 192 / 15539 - CLASS_LOSS : 0.10392
189 / 500 :: 832 / 15539 - CLASS_LOSS : 0.15411
189 / 500 :: 1472 / 15539 - CLASS_LOSS : 0.29109
189 / 500 :: 2112 / 15539 - CLASS_LOSS : 0.13624
189 / 500 :: 2752 / 15539 - CLASS_LOSS : 0.07969
189 / 500 :: 3392 / 15539 - CLASS_LOSS : 0.17298
189 / 500 :: 4032 / 15539 - CLASS_LOSS : 0.272
189 / 500 :: 4672 / 15539 - CLASS_LOSS : 0.14045
189 / 500 :: 5312 / 15539 - CLASS_LOSS : 0.20904
189 / 500 :: 5952 / 15539 - CLASS_LOSS : 0.20213
189 / 500 :: 6592 / 15539 - CLASS_LOSS : 0.15948
189 / 500 :: 7232 / 15539 - CLASS_LOSS : 0.18993
189 / 500 :: 7872 / 15539 - CLASS_LOSS : 0.16766
189 / 500 :: 8512 / 15539 - CLASS_LOSS : 0.20612
189 / 500 :: 9152 / 15539 - CLASS_LOSS : 0.13176
189 / 500 :: 9792 / 15539 - CLASS_LOSS : 0.18175
189 / 500 :: 10432 / 15539 - CLASS_LOSS : 0.16729
189 / 500 :: 11072 / 15539 - CLASS_LOSS : 0.16597
189 / 500 :: 11712 / 15539 - CLASS_LOSS : 0.19214
189 / 500 :: 12352 / 15539 - CLASS_LOSS : 0.15127
189 / 500 :: 12992 / 15539 - CLASS_LOSS : 0.13271
189 / 500 :: 13632 / 15539 - CLASS_LOSS : 0.12294
189 / 500 :: 14272 / 15539 - CLASS_LOSS : 0.12077
189 / 500 :: 14912 / 15539 - CLASS_LOSS : 0.14712
189 / 500 :: 15539 / 15539 - CLASS_LOSS : 0.26591
190 / 500 :: 640 / 15539 - CLASS_LOSS : 0.19752
190 / 500 :: 1280 / 15539 - CLASS_LOSS : 0.14719
190 / 500 :: 1920 / 15539 - CLASS_LOSS : 0.15131
190 / 500 :: 2560 / 15539 - CLASS_LOSS : 0.15473
190 / 500 :: 3200 / 15539 - CLASS_LOSS : 0.1084
190 / 500 :: 3840 / 15539 - CLASS_LOSS : 0.16965
190 / 500 :: 4480 / 15539 - CLASS_LOSS : 0.18842
190 / 500 :: 5120 / 15539 - CLASS_LOSS : 0.19424
190 / 500 :: 5760 / 15539 - CLASS_LOSS : 0.19953
190 / 500 :: 6400 / 15539 - CLASS_LOSS : 0.14668
190 / 500 :: 7040 / 15539 - CLASS_LOSS : 0.1907
190 / 500 :: 7680 / 15539 - CLASS_LOSS : 0.16994
190 / 500 :: 8320 / 15539 - CLASS_LOSS : 0.27179
190 / 500 :: 8960 / 15539 - CLASS_LOSS : 0.17238
190 / 500 :: 9600 / 15539 - CLASS_LOSS : 0.14105
190 / 500 :: 10240 / 15539 - CLASS_LOSS : 0.20239
190 / 500 :: 10880 / 15539 - CLASS_LOSS : 0.14119
190 / 500 :: 11520 / 15539 - CLASS_LOSS : 0.22042
190 / 500 :: 12160 / 15539 - CLASS_LOSS : 0.16048
190 / 500 :: 12800 / 15539 - CLASS_LOSS : 0.26212
190 / 500 :: 13440 / 15539 - CLASS_LOSS : 0.08397
190 / 500 :: 14080 / 15539 - CLASS_LOSS : 0.1558
190 / 500 :: 14720 / 15539 - CLASS_LOSS : 0.09937
190 / 500 :: 15360 / 15539 - CLASS_LOSS : 0.15605
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.5378724499646051 0.4520668425681618 0.38474805328528217
PSPrecision@1,3,5: 0.389864120946335 0.42342074268774954 0.44189673463507334
testing....
Precision@1,3,5: 0.4870044631136781 0.37805198214754526 0.3170385928065109
PSPrecision@1,3,5: 0.29134135108264103 0.3033371646413416 0.31804011475215377
191 / 500 :: 448 / 15539 - CLASS_LOSS : 0.22541
191 / 500 :: 1088 / 15539 - CLASS_LOSS : 0.13503
191 / 500 :: 1728 / 15539 - CLASS_LOSS : 0.13613
191 / 500 :: 2368 / 15539 - CLASS_LOSS : 0.21069
191 / 500 :: 3008 / 15539 - CLASS_LOSS : 0.15658
191 / 500 :: 3648 / 15539 - CLASS_LOSS : 0.14346
191 / 500 :: 4288 / 15539 - CLASS_LOSS : 0.18642
191 / 500 :: 4928 / 15539 - CLASS_LOSS : 0.20619
191 / 500 :: 5568 / 15539 - CLASS_LOSS : 0.21688
191 / 500 :: 6208 / 15539 - CLASS_LOSS : 0.13684
191 / 500 :: 6848 / 15539 - CLASS_LOSS : 0.14923
191 / 500 :: 7488 / 15539 - CLASS_LOSS : 0.21008
191 / 500 :: 8128 / 15539 - CLASS_LOSS : 0.10035
191 / 500 :: 8768 / 15539 - CLASS_LOSS : 0.11498
191 / 500 :: 9408 / 15539 - CLASS_LOSS : 0.14971
191 / 500 :: 10048 / 15539 - CLASS_LOSS : 0.21978
191 / 500 :: 10688 / 15539 - CLASS_LOSS : 0.145
191 / 500 :: 11328 / 15539 - CLASS_LOSS : 0.09675
191 / 500 :: 11968 / 15539 - CLASS_LOSS : 0.13728
191 / 500 :: 12608 / 15539 - CLASS_LOSS : 0.1304
191 / 500 :: 13248 / 15539 - CLASS_LOSS : 0.21895
191 / 500 :: 13888 / 15539 - CLASS_LOSS : 0.19182
191 / 500 :: 14528 / 15539 - CLASS_LOSS : 0.15219
191 / 500 :: 15168 / 15539 - CLASS_LOSS : 0.16086
192 / 500 :: 256 / 15539 - CLASS_LOSS : 0.15478
192 / 500 :: 896 / 15539 - CLASS_LOSS : 0.13217
192 / 500 :: 1536 / 15539 - CLASS_LOSS : 0.18589
192 / 500 :: 2176 / 15539 - CLASS_LOSS : 0.1578
192 / 500 :: 2816 / 15539 - CLASS_LOSS : 0.25082
192 / 500 :: 3456 / 15539 - CLASS_LOSS : 0.18915
192 / 500 :: 4096 / 15539 - CLASS_LOSS : 0.18914
192 / 500 :: 4736 / 15539 - CLASS_LOSS : 0.18593
192 / 500 :: 5376 / 15539 - CLASS_LOSS : 0.24755
192 / 500 :: 6016 / 15539 - CLASS_LOSS : 0.28034
192 / 500 :: 6656 / 15539 - CLASS_LOSS : 0.17621
192 / 500 :: 7296 / 15539 - CLASS_LOSS : 0.20895
192 / 500 :: 7936 / 15539 - CLASS_LOSS : 0.19821
192 / 500 :: 8576 / 15539 - CLASS_LOSS : 0.1297
192 / 500 :: 9216 / 15539 - CLASS_LOSS : 0.13852
192 / 500 :: 9856 / 15539 - CLASS_LOSS : 0.17942
192 / 500 :: 10496 / 15539 - CLASS_LOSS : 0.20306
192 / 500 :: 11136 / 15539 - CLASS_LOSS : 0.14935
192 / 500 :: 11776 / 15539 - CLASS_LOSS : 0.09379
192 / 500 :: 12416 / 15539 - CLASS_LOSS : 0.22045
192 / 500 :: 13056 / 15539 - CLASS_LOSS : 0.13045
192 / 500 :: 13696 / 15539 - CLASS_LOSS : 0.23429
192 / 500 :: 14336 / 15539 - CLASS_LOSS : 0.10194
192 / 500 :: 14976 / 15539 - CLASS_LOSS : 0.15156
193 / 500 :: 64 / 15539 - CLASS_LOSS : 0.1518
193 / 500 :: 704 / 15539 - CLASS_LOSS : 0.22553
193 / 500 :: 1344 / 15539 - CLASS_LOSS : 0.06991
193 / 500 :: 1984 / 15539 - CLASS_LOSS : 0.24656
193 / 500 :: 2624 / 15539 - CLASS_LOSS : 0.11407
193 / 500 :: 3264 / 15539 - CLASS_LOSS : 0.1817
193 / 500 :: 3904 / 15539 - CLASS_LOSS : 0.16075
193 / 500 :: 4544 / 15539 - CLASS_LOSS : 0.2001
193 / 500 :: 5184 / 15539 - CLASS_LOSS : 0.13935
193 / 500 :: 5824 / 15539 - CLASS_LOSS : 0.19068
193 / 500 :: 6464 / 15539 - CLASS_LOSS : 0.2425
193 / 500 :: 7104 / 15539 - CLASS_LOSS : 0.16071
193 / 500 :: 7744 / 15539 - CLASS_LOSS : 0.15912
193 / 500 :: 8384 / 15539 - CLASS_LOSS : 0.10459
193 / 500 :: 9024 / 15539 - CLASS_LOSS : 0.16541
193 / 500 :: 9664 / 15539 - CLASS_LOSS : 0.1357
193 / 500 :: 10304 / 15539 - CLASS_LOSS : 0.15479
193 / 500 :: 10944 / 15539 - CLASS_LOSS : 0.05162
193 / 500 :: 11584 / 15539 - CLASS_LOSS : 0.1212
193 / 500 :: 12224 / 15539 - CLASS_LOSS : 0.17189
193 / 500 :: 12864 / 15539 - CLASS_LOSS : 0.13926
193 / 500 :: 13504 / 15539 - CLASS_LOSS : 0.3041
193 / 500 :: 14144 / 15539 - CLASS_LOSS : 0.16333
193 / 500 :: 14784 / 15539 - CLASS_LOSS : 0.15632
193 / 500 :: 15424 / 15539 - CLASS_LOSS : 0.13055
194 / 500 :: 512 / 15539 - CLASS_LOSS : 0.17912
194 / 500 :: 1152 / 15539 - CLASS_LOSS : 0.14648
194 / 500 :: 1792 / 15539 - CLASS_LOSS : 0.20355
194 / 500 :: 2432 / 15539 - CLASS_LOSS : 0.15794
194 / 500 :: 3072 / 15539 - CLASS_LOSS : 0.26021
194 / 500 :: 3712 / 15539 - CLASS_LOSS : 0.19298
194 / 500 :: 4352 / 15539 - CLASS_LOSS : 0.17076
194 / 500 :: 4992 / 15539 - CLASS_LOSS : 0.06383
194 / 500 :: 5632 / 15539 - CLASS_LOSS : 0.16161
194 / 500 :: 6272 / 15539 - CLASS_LOSS : 0.21806
194 / 500 :: 6912 / 15539 - CLASS_LOSS : 0.12211
194 / 500 :: 7552 / 15539 - CLASS_LOSS : 0.117
194 / 500 :: 8192 / 15539 - CLASS_LOSS : 0.17258
194 / 500 :: 8832 / 15539 - CLASS_LOSS : 0.09083
194 / 500 :: 9472 / 15539 - CLASS_LOSS : 0.18563
194 / 500 :: 10112 / 15539 - CLASS_LOSS : 0.26622
194 / 500 :: 10752 / 15539 - CLASS_LOSS : 0.11145
194 / 500 :: 11392 / 15539 - CLASS_LOSS : 0.20472
194 / 500 :: 12032 / 15539 - CLASS_LOSS : 0.11605
194 / 500 :: 12672 / 15539 - CLASS_LOSS : 0.12966
194 / 500 :: 13312 / 15539 - CLASS_LOSS : 0.17469
194 / 500 :: 13952 / 15539 - CLASS_LOSS : 0.10557
194 / 500 :: 14592 / 15539 - CLASS_LOSS : 0.13837
194 / 500 :: 15232 / 15539 - CLASS_LOSS : 0.23606
195 / 500 :: 320 / 15539 - CLASS_LOSS : 0.08018
195 / 500 :: 960 / 15539 - CLASS_LOSS : 0.18376
195 / 500 :: 1600 / 15539 - CLASS_LOSS : 0.25327
195 / 500 :: 2240 / 15539 - CLASS_LOSS : 0.14456
195 / 500 :: 2880 / 15539 - CLASS_LOSS : 0.18015
195 / 500 :: 3520 / 15539 - CLASS_LOSS : 0.17384
195 / 500 :: 4160 / 15539 - CLASS_LOSS : 0.13032
195 / 500 :: 4800 / 15539 - CLASS_LOSS : 0.16521
195 / 500 :: 5440 / 15539 - CLASS_LOSS : 0.17871
195 / 500 :: 6080 / 15539 - CLASS_LOSS : 0.18099
195 / 500 :: 6720 / 15539 - CLASS_LOSS : 0.11039
195 / 500 :: 7360 / 15539 - CLASS_LOSS : 0.26269
195 / 500 :: 8000 / 15539 - CLASS_LOSS : 0.22223
195 / 500 :: 8640 / 15539 - CLASS_LOSS : 0.13733
195 / 500 :: 9280 / 15539 - CLASS_LOSS : 0.16039
195 / 500 :: 9920 / 15539 - CLASS_LOSS : 0.10163
195 / 500 :: 10560 / 15539 - CLASS_LOSS : 0.09646
195 / 500 :: 11200 / 15539 - CLASS_LOSS : 0.18755
195 / 500 :: 11840 / 15539 - CLASS_LOSS : 0.13494
195 / 500 :: 12480 / 15539 - CLASS_LOSS : 0.21473
195 / 500 :: 13120 / 15539 - CLASS_LOSS : 0.11095
195 / 500 :: 13760 / 15539 - CLASS_LOSS : 0.15604
195 / 500 :: 14400 / 15539 - CLASS_LOSS : 0.28982
195 / 500 :: 15040 / 15539 - CLASS_LOSS : 0.13459
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.5672823218997362 0.46253512667052793 0.39456850505180513
PSPrecision@1,3,5: 0.4046957969804496 0.42987577715361197 0.4511160151738149
testing....
Precision@1,3,5: 0.4909425045943817 0.3863656252734751 0.3203465476503019
PSPrecision@1,3,5: 0.291546332900262 0.3122133431151799 0.320996786036551
196 / 500 :: 128 / 15539 - CLASS_LOSS : 0.13484
196 / 500 :: 768 / 15539 - CLASS_LOSS : 0.154
196 / 500 :: 1408 / 15539 - CLASS_LOSS : 0.26158
196 / 500 :: 2048 / 15539 - CLASS_LOSS : 0.21363
196 / 500 :: 2688 / 15539 - CLASS_LOSS : 0.21766
196 / 500 :: 3328 / 15539 - CLASS_LOSS : 0.10356
196 / 500 :: 3968 / 15539 - CLASS_LOSS : 0.16492
196 / 500 :: 4608 / 15539 - CLASS_LOSS : 0.213
196 / 500 :: 5248 / 15539 - CLASS_LOSS : 0.23002
196 / 500 :: 5888 / 15539 - CLASS_LOSS : 0.28151
196 / 500 :: 6528 / 15539 - CLASS_LOSS : 0.11959
196 / 500 :: 7168 / 15539 - CLASS_LOSS : 0.2498
196 / 500 :: 7808 / 15539 - CLASS_LOSS : 0.2149
196 / 500 :: 8448 / 15539 - CLASS_LOSS : 0.14286
196 / 500 :: 9088 / 15539 - CLASS_LOSS : 0.15517
196 / 500 :: 9728 / 15539 - CLASS_LOSS : 0.1733
196 / 500 :: 10368 / 15539 - CLASS_LOSS : 0.20326
196 / 500 :: 11008 / 15539 - CLASS_LOSS : 0.07919
196 / 500 :: 11648 / 15539 - CLASS_LOSS : 0.19898
196 / 500 :: 12288 / 15539 - CLASS_LOSS : 0.12864
196 / 500 :: 12928 / 15539 - CLASS_LOSS : 0.28623
196 / 500 :: 13568 / 15539 - CLASS_LOSS : 0.07526
196 / 500 :: 14208 / 15539 - CLASS_LOSS : 0.14489
196 / 500 :: 14848 / 15539 - CLASS_LOSS : 0.11464
196 / 500 :: 15488 / 15539 - CLASS_LOSS : 0.18519
197 / 500 :: 576 / 15539 - CLASS_LOSS : 0.15407
197 / 500 :: 1216 / 15539 - CLASS_LOSS : 0.16585
197 / 500 :: 1856 / 15539 - CLASS_LOSS : 0.16229
197 / 500 :: 2496 / 15539 - CLASS_LOSS : 0.09737
197 / 500 :: 3136 / 15539 - CLASS_LOSS : 0.13202
197 / 500 :: 3776 / 15539 - CLASS_LOSS : 0.15472
197 / 500 :: 4416 / 15539 - CLASS_LOSS : 0.13209
197 / 500 :: 5056 / 15539 - CLASS_LOSS : 0.20918
197 / 500 :: 5696 / 15539 - CLASS_LOSS : 0.09489
197 / 500 :: 6336 / 15539 - CLASS_LOSS : 0.19592
197 / 500 :: 6976 / 15539 - CLASS_LOSS : 0.17539
197 / 500 :: 7616 / 15539 - CLASS_LOSS : 0.13913
197 / 500 :: 8256 / 15539 - CLASS_LOSS : 0.15406
197 / 500 :: 8896 / 15539 - CLASS_LOSS : 0.13029
197 / 500 :: 9536 / 15539 - CLASS_LOSS : 0.15964
197 / 500 :: 10176 / 15539 - CLASS_LOSS : 0.08608
197 / 500 :: 10816 / 15539 - CLASS_LOSS : 0.21223
197 / 500 :: 11456 / 15539 - CLASS_LOSS : 0.14973
197 / 500 :: 12096 / 15539 - CLASS_LOSS : 0.21431
197 / 500 :: 12736 / 15539 - CLASS_LOSS : 0.17312
197 / 500 :: 13376 / 15539 - CLASS_LOSS : 0.17008
197 / 500 :: 14016 / 15539 - CLASS_LOSS : 0.20334
197 / 500 :: 14656 / 15539 - CLASS_LOSS : 0.17279
197 / 500 :: 15296 / 15539 - CLASS_LOSS : 0.19409
198 / 500 :: 384 / 15539 - CLASS_LOSS : 0.24066
198 / 500 :: 1024 / 15539 - CLASS_LOSS : 0.16679
198 / 500 :: 1664 / 15539 - CLASS_LOSS : 0.19869
198 / 500 :: 2304 / 15539 - CLASS_LOSS : 0.26001
198 / 500 :: 2944 / 15539 - CLASS_LOSS : 0.18194
198 / 500 :: 3584 / 15539 - CLASS_LOSS : 0.13574
198 / 500 :: 4224 / 15539 - CLASS_LOSS : 0.14694
198 / 500 :: 4864 / 15539 - CLASS_LOSS : 0.23145
198 / 500 :: 5504 / 15539 - CLASS_LOSS : 0.17556
198 / 500 :: 6144 / 15539 - CLASS_LOSS : 0.21777
198 / 500 :: 6784 / 15539 - CLASS_LOSS : 0.17815
198 / 500 :: 7424 / 15539 - CLASS_LOSS : 0.22845
198 / 500 :: 8064 / 15539 - CLASS_LOSS : 0.14258
198 / 500 :: 8704 / 15539 - CLASS_LOSS : 0.22302
198 / 500 :: 9344 / 15539 - CLASS_LOSS : 0.17894
198 / 500 :: 9984 / 15539 - CLASS_LOSS : 0.22898
198 / 500 :: 10624 / 15539 - CLASS_LOSS : 0.21357
198 / 500 :: 11264 / 15539 - CLASS_LOSS : 0.11525
198 / 500 :: 11904 / 15539 - CLASS_LOSS : 0.15306
198 / 500 :: 12544 / 15539 - CLASS_LOSS : 0.25156
198 / 500 :: 13184 / 15539 - CLASS_LOSS : 0.19598
198 / 500 :: 13824 / 15539 - CLASS_LOSS : 0.15068
198 / 500 :: 14464 / 15539 - CLASS_LOSS : 0.10576
198 / 500 :: 15104 / 15539 - CLASS_LOSS : 0.14632
199 / 500 :: 192 / 15539 - CLASS_LOSS : 0.25229
199 / 500 :: 832 / 15539 - CLASS_LOSS : 0.14346
199 / 500 :: 1472 / 15539 - CLASS_LOSS : 0.13634
199 / 500 :: 2112 / 15539 - CLASS_LOSS : 0.17032
199 / 500 :: 2752 / 15539 - CLASS_LOSS : 0.15665
199 / 500 :: 3392 / 15539 - CLASS_LOSS : 0.23418
199 / 500 :: 4032 / 15539 - CLASS_LOSS : 0.08726
199 / 500 :: 4672 / 15539 - CLASS_LOSS : 0.0976
199 / 500 :: 5312 / 15539 - CLASS_LOSS : 0.15609
199 / 500 :: 5952 / 15539 - CLASS_LOSS : 0.13135
199 / 500 :: 6592 / 15539 - CLASS_LOSS : 0.16467
199 / 500 :: 7232 / 15539 - CLASS_LOSS : 0.18166
199 / 500 :: 7872 / 15539 - CLASS_LOSS : 0.14981
199 / 500 :: 8512 / 15539 - CLASS_LOSS : 0.13636
199 / 500 :: 9152 / 15539 - CLASS_LOSS : 0.19172
199 / 500 :: 9792 / 15539 - CLASS_LOSS : 0.12458
199 / 500 :: 10432 / 15539 - CLASS_LOSS : 0.19736
199 / 500 :: 11072 / 15539 - CLASS_LOSS : 0.17983
199 / 500 :: 11712 / 15539 - CLASS_LOSS : 0.17412
199 / 500 :: 12352 / 15539 - CLASS_LOSS : 0.20778
199 / 500 :: 12992 / 15539 - CLASS_LOSS : 0.30254
199 / 500 :: 13632 / 15539 - CLASS_LOSS : 0.13418
199 / 500 :: 14272 / 15539 - CLASS_LOSS : 0.14822
199 / 500 :: 14912 / 15539 - CLASS_LOSS : 0.2078
199 / 500 :: 15539 / 15539 - CLASS_LOSS : 0.36519
200 / 500 :: 640 / 15539 - CLASS_LOSS : 0.20788
200 / 500 :: 1280 / 15539 - CLASS_LOSS : 0.19722
200 / 500 :: 1920 / 15539 - CLASS_LOSS : 0.13627
200 / 500 :: 2560 / 15539 - CLASS_LOSS : 0.18887
200 / 500 :: 3200 / 15539 - CLASS_LOSS : 0.14153
200 / 500 :: 3840 / 15539 - CLASS_LOSS : 0.09194
200 / 500 :: 4480 / 15539 - CLASS_LOSS : 0.20396
200 / 500 :: 5120 / 15539 - CLASS_LOSS : 0.15837
200 / 500 :: 5760 / 15539 - CLASS_LOSS : 0.34695
200 / 500 :: 6400 / 15539 - CLASS_LOSS : 0.30974
200 / 500 :: 7040 / 15539 - CLASS_LOSS : 0.16877
200 / 500 :: 7680 / 15539 - CLASS_LOSS : 0.16495
200 / 500 :: 8320 / 15539 - CLASS_LOSS : 0.24826
200 / 500 :: 8960 / 15539 - CLASS_LOSS : 0.23949
200 / 500 :: 9600 / 15539 - CLASS_LOSS : 0.13849
200 / 500 :: 10240 / 15539 - CLASS_LOSS : 0.1489
200 / 500 :: 10880 / 15539 - CLASS_LOSS : 0.10141
200 / 500 :: 11520 / 15539 - CLASS_LOSS : 0.20391
200 / 500 :: 12160 / 15539 - CLASS_LOSS : 0.13941
200 / 500 :: 12800 / 15539 - CLASS_LOSS : 0.19751
200 / 500 :: 13440 / 15539 - CLASS_LOSS : 0.22454
200 / 500 :: 14080 / 15539 - CLASS_LOSS : 0.1675
200 / 500 :: 14720 / 15539 - CLASS_LOSS : 0.17261
200 / 500 :: 15360 / 15539 - CLASS_LOSS : 0.13958
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.5617478602226655 0.4686058733938263 0.3981208571980179
PSPrecision@1,3,5: 0.403436822221833 0.4364083282849519 0.45457912036181863
testing....
Precision@1,3,5: 0.48201627723812024 0.38435284851667106 0.3252822263061171
PSPrecision@1,3,5: 0.2883765626553283 0.3087893741583644 0.3250671284576216
201 / 500 :: 448 / 15539 - CLASS_LOSS : 0.15877
201 / 500 :: 1088 / 15539 - CLASS_LOSS : 0.12075
201 / 500 :: 1728 / 15539 - CLASS_LOSS : 0.14025
201 / 500 :: 2368 / 15539 - CLASS_LOSS : 0.14913
201 / 500 :: 3008 / 15539 - CLASS_LOSS : 0.14
201 / 500 :: 3648 / 15539 - CLASS_LOSS : 0.11829
201 / 500 :: 4288 / 15539 - CLASS_LOSS : 0.17866
201 / 500 :: 4928 / 15539 - CLASS_LOSS : 0.24547
201 / 500 :: 5568 / 15539 - CLASS_LOSS : 0.15503
201 / 500 :: 6208 / 15539 - CLASS_LOSS : 0.14456
201 / 500 :: 6848 / 15539 - CLASS_LOSS : 0.18569
201 / 500 :: 7488 / 15539 - CLASS_LOSS : 0.18118
201 / 500 :: 8128 / 15539 - CLASS_LOSS : 0.14008
201 / 500 :: 8768 / 15539 - CLASS_LOSS : 0.13988
201 / 500 :: 9408 / 15539 - CLASS_LOSS : 0.16301
201 / 500 :: 10048 / 15539 - CLASS_LOSS : 0.11463
201 / 500 :: 10688 / 15539 - CLASS_LOSS : 0.11482
201 / 500 :: 11328 / 15539 - CLASS_LOSS : 0.17567
201 / 500 :: 11968 / 15539 - CLASS_LOSS : 0.22986
201 / 500 :: 12608 / 15539 - CLASS_LOSS : 0.2102
201 / 500 :: 13248 / 15539 - CLASS_LOSS : 0.26078
201 / 500 :: 13888 / 15539 - CLASS_LOSS : 0.19171
201 / 500 :: 14528 / 15539 - CLASS_LOSS : 0.11659
201 / 500 :: 15168 / 15539 - CLASS_LOSS : 0.11974
202 / 500 :: 256 / 15539 - CLASS_LOSS : 0.30192
202 / 500 :: 896 / 15539 - CLASS_LOSS : 0.13841
202 / 500 :: 1536 / 15539 - CLASS_LOSS : 0.21405
202 / 500 :: 2176 / 15539 - CLASS_LOSS : 0.16875
202 / 500 :: 2816 / 15539 - CLASS_LOSS : 0.11688
202 / 500 :: 3456 / 15539 - CLASS_LOSS : 0.20953
202 / 500 :: 4096 / 15539 - CLASS_LOSS : 0.16909
202 / 500 :: 4736 / 15539 - CLASS_LOSS : 0.18883
202 / 500 :: 5376 / 15539 - CLASS_LOSS : 0.22063
202 / 500 :: 6016 / 15539 - CLASS_LOSS : 0.14148
202 / 500 :: 6656 / 15539 - CLASS_LOSS : 0.11975
202 / 500 :: 7296 / 15539 - CLASS_LOSS : 0.17224
202 / 500 :: 7936 / 15539 - CLASS_LOSS : 0.19094
202 / 500 :: 8576 / 15539 - CLASS_LOSS : 0.24609
202 / 500 :: 9216 / 15539 - CLASS_LOSS : 0.17028
202 / 500 :: 9856 / 15539 - CLASS_LOSS : 0.11003
202 / 500 :: 10496 / 15539 - CLASS_LOSS : 0.13414
202 / 500 :: 11136 / 15539 - CLASS_LOSS : 0.16656
202 / 500 :: 11776 / 15539 - CLASS_LOSS : 0.2284
202 / 500 :: 12416 / 15539 - CLASS_LOSS : 0.15353
202 / 500 :: 13056 / 15539 - CLASS_LOSS : 0.19244
202 / 500 :: 13696 / 15539 - CLASS_LOSS : 0.12352
202 / 500 :: 14336 / 15539 - CLASS_LOSS : 0.13442
202 / 500 :: 14976 / 15539 - CLASS_LOSS : 0.15566
203 / 500 :: 64 / 15539 - CLASS_LOSS : 0.19629
203 / 500 :: 704 / 15539 - CLASS_LOSS : 0.11075
203 / 500 :: 1344 / 15539 - CLASS_LOSS : 0.19132
203 / 500 :: 1984 / 15539 - CLASS_LOSS : 0.15717
203 / 500 :: 2624 / 15539 - CLASS_LOSS : 0.25362
203 / 500 :: 3264 / 15539 - CLASS_LOSS : 0.16676
203 / 500 :: 3904 / 15539 - CLASS_LOSS : 0.11653
203 / 500 :: 4544 / 15539 - CLASS_LOSS : 0.18694
203 / 500 :: 5184 / 15539 - CLASS_LOSS : 0.11149
203 / 500 :: 5824 / 15539 - CLASS_LOSS : 0.10961
203 / 500 :: 6464 / 15539 - CLASS_LOSS : 0.18656
203 / 500 :: 7104 / 15539 - CLASS_LOSS : 0.1448
203 / 500 :: 7744 / 15539 - CLASS_LOSS : 0.25693
203 / 500 :: 8384 / 15539 - CLASS_LOSS : 0.13851
203 / 500 :: 9024 / 15539 - CLASS_LOSS : 0.20051
203 / 500 :: 9664 / 15539 - CLASS_LOSS : 0.19125
203 / 500 :: 10304 / 15539 - CLASS_LOSS : 0.15363
203 / 500 :: 10944 / 15539 - CLASS_LOSS : 0.08377
203 / 500 :: 11584 / 15539 - CLASS_LOSS : 0.15361
203 / 500 :: 12224 / 15539 - CLASS_LOSS : 0.19874
203 / 500 :: 12864 / 15539 - CLASS_LOSS : 0.13563
203 / 500 :: 13504 / 15539 - CLASS_LOSS : 0.16231
203 / 500 :: 14144 / 15539 - CLASS_LOSS : 0.17934
203 / 500 :: 14784 / 15539 - CLASS_LOSS : 0.22085
203 / 500 :: 15424 / 15539 - CLASS_LOSS : 0.16769
204 / 500 :: 512 / 15539 - CLASS_LOSS : 0.1632
204 / 500 :: 1152 / 15539 - CLASS_LOSS : 0.26327
204 / 500 :: 1792 / 15539 - CLASS_LOSS : 0.20277
204 / 500 :: 2432 / 15539 - CLASS_LOSS : 0.20784
204 / 500 :: 3072 / 15539 - CLASS_LOSS : 0.16212
204 / 500 :: 3712 / 15539 - CLASS_LOSS : 0.2341
204 / 500 :: 4352 / 15539 - CLASS_LOSS : 0.15375
204 / 500 :: 4992 / 15539 - CLASS_LOSS : 0.09599
204 / 500 :: 5632 / 15539 - CLASS_LOSS : 0.15361
204 / 500 :: 6272 / 15539 - CLASS_LOSS : 0.18623
204 / 500 :: 6912 / 15539 - CLASS_LOSS : 0.07726
204 / 500 :: 7552 / 15539 - CLASS_LOSS : 0.18678
204 / 500 :: 8192 / 15539 - CLASS_LOSS : 0.16159
204 / 500 :: 8832 / 15539 - CLASS_LOSS : 0.12329
204 / 500 :: 9472 / 15539 - CLASS_LOSS : 0.1189
204 / 500 :: 10112 / 15539 - CLASS_LOSS : 0.13723
204 / 500 :: 10752 / 15539 - CLASS_LOSS : 0.2563
204 / 500 :: 11392 / 15539 - CLASS_LOSS : 0.19397
204 / 500 :: 12032 / 15539 - CLASS_LOSS : 0.16522
204 / 500 :: 12672 / 15539 - CLASS_LOSS : 0.17325
204 / 500 :: 13312 / 15539 - CLASS_LOSS : 0.10195
204 / 500 :: 13952 / 15539 - CLASS_LOSS : 0.19296
204 / 500 :: 14592 / 15539 - CLASS_LOSS : 0.15277
204 / 500 :: 15232 / 15539 - CLASS_LOSS : 0.14002
205 / 500 :: 320 / 15539 - CLASS_LOSS : 0.09188
205 / 500 :: 960 / 15539 - CLASS_LOSS : 0.08705
205 / 500 :: 1600 / 15539 - CLASS_LOSS : 0.41276
205 / 500 :: 2240 / 15539 - CLASS_LOSS : 0.10363
205 / 500 :: 2880 / 15539 - CLASS_LOSS : 0.0917
205 / 500 :: 3520 / 15539 - CLASS_LOSS : 0.11596
205 / 500 :: 4160 / 15539 - CLASS_LOSS : 0.25744
205 / 500 :: 4800 / 15539 - CLASS_LOSS : 0.17594
205 / 500 :: 5440 / 15539 - CLASS_LOSS : 0.09458
205 / 500 :: 6080 / 15539 - CLASS_LOSS : 0.11378
205 / 500 :: 6720 / 15539 - CLASS_LOSS : 0.14791
205 / 500 :: 7360 / 15539 - CLASS_LOSS : 0.25073
205 / 500 :: 8000 / 15539 - CLASS_LOSS : 0.1605
205 / 500 :: 8640 / 15539 - CLASS_LOSS : 0.2108
205 / 500 :: 9280 / 15539 - CLASS_LOSS : 0.19278
205 / 500 :: 9920 / 15539 - CLASS_LOSS : 0.12966
205 / 500 :: 10560 / 15539 - CLASS_LOSS : 0.13608
205 / 500 :: 11200 / 15539 - CLASS_LOSS : 0.19316
205 / 500 :: 11840 / 15539 - CLASS_LOSS : 0.19968
205 / 500 :: 12480 / 15539 - CLASS_LOSS : 0.15651
205 / 500 :: 13120 / 15539 - CLASS_LOSS : 0.11544
205 / 500 :: 13760 / 15539 - CLASS_LOSS : 0.11154
205 / 500 :: 14400 / 15539 - CLASS_LOSS : 0.25107
205 / 500 :: 15040 / 15539 - CLASS_LOSS : 0.08458
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.5506789368685243 0.46262093227792433 0.3946843426217903
PSPrecision@1,3,5: 0.39761398990296004 0.4299329974201166 0.451273858427811
testing....
Precision@1,3,5: 0.47335258598057234 0.38251509582567605 0.32444211079023366
PSPrecision@1,3,5: 0.28390306407745786 0.3051128606933054 0.3226031832889736
206 / 500 :: 128 / 15539 - CLASS_LOSS : 0.11345
206 / 500 :: 768 / 15539 - CLASS_LOSS : 0.25991
206 / 500 :: 1408 / 15539 - CLASS_LOSS : 0.10213
206 / 500 :: 2048 / 15539 - CLASS_LOSS : 0.16333
206 / 500 :: 2688 / 15539 - CLASS_LOSS : 0.20166
206 / 500 :: 3328 / 15539 - CLASS_LOSS : 0.1626
206 / 500 :: 3968 / 15539 - CLASS_LOSS : 0.20755
206 / 500 :: 4608 / 15539 - CLASS_LOSS : 0.22939
206 / 500 :: 5248 / 15539 - CLASS_LOSS : 0.20941
206 / 500 :: 5888 / 15539 - CLASS_LOSS : 0.30116
206 / 500 :: 6528 / 15539 - CLASS_LOSS : 0.22263
206 / 500 :: 7168 / 15539 - CLASS_LOSS : 0.09972
206 / 500 :: 7808 / 15539 - CLASS_LOSS : 0.10688
206 / 500 :: 8448 / 15539 - CLASS_LOSS : 0.24677
206 / 500 :: 9088 / 15539 - CLASS_LOSS : 0.08805
206 / 500 :: 9728 / 15539 - CLASS_LOSS : 0.103
206 / 500 :: 10368 / 15539 - CLASS_LOSS : 0.17161
206 / 500 :: 11008 / 15539 - CLASS_LOSS : 0.1502
206 / 500 :: 11648 / 15539 - CLASS_LOSS : 0.24759
206 / 500 :: 12288 / 15539 - CLASS_LOSS : 0.29142
206 / 500 :: 12928 / 15539 - CLASS_LOSS : 0.16373
206 / 500 :: 13568 / 15539 - CLASS_LOSS : 0.17439
206 / 500 :: 14208 / 15539 - CLASS_LOSS : 0.15494
206 / 500 :: 14848 / 15539 - CLASS_LOSS : 0.07874
206 / 500 :: 15488 / 15539 - CLASS_LOSS : 0.09523
207 / 500 :: 576 / 15539 - CLASS_LOSS : 0.14788
207 / 500 :: 1216 / 15539 - CLASS_LOSS : 0.11968
207 / 500 :: 1856 / 15539 - CLASS_LOSS : 0.23963
207 / 500 :: 2496 / 15539 - CLASS_LOSS : 0.25129
207 / 500 :: 3136 / 15539 - CLASS_LOSS : 0.12353
207 / 500 :: 3776 / 15539 - CLASS_LOSS : 0.22281
207 / 500 :: 4416 / 15539 - CLASS_LOSS : 0.17494
207 / 500 :: 5056 / 15539 - CLASS_LOSS : 0.14071
207 / 500 :: 5696 / 15539 - CLASS_LOSS : 0.16566
207 / 500 :: 6336 / 15539 - CLASS_LOSS : 0.11374
207 / 500 :: 6976 / 15539 - CLASS_LOSS : 0.12137
207 / 500 :: 7616 / 15539 - CLASS_LOSS : 0.13744
207 / 500 :: 8256 / 15539 - CLASS_LOSS : 0.13722
207 / 500 :: 8896 / 15539 - CLASS_LOSS : 0.11421
207 / 500 :: 9536 / 15539 - CLASS_LOSS : 0.11006
207 / 500 :: 10176 / 15539 - CLASS_LOSS : 0.10666
207 / 500 :: 10816 / 15539 - CLASS_LOSS : 0.17165
207 / 500 :: 11456 / 15539 - CLASS_LOSS : 0.10517
207 / 500 :: 12096 / 15539 - CLASS_LOSS : 0.1811
207 / 500 :: 12736 / 15539 - CLASS_LOSS : 0.15911
207 / 500 :: 13376 / 15539 - CLASS_LOSS : 0.1161
207 / 500 :: 14016 / 15539 - CLASS_LOSS : 0.23004
207 / 500 :: 14656 / 15539 - CLASS_LOSS : 0.16762
207 / 500 :: 15296 / 15539 - CLASS_LOSS : 0.18372
208 / 500 :: 384 / 15539 - CLASS_LOSS : 0.11692
208 / 500 :: 1024 / 15539 - CLASS_LOSS : 0.14172
208 / 500 :: 1664 / 15539 - CLASS_LOSS : 0.1347
208 / 500 :: 2304 / 15539 - CLASS_LOSS : 0.18628
208 / 500 :: 2944 / 15539 - CLASS_LOSS : 0.13696
208 / 500 :: 3584 / 15539 - CLASS_LOSS : 0.19878
208 / 500 :: 4224 / 15539 - CLASS_LOSS : 0.17035
208 / 500 :: 4864 / 15539 - CLASS_LOSS : 0.15774
208 / 500 :: 5504 / 15539 - CLASS_LOSS : 0.15779
208 / 500 :: 6144 / 15539 - CLASS_LOSS : 0.17935
208 / 500 :: 6784 / 15539 - CLASS_LOSS : 0.13573
208 / 500 :: 7424 / 15539 - CLASS_LOSS : 0.14594
208 / 500 :: 8064 / 15539 - CLASS_LOSS : 0.11979
208 / 500 :: 8704 / 15539 - CLASS_LOSS : 0.25258
208 / 500 :: 9344 / 15539 - CLASS_LOSS : 0.1987
208 / 500 :: 9984 / 15539 - CLASS_LOSS : 0.15798
208 / 500 :: 10624 / 15539 - CLASS_LOSS : 0.1417
208 / 500 :: 11264 / 15539 - CLASS_LOSS : 0.22958
208 / 500 :: 11904 / 15539 - CLASS_LOSS : 0.09886
208 / 500 :: 12544 / 15539 - CLASS_LOSS : 0.11076
208 / 500 :: 13184 / 15539 - CLASS_LOSS : 0.28334
208 / 500 :: 13824 / 15539 - CLASS_LOSS : 0.12009
208 / 500 :: 14464 / 15539 - CLASS_LOSS : 0.12481
208 / 500 :: 15104 / 15539 - CLASS_LOSS : 0.17053
209 / 500 :: 192 / 15539 - CLASS_LOSS : 0.28959
209 / 500 :: 832 / 15539 - CLASS_LOSS : 0.1346
209 / 500 :: 1472 / 15539 - CLASS_LOSS : 0.15583
209 / 500 :: 2112 / 15539 - CLASS_LOSS : 0.1842
209 / 500 :: 2752 / 15539 - CLASS_LOSS : 0.18308
209 / 500 :: 3392 / 15539 - CLASS_LOSS : 0.1306
209 / 500 :: 4032 / 15539 - CLASS_LOSS : 0.12702
209 / 500 :: 4672 / 15539 - CLASS_LOSS : 0.20305
209 / 500 :: 5312 / 15539 - CLASS_LOSS : 0.26509
209 / 500 :: 5952 / 15539 - CLASS_LOSS : 0.09861
209 / 500 :: 6592 / 15539 - CLASS_LOSS : 0.20826
209 / 500 :: 7232 / 15539 - CLASS_LOSS : 0.05923
209 / 500 :: 7872 / 15539 - CLASS_LOSS : 0.19764
209 / 500 :: 8512 / 15539 - CLASS_LOSS : 0.17726
209 / 500 :: 9152 / 15539 - CLASS_LOSS : 0.19814
209 / 500 :: 9792 / 15539 - CLASS_LOSS : 0.10221
209 / 500 :: 10432 / 15539 - CLASS_LOSS : 0.12965
209 / 500 :: 11072 / 15539 - CLASS_LOSS : 0.10095
209 / 500 :: 11712 / 15539 - CLASS_LOSS : 0.15567
209 / 500 :: 12352 / 15539 - CLASS_LOSS : 0.13862
209 / 500 :: 12992 / 15539 - CLASS_LOSS : 0.15514
209 / 500 :: 13632 / 15539 - CLASS_LOSS : 0.20544
209 / 500 :: 14272 / 15539 - CLASS_LOSS : 0.12598
209 / 500 :: 14912 / 15539 - CLASS_LOSS : 0.09104
209 / 500 :: 15539 / 15539 - CLASS_LOSS : 0.21893
210 / 500 :: 640 / 15539 - CLASS_LOSS : 0.21649
210 / 500 :: 1280 / 15539 - CLASS_LOSS : 0.11514
210 / 500 :: 1920 / 15539 - CLASS_LOSS : 0.12968
210 / 500 :: 2560 / 15539 - CLASS_LOSS : 0.15718
210 / 500 :: 3200 / 15539 - CLASS_LOSS : 0.22343
210 / 500 :: 3840 / 15539 - CLASS_LOSS : 0.13425
210 / 500 :: 4480 / 15539 - CLASS_LOSS : 0.17728
210 / 500 :: 5120 / 15539 - CLASS_LOSS : 0.17623
210 / 500 :: 5760 / 15539 - CLASS_LOSS : 0.20308
210 / 500 :: 6400 / 15539 - CLASS_LOSS : 0.09328
210 / 500 :: 7040 / 15539 - CLASS_LOSS : 0.19498
210 / 500 :: 7680 / 15539 - CLASS_LOSS : 0.07842
210 / 500 :: 8320 / 15539 - CLASS_LOSS : 0.16944
210 / 500 :: 8960 / 15539 - CLASS_LOSS : 0.12727
210 / 500 :: 9600 / 15539 - CLASS_LOSS : 0.1516
210 / 500 :: 10240 / 15539 - CLASS_LOSS : 0.14011
210 / 500 :: 10880 / 15539 - CLASS_LOSS : 0.13779
210 / 500 :: 11520 / 15539 - CLASS_LOSS : 0.17124
210 / 500 :: 12160 / 15539 - CLASS_LOSS : 0.18983
210 / 500 :: 12800 / 15539 - CLASS_LOSS : 0.18441
210 / 500 :: 13440 / 15539 - CLASS_LOSS : 0.15454
210 / 500 :: 14080 / 15539 - CLASS_LOSS : 0.13888
210 / 500 :: 14720 / 15539 - CLASS_LOSS : 0.11338
210 / 500 :: 15360 / 15539 - CLASS_LOSS : 0.11143
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.548297831263273 0.4601754724671257 0.3915953407555184
PSPrecision@1,3,5: 0.3976964969645885 0.4296958823265733 0.44909779072785805
testing....
Precision@1,3,5: 0.46836440010501446 0.3840903124179575 0.3223418220005251
PSPrecision@1,3,5: 0.27912858893943876 0.3068983018777785 0.3219447274009359
211 / 500 :: 448 / 15539 - CLASS_LOSS : 0.14083
211 / 500 :: 1088 / 15539 - CLASS_LOSS : 0.23343
211 / 500 :: 1728 / 15539 - CLASS_LOSS : 0.12979
211 / 500 :: 2368 / 15539 - CLASS_LOSS : 0.19244
211 / 500 :: 3008 / 15539 - CLASS_LOSS : 0.25017
211 / 500 :: 3648 / 15539 - CLASS_LOSS : 0.20725
211 / 500 :: 4288 / 15539 - CLASS_LOSS : 0.15214
211 / 500 :: 4928 / 15539 - CLASS_LOSS : 0.28901
211 / 500 :: 5568 / 15539 - CLASS_LOSS : 0.19297
211 / 500 :: 6208 / 15539 - CLASS_LOSS : 0.19939
211 / 500 :: 6848 / 15539 - CLASS_LOSS : 0.23941
211 / 500 :: 7488 / 15539 - CLASS_LOSS : 0.19279
211 / 500 :: 8128 / 15539 - CLASS_LOSS : 0.195
211 / 500 :: 8768 / 15539 - CLASS_LOSS : 0.14231
211 / 500 :: 9408 / 15539 - CLASS_LOSS : 0.19244
211 / 500 :: 10048 / 15539 - CLASS_LOSS : 0.12464
211 / 500 :: 10688 / 15539 - CLASS_LOSS : 0.1285
211 / 500 :: 11328 / 15539 - CLASS_LOSS : 0.16473
211 / 500 :: 11968 / 15539 - CLASS_LOSS : 0.302
211 / 500 :: 12608 / 15539 - CLASS_LOSS : 0.1875
211 / 500 :: 13248 / 15539 - CLASS_LOSS : 0.14668
211 / 500 :: 13888 / 15539 - CLASS_LOSS : 0.10697
211 / 500 :: 14528 / 15539 - CLASS_LOSS : 0.14388
211 / 500 :: 15168 / 15539 - CLASS_LOSS : 0.17257
212 / 500 :: 256 / 15539 - CLASS_LOSS : 0.22439
212 / 500 :: 896 / 15539 - CLASS_LOSS : 0.21151
212 / 500 :: 1536 / 15539 - CLASS_LOSS : 0.18018
212 / 500 :: 2176 / 15539 - CLASS_LOSS : 0.21306
212 / 500 :: 2816 / 15539 - CLASS_LOSS : 0.10276
212 / 500 :: 3456 / 15539 - CLASS_LOSS : 0.12387
212 / 500 :: 4096 / 15539 - CLASS_LOSS : 0.17145
212 / 500 :: 4736 / 15539 - CLASS_LOSS : 0.10171
212 / 500 :: 5376 / 15539 - CLASS_LOSS : 0.14239
212 / 500 :: 6016 / 15539 - CLASS_LOSS : 0.14301
212 / 500 :: 6656 / 15539 - CLASS_LOSS : 0.14597
212 / 500 :: 7296 / 15539 - CLASS_LOSS : 0.11378
212 / 500 :: 7936 / 15539 - CLASS_LOSS : 0.15188
212 / 500 :: 8576 / 15539 - CLASS_LOSS : 0.12824
212 / 500 :: 9216 / 15539 - CLASS_LOSS : 0.14493
212 / 500 :: 9856 / 15539 - CLASS_LOSS : 0.14762
212 / 500 :: 10496 / 15539 - CLASS_LOSS : 0.2111
212 / 500 :: 11136 / 15539 - CLASS_LOSS : 0.14201
212 / 500 :: 11776 / 15539 - CLASS_LOSS : 0.15942
212 / 500 :: 12416 / 15539 - CLASS_LOSS : 0.19577
212 / 500 :: 13056 / 15539 - CLASS_LOSS : 0.17742
212 / 500 :: 13696 / 15539 - CLASS_LOSS : 0.13052
212 / 500 :: 14336 / 15539 - CLASS_LOSS : 0.10612
212 / 500 :: 14976 / 15539 - CLASS_LOSS : 0.15097
213 / 500 :: 64 / 15539 - CLASS_LOSS : 0.12651
213 / 500 :: 704 / 15539 - CLASS_LOSS : 0.08917
213 / 500 :: 1344 / 15539 - CLASS_LOSS : 0.12897
213 / 500 :: 1984 / 15539 - CLASS_LOSS : 0.12206
213 / 500 :: 2624 / 15539 - CLASS_LOSS : 0.1606
213 / 500 :: 3264 / 15539 - CLASS_LOSS : 0.17323
213 / 500 :: 3904 / 15539 - CLASS_LOSS : 0.17087
213 / 500 :: 4544 / 15539 - CLASS_LOSS : 0.20738
213 / 500 :: 5184 / 15539 - CLASS_LOSS : 0.13386
213 / 500 :: 5824 / 15539 - CLASS_LOSS : 0.18885
213 / 500 :: 6464 / 15539 - CLASS_LOSS : 0.14409
213 / 500 :: 7104 / 15539 - CLASS_LOSS : 0.2174
213 / 500 :: 7744 / 15539 - CLASS_LOSS : 0.11048
213 / 500 :: 8384 / 15539 - CLASS_LOSS : 0.23141
213 / 500 :: 9024 / 15539 - CLASS_LOSS : 0.28032
213 / 500 :: 9664 / 15539 - CLASS_LOSS : 0.11611
213 / 500 :: 10304 / 15539 - CLASS_LOSS : 0.16725
213 / 500 :: 10944 / 15539 - CLASS_LOSS : 0.0987
213 / 500 :: 11584 / 15539 - CLASS_LOSS : 0.18034
213 / 500 :: 12224 / 15539 - CLASS_LOSS : 0.14435
213 / 500 :: 12864 / 15539 - CLASS_LOSS : 0.19113
213 / 500 :: 13504 / 15539 - CLASS_LOSS : 0.21804
213 / 500 :: 14144 / 15539 - CLASS_LOSS : 0.14938
213 / 500 :: 14784 / 15539 - CLASS_LOSS : 0.16161
213 / 500 :: 15424 / 15539 - CLASS_LOSS : 0.11912
214 / 500 :: 512 / 15539 - CLASS_LOSS : 0.13013
214 / 500 :: 1152 / 15539 - CLASS_LOSS : 0.2071
214 / 500 :: 1792 / 15539 - CLASS_LOSS : 0.09363
214 / 500 :: 2432 / 15539 - CLASS_LOSS : 0.18798
214 / 500 :: 3072 / 15539 - CLASS_LOSS : 0.1119
214 / 500 :: 3712 / 15539 - CLASS_LOSS : 0.27934
214 / 500 :: 4352 / 15539 - CLASS_LOSS : 0.1619
214 / 500 :: 4992 / 15539 - CLASS_LOSS : 0.15189
214 / 500 :: 5632 / 15539 - CLASS_LOSS : 0.16974
214 / 500 :: 6272 / 15539 - CLASS_LOSS : 0.11159
214 / 500 :: 6912 / 15539 - CLASS_LOSS : 0.09023
214 / 500 :: 7552 / 15539 - CLASS_LOSS : 0.29074
214 / 500 :: 8192 / 15539 - CLASS_LOSS : 0.14012
214 / 500 :: 8832 / 15539 - CLASS_LOSS : 0.28511
214 / 500 :: 9472 / 15539 - CLASS_LOSS : 0.19636
214 / 500 :: 10112 / 15539 - CLASS_LOSS : 0.16968
214 / 500 :: 10752 / 15539 - CLASS_LOSS : 0.14941
214 / 500 :: 11392 / 15539 - CLASS_LOSS : 0.23468
214 / 500 :: 12032 / 15539 - CLASS_LOSS : 0.07697
214 / 500 :: 12672 / 15539 - CLASS_LOSS : 0.10898
214 / 500 :: 13312 / 15539 - CLASS_LOSS : 0.24348
214 / 500 :: 13952 / 15539 - CLASS_LOSS : 0.07301
214 / 500 :: 14592 / 15539 - CLASS_LOSS : 0.18116
214 / 500 :: 15232 / 15539 - CLASS_LOSS : 0.08395
215 / 500 :: 320 / 15539 - CLASS_LOSS : 0.09664
215 / 500 :: 960 / 15539 - CLASS_LOSS : 0.15452
215 / 500 :: 1600 / 15539 - CLASS_LOSS : 0.17145
215 / 500 :: 2240 / 15539 - CLASS_LOSS : 0.16753
215 / 500 :: 2880 / 15539 - CLASS_LOSS : 0.11228
215 / 500 :: 3520 / 15539 - CLASS_LOSS : 0.10666
215 / 500 :: 4160 / 15539 - CLASS_LOSS : 0.19106
215 / 500 :: 4800 / 15539 - CLASS_LOSS : 0.21001
215 / 500 :: 5440 / 15539 - CLASS_LOSS : 0.17199
215 / 500 :: 6080 / 15539 - CLASS_LOSS : 0.15446
215 / 500 :: 6720 / 15539 - CLASS_LOSS : 0.22175
215 / 500 :: 7360 / 15539 - CLASS_LOSS : 0.19189
215 / 500 :: 8000 / 15539 - CLASS_LOSS : 0.18844
215 / 500 :: 8640 / 15539 - CLASS_LOSS : 0.16191
215 / 500 :: 9280 / 15539 - CLASS_LOSS : 0.11747
215 / 500 :: 9920 / 15539 - CLASS_LOSS : 0.12893
215 / 500 :: 10560 / 15539 - CLASS_LOSS : 0.23076
215 / 500 :: 11200 / 15539 - CLASS_LOSS : 0.10682
215 / 500 :: 11840 / 15539 - CLASS_LOSS : 0.31432
215 / 500 :: 12480 / 15539 - CLASS_LOSS : 0.2485
215 / 500 :: 13120 / 15539 - CLASS_LOSS : 0.15803
215 / 500 :: 13760 / 15539 - CLASS_LOSS : 0.1413
215 / 500 :: 14400 / 15539 - CLASS_LOSS : 0.11406
215 / 500 :: 15040 / 15539 - CLASS_LOSS : 0.22428
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.5342686144539546 0.4568719565823627 0.39155672823218995
PSPrecision@1,3,5: 0.39103896793747916 0.42866022879464877 0.45013332526849176
testing....
Precision@1,3,5: 0.46468889472302444 0.37980222280563575 0.3177736938829089
PSPrecision@1,3,5: 0.28016406731541005 0.306435572905216 0.3178928580237806
216 / 500 :: 128 / 15539 - CLASS_LOSS : 0.13136
216 / 500 :: 768 / 15539 - CLASS_LOSS : 0.20423
216 / 500 :: 1408 / 15539 - CLASS_LOSS : 0.1103
216 / 500 :: 2048 / 15539 - CLASS_LOSS : 0.15342
216 / 500 :: 2688 / 15539 - CLASS_LOSS : 0.24186
216 / 500 :: 3328 / 15539 - CLASS_LOSS : 0.22634
216 / 500 :: 3968 / 15539 - CLASS_LOSS : 0.11768
216 / 500 :: 4608 / 15539 - CLASS_LOSS : 0.33523
216 / 500 :: 5248 / 15539 - CLASS_LOSS : 0.15228
216 / 500 :: 5888 / 15539 - CLASS_LOSS : 0.20437
216 / 500 :: 6528 / 15539 - CLASS_LOSS : 0.2226
216 / 500 :: 7168 / 15539 - CLASS_LOSS : 0.13452
216 / 500 :: 7808 / 15539 - CLASS_LOSS : 0.21632
216 / 500 :: 8448 / 15539 - CLASS_LOSS : 0.13326
216 / 500 :: 9088 / 15539 - CLASS_LOSS : 0.12911
216 / 500 :: 9728 / 15539 - CLASS_LOSS : 0.13912
216 / 500 :: 10368 / 15539 - CLASS_LOSS : 0.19023
216 / 500 :: 11008 / 15539 - CLASS_LOSS : 0.20006
216 / 500 :: 11648 / 15539 - CLASS_LOSS : 0.21399
216 / 500 :: 12288 / 15539 - CLASS_LOSS : 0.21908
216 / 500 :: 12928 / 15539 - CLASS_LOSS : 0.22105
216 / 500 :: 13568 / 15539 - CLASS_LOSS : 0.16384
216 / 500 :: 14208 / 15539 - CLASS_LOSS : 0.15354
216 / 500 :: 14848 / 15539 - CLASS_LOSS : 0.07024
216 / 500 :: 15488 / 15539 - CLASS_LOSS : 0.12481
217 / 500 :: 576 / 15539 - CLASS_LOSS : 0.16853
217 / 500 :: 1216 / 15539 - CLASS_LOSS : 0.18663
217 / 500 :: 1856 / 15539 - CLASS_LOSS : 0.16324
217 / 500 :: 2496 / 15539 - CLASS_LOSS : 0.10206
217 / 500 :: 3136 / 15539 - CLASS_LOSS : 0.16246
217 / 500 :: 3776 / 15539 - CLASS_LOSS : 0.28906
217 / 500 :: 4416 / 15539 - CLASS_LOSS : 0.16855
217 / 500 :: 5056 / 15539 - CLASS_LOSS : 0.11551
217 / 500 :: 5696 / 15539 - CLASS_LOSS : 0.16636
217 / 500 :: 6336 / 15539 - CLASS_LOSS : 0.12961
217 / 500 :: 6976 / 15539 - CLASS_LOSS : 0.12774
217 / 500 :: 7616 / 15539 - CLASS_LOSS : 0.11432
217 / 500 :: 8256 / 15539 - CLASS_LOSS : 0.28765
217 / 500 :: 8896 / 15539 - CLASS_LOSS : 0.2505
217 / 500 :: 9536 / 15539 - CLASS_LOSS : 0.14093
217 / 500 :: 10176 / 15539 - CLASS_LOSS : 0.17481
217 / 500 :: 10816 / 15539 - CLASS_LOSS : 0.14488
217 / 500 :: 11456 / 15539 - CLASS_LOSS : 0.11821
217 / 500 :: 12096 / 15539 - CLASS_LOSS : 0.20774
217 / 500 :: 12736 / 15539 - CLASS_LOSS : 0.17908
217 / 500 :: 13376 / 15539 - CLASS_LOSS : 0.23342
217 / 500 :: 14016 / 15539 - CLASS_LOSS : 0.1921
217 / 500 :: 14656 / 15539 - CLASS_LOSS : 0.12723
217 / 500 :: 15296 / 15539 - CLASS_LOSS : 0.15099
218 / 500 :: 384 / 15539 - CLASS_LOSS : 0.13775
218 / 500 :: 1024 / 15539 - CLASS_LOSS : 0.21049
218 / 500 :: 1664 / 15539 - CLASS_LOSS : 0.2313
218 / 500 :: 2304 / 15539 - CLASS_LOSS : 0.11
218 / 500 :: 2944 / 15539 - CLASS_LOSS : 0.25882
218 / 500 :: 3584 / 15539 - CLASS_LOSS : 0.10971
218 / 500 :: 4224 / 15539 - CLASS_LOSS : 0.15147
218 / 500 :: 4864 / 15539 - CLASS_LOSS : 0.12478
218 / 500 :: 5504 / 15539 - CLASS_LOSS : 0.27819
218 / 500 :: 6144 / 15539 - CLASS_LOSS : 0.17493
218 / 500 :: 6784 / 15539 - CLASS_LOSS : 0.23242
218 / 500 :: 7424 / 15539 - CLASS_LOSS : 0.21662
218 / 500 :: 8064 / 15539 - CLASS_LOSS : 0.17408
218 / 500 :: 8704 / 15539 - CLASS_LOSS : 0.17603
218 / 500 :: 9344 / 15539 - CLASS_LOSS : 0.16681
218 / 500 :: 9984 / 15539 - CLASS_LOSS : 0.30052
218 / 500 :: 10624 / 15539 - CLASS_LOSS : 0.23432
218 / 500 :: 11264 / 15539 - CLASS_LOSS : 0.04778
218 / 500 :: 11904 / 15539 - CLASS_LOSS : 0.21815
218 / 500 :: 12544 / 15539 - CLASS_LOSS : 0.09794
218 / 500 :: 13184 / 15539 - CLASS_LOSS : 0.17717
218 / 500 :: 13824 / 15539 - CLASS_LOSS : 0.17797
218 / 500 :: 14464 / 15539 - CLASS_LOSS : 0.16237
218 / 500 :: 15104 / 15539 - CLASS_LOSS : 0.27867
219 / 500 :: 192 / 15539 - CLASS_LOSS : 0.18151
219 / 500 :: 832 / 15539 - CLASS_LOSS : 0.24708
219 / 500 :: 1472 / 15539 - CLASS_LOSS : 0.14645
219 / 500 :: 2112 / 15539 - CLASS_LOSS : 0.18058
219 / 500 :: 2752 / 15539 - CLASS_LOSS : 0.13763
219 / 500 :: 3392 / 15539 - CLASS_LOSS : 0.21303
219 / 500 :: 4032 / 15539 - CLASS_LOSS : 0.15189
219 / 500 :: 4672 / 15539 - CLASS_LOSS : 0.16112
219 / 500 :: 5312 / 15539 - CLASS_LOSS : 0.19311
219 / 500 :: 5952 / 15539 - CLASS_LOSS : 0.16686
219 / 500 :: 6592 / 15539 - CLASS_LOSS : 0.19586
219 / 500 :: 7232 / 15539 - CLASS_LOSS : 0.11841
219 / 500 :: 7872 / 15539 - CLASS_LOSS : 0.14961
219 / 500 :: 8512 / 15539 - CLASS_LOSS : 0.18345
219 / 500 :: 9152 / 15539 - CLASS_LOSS : 0.1499
219 / 500 :: 9792 / 15539 - CLASS_LOSS : 0.16457
219 / 500 :: 10432 / 15539 - CLASS_LOSS : 0.23472
219 / 500 :: 11072 / 15539 - CLASS_LOSS : 0.1789
219 / 500 :: 11712 / 15539 - CLASS_LOSS : 0.24928
219 / 500 :: 12352 / 15539 - CLASS_LOSS : 0.11564
219 / 500 :: 12992 / 15539 - CLASS_LOSS : 0.22589
219 / 500 :: 13632 / 15539 - CLASS_LOSS : 0.08029
219 / 500 :: 14272 / 15539 - CLASS_LOSS : 0.21042
219 / 500 :: 14912 / 15539 - CLASS_LOSS : 0.16415
219 / 500 :: 15539 / 15539 - CLASS_LOSS : 0.39251
220 / 500 :: 640 / 15539 - CLASS_LOSS : 0.13832
220 / 500 :: 1280 / 15539 - CLASS_LOSS : 0.31757
220 / 500 :: 1920 / 15539 - CLASS_LOSS : 0.17401
220 / 500 :: 2560 / 15539 - CLASS_LOSS : 0.1563
220 / 500 :: 3200 / 15539 - CLASS_LOSS : 0.12752
220 / 500 :: 3840 / 15539 - CLASS_LOSS : 0.13706
220 / 500 :: 4480 / 15539 - CLASS_LOSS : 0.1245
220 / 500 :: 5120 / 15539 - CLASS_LOSS : 0.1574
220 / 500 :: 5760 / 15539 - CLASS_LOSS : 0.1048
220 / 500 :: 6400 / 15539 - CLASS_LOSS : 0.24716
220 / 500 :: 7040 / 15539 - CLASS_LOSS : 0.18219
220 / 500 :: 7680 / 15539 - CLASS_LOSS : 0.16955
220 / 500 :: 8320 / 15539 - CLASS_LOSS : 0.09769
220 / 500 :: 8960 / 15539 - CLASS_LOSS : 0.11722
220 / 500 :: 9600 / 15539 - CLASS_LOSS : 0.17499
220 / 500 :: 10240 / 15539 - CLASS_LOSS : 0.12794
220 / 500 :: 10880 / 15539 - CLASS_LOSS : 0.11001
220 / 500 :: 11520 / 15539 - CLASS_LOSS : 0.14572
220 / 500 :: 12160 / 15539 - CLASS_LOSS : 0.16787
220 / 500 :: 12800 / 15539 - CLASS_LOSS : 0.07696
220 / 500 :: 13440 / 15539 - CLASS_LOSS : 0.13512
220 / 500 :: 14080 / 15539 - CLASS_LOSS : 0.15551
220 / 500 :: 14720 / 15539 - CLASS_LOSS : 0.19135
220 / 500 :: 15360 / 15539 - CLASS_LOSS : 0.22377
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.5518373125683763 0.46320012012785033 0.396550614582663
PSPrecision@1,3,5: 0.4005144928280457 0.43423696793820177 0.4559035218908776
testing....
Precision@1,3,5: 0.46285114203202943 0.3809398792333946 0.3210816487266999
PSPrecision@1,3,5: 0.27885905676355904 0.3083351175639217 0.3228132734484069
221 / 500 :: 448 / 15539 - CLASS_LOSS : 0.1397
221 / 500 :: 1088 / 15539 - CLASS_LOSS : 0.16279
221 / 500 :: 1728 / 15539 - CLASS_LOSS : 0.1428
221 / 500 :: 2368 / 15539 - CLASS_LOSS : 0.13479
221 / 500 :: 3008 / 15539 - CLASS_LOSS : 0.10839
221 / 500 :: 3648 / 15539 - CLASS_LOSS : 0.17863
221 / 500 :: 4288 / 15539 - CLASS_LOSS : 0.12921
221 / 500 :: 4928 / 15539 - CLASS_LOSS : 0.22573
221 / 500 :: 5568 / 15539 - CLASS_LOSS : 0.19003
221 / 500 :: 6208 / 15539 - CLASS_LOSS : 0.27721
221 / 500 :: 6848 / 15539 - CLASS_LOSS : 0.16353
221 / 500 :: 7488 / 15539 - CLASS_LOSS : 0.09516
221 / 500 :: 8128 / 15539 - CLASS_LOSS : 0.18904
221 / 500 :: 8768 / 15539 - CLASS_LOSS : 0.14303
221 / 500 :: 9408 / 15539 - CLASS_LOSS : 0.15931
221 / 500 :: 10048 / 15539 - CLASS_LOSS : 0.19271
221 / 500 :: 10688 / 15539 - CLASS_LOSS : 0.209
221 / 500 :: 11328 / 15539 - CLASS_LOSS : 0.09983
221 / 500 :: 11968 / 15539 - CLASS_LOSS : 0.16566
221 / 500 :: 12608 / 15539 - CLASS_LOSS : 0.25426
221 / 500 :: 13248 / 15539 - CLASS_LOSS : 0.16674
221 / 500 :: 13888 / 15539 - CLASS_LOSS : 0.13735
221 / 500 :: 14528 / 15539 - CLASS_LOSS : 0.20134
221 / 500 :: 15168 / 15539 - CLASS_LOSS : 0.24048
222 / 500 :: 256 / 15539 - CLASS_LOSS : 0.16679
222 / 500 :: 896 / 15539 - CLASS_LOSS : 0.18294
222 / 500 :: 1536 / 15539 - CLASS_LOSS : 0.14502
222 / 500 :: 2176 / 15539 - CLASS_LOSS : 0.19578
222 / 500 :: 2816 / 15539 - CLASS_LOSS : 0.30079
222 / 500 :: 3456 / 15539 - CLASS_LOSS : 0.16686
222 / 500 :: 4096 / 15539 - CLASS_LOSS : 0.22603
222 / 500 :: 4736 / 15539 - CLASS_LOSS : 0.08193
222 / 500 :: 5376 / 15539 - CLASS_LOSS : 0.13731
222 / 500 :: 6016 / 15539 - CLASS_LOSS : 0.14902
222 / 500 :: 6656 / 15539 - CLASS_LOSS : 0.16707
222 / 500 :: 7296 / 15539 - CLASS_LOSS : 0.19789
222 / 500 :: 7936 / 15539 - CLASS_LOSS : 0.15506
222 / 500 :: 8576 / 15539 - CLASS_LOSS : 0.14212
222 / 500 :: 9216 / 15539 - CLASS_LOSS : 0.23628
222 / 500 :: 9856 / 15539 - CLASS_LOSS : 0.12585
222 / 500 :: 10496 / 15539 - CLASS_LOSS : 0.16868
222 / 500 :: 11136 / 15539 - CLASS_LOSS : 0.22441
222 / 500 :: 11776 / 15539 - CLASS_LOSS : 0.14124
222 / 500 :: 12416 / 15539 - CLASS_LOSS : 0.13015
222 / 500 :: 13056 / 15539 - CLASS_LOSS : 0.12152
222 / 500 :: 13696 / 15539 - CLASS_LOSS : 0.16544
222 / 500 :: 14336 / 15539 - CLASS_LOSS : 0.19022
222 / 500 :: 14976 / 15539 - CLASS_LOSS : 0.20028
223 / 500 :: 64 / 15539 - CLASS_LOSS : 0.28703
223 / 500 :: 704 / 15539 - CLASS_LOSS : 0.13566
223 / 500 :: 1344 / 15539 - CLASS_LOSS : 0.20122
223 / 500 :: 1984 / 15539 - CLASS_LOSS : 0.19227
223 / 500 :: 2624 / 15539 - CLASS_LOSS : 0.15623
223 / 500 :: 3264 / 15539 - CLASS_LOSS : 0.14636
223 / 500 :: 3904 / 15539 - CLASS_LOSS : 0.13283
223 / 500 :: 4544 / 15539 - CLASS_LOSS : 0.1495
223 / 500 :: 5184 / 15539 - CLASS_LOSS : 0.15348
223 / 500 :: 5824 / 15539 - CLASS_LOSS : 0.06329
223 / 500 :: 6464 / 15539 - CLASS_LOSS : 0.18726
223 / 500 :: 7104 / 15539 - CLASS_LOSS : 0.22306
223 / 500 :: 7744 / 15539 - CLASS_LOSS : 0.28604
223 / 500 :: 8384 / 15539 - CLASS_LOSS : 0.12313
223 / 500 :: 9024 / 15539 - CLASS_LOSS : 0.23147
223 / 500 :: 9664 / 15539 - CLASS_LOSS : 0.21475
223 / 500 :: 10304 / 15539 - CLASS_LOSS : 0.17195
223 / 500 :: 10944 / 15539 - CLASS_LOSS : 0.18758
223 / 500 :: 11584 / 15539 - CLASS_LOSS : 0.20988
223 / 500 :: 12224 / 15539 - CLASS_LOSS : 0.22541
223 / 500 :: 12864 / 15539 - CLASS_LOSS : 0.10583
223 / 500 :: 13504 / 15539 - CLASS_LOSS : 0.13062
223 / 500 :: 14144 / 15539 - CLASS_LOSS : 0.17738
223 / 500 :: 14784 / 15539 - CLASS_LOSS : 0.2012
223 / 500 :: 15424 / 15539 - CLASS_LOSS : 0.1046
224 / 500 :: 512 / 15539 - CLASS_LOSS : 0.14699
224 / 500 :: 1152 / 15539 - CLASS_LOSS : 0.14521
224 / 500 :: 1792 / 15539 - CLASS_LOSS : 0.10624
224 / 500 :: 2432 / 15539 - CLASS_LOSS : 0.16142
224 / 500 :: 3072 / 15539 - CLASS_LOSS : 0.1255
224 / 500 :: 3712 / 15539 - CLASS_LOSS : 0.17521
224 / 500 :: 4352 / 15539 - CLASS_LOSS : 0.10641
224 / 500 :: 4992 / 15539 - CLASS_LOSS : 0.20701
224 / 500 :: 5632 / 15539 - CLASS_LOSS : 0.12902
224 / 500 :: 6272 / 15539 - CLASS_LOSS : 0.18341
224 / 500 :: 6912 / 15539 - CLASS_LOSS : 0.13108
224 / 500 :: 7552 / 15539 - CLASS_LOSS : 0.21464
224 / 500 :: 8192 / 15539 - CLASS_LOSS : 0.20822
224 / 500 :: 8832 / 15539 - CLASS_LOSS : 0.21627
224 / 500 :: 9472 / 15539 - CLASS_LOSS : 0.32617
224 / 500 :: 10112 / 15539 - CLASS_LOSS : 0.09425
224 / 500 :: 10752 / 15539 - CLASS_LOSS : 0.08304
224 / 500 :: 11392 / 15539 - CLASS_LOSS : 0.23576
224 / 500 :: 12032 / 15539 - CLASS_LOSS : 0.1486
224 / 500 :: 12672 / 15539 - CLASS_LOSS : 0.15176
224 / 500 :: 13312 / 15539 - CLASS_LOSS : 0.20651
224 / 500 :: 13952 / 15539 - CLASS_LOSS : 0.131
224 / 500 :: 14592 / 15539 - CLASS_LOSS : 0.20374
224 / 500 :: 15232 / 15539 - CLASS_LOSS : 0.16491
225 / 500 :: 320 / 15539 - CLASS_LOSS : 0.10925
225 / 500 :: 960 / 15539 - CLASS_LOSS : 0.26559
225 / 500 :: 1600 / 15539 - CLASS_LOSS : 0.17984
225 / 500 :: 2240 / 15539 - CLASS_LOSS : 0.17003
225 / 500 :: 2880 / 15539 - CLASS_LOSS : 0.2724
225 / 500 :: 3520 / 15539 - CLASS_LOSS : 0.17337
225 / 500 :: 4160 / 15539 - CLASS_LOSS : 0.12281
225 / 500 :: 4800 / 15539 - CLASS_LOSS : 0.17963
225 / 500 :: 5440 / 15539 - CLASS_LOSS : 0.17513
225 / 500 :: 6080 / 15539 - CLASS_LOSS : 0.19893
225 / 500 :: 6720 / 15539 - CLASS_LOSS : 0.12026
225 / 500 :: 7360 / 15539 - CLASS_LOSS : 0.12664
225 / 500 :: 8000 / 15539 - CLASS_LOSS : 0.09545
225 / 500 :: 8640 / 15539 - CLASS_LOSS : 0.2675
225 / 500 :: 9280 / 15539 - CLASS_LOSS : 0.1773
225 / 500 :: 9920 / 15539 - CLASS_LOSS : 0.18118
225 / 500 :: 10560 / 15539 - CLASS_LOSS : 0.17614
225 / 500 :: 11200 / 15539 - CLASS_LOSS : 0.14668
225 / 500 :: 11840 / 15539 - CLASS_LOSS : 0.15042
225 / 500 :: 12480 / 15539 - CLASS_LOSS : 0.20293
225 / 500 :: 13120 / 15539 - CLASS_LOSS : 0.18254
225 / 500 :: 13760 / 15539 - CLASS_LOSS : 0.12415
225 / 500 :: 14400 / 15539 - CLASS_LOSS : 0.16211
225 / 500 :: 15040 / 15539 - CLASS_LOSS : 0.11188
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.5518373125683763 0.46399382199626743 0.39809511551579896
PSPrecision@1,3,5: 0.40006671263067883 0.4364504445676191 0.4590412271165096
testing....
Precision@1,3,5: 0.47046468889472304 0.3838277763192439 0.3211341559464426
PSPrecision@1,3,5: 0.2811302037966729 0.3086038998075674 0.32142402948608945
226 / 500 :: 128 / 15539 - CLASS_LOSS : 0.26869
226 / 500 :: 768 / 15539 - CLASS_LOSS : 0.16643
226 / 500 :: 1408 / 15539 - CLASS_LOSS : 0.25545
226 / 500 :: 2048 / 15539 - CLASS_LOSS : 0.18541
226 / 500 :: 2688 / 15539 - CLASS_LOSS : 0.13105
226 / 500 :: 3328 / 15539 - CLASS_LOSS : 0.2115
226 / 500 :: 3968 / 15539 - CLASS_LOSS : 0.16216
226 / 500 :: 4608 / 15539 - CLASS_LOSS : 0.11366
226 / 500 :: 5248 / 15539 - CLASS_LOSS : 0.15552
226 / 500 :: 5888 / 15539 - CLASS_LOSS : 0.15502
226 / 500 :: 6528 / 15539 - CLASS_LOSS : 0.09374
226 / 500 :: 7168 / 15539 - CLASS_LOSS : 0.18594
226 / 500 :: 7808 / 15539 - CLASS_LOSS : 0.13181
226 / 500 :: 8448 / 15539 - CLASS_LOSS : 0.14059
226 / 500 :: 9088 / 15539 - CLASS_LOSS : 0.11645
226 / 500 :: 9728 / 15539 - CLASS_LOSS : 0.14516
226 / 500 :: 10368 / 15539 - CLASS_LOSS : 0.13513
226 / 500 :: 11008 / 15539 - CLASS_LOSS : 0.10963
226 / 500 :: 11648 / 15539 - CLASS_LOSS : 0.14382
226 / 500 :: 12288 / 15539 - CLASS_LOSS : 0.18673
226 / 500 :: 12928 / 15539 - CLASS_LOSS : 0.19728
226 / 500 :: 13568 / 15539 - CLASS_LOSS : 0.11638
226 / 500 :: 14208 / 15539 - CLASS_LOSS : 0.11579
226 / 500 :: 14848 / 15539 - CLASS_LOSS : 0.15559
226 / 500 :: 15488 / 15539 - CLASS_LOSS : 0.15281
227 / 500 :: 576 / 15539 - CLASS_LOSS : 0.2111
227 / 500 :: 1216 / 15539 - CLASS_LOSS : 0.15481
227 / 500 :: 1856 / 15539 - CLASS_LOSS : 0.24347
227 / 500 :: 2496 / 15539 - CLASS_LOSS : 0.14569
227 / 500 :: 3136 / 15539 - CLASS_LOSS : 0.23734
227 / 500 :: 3776 / 15539 - CLASS_LOSS : 0.19776
227 / 500 :: 4416 / 15539 - CLASS_LOSS : 0.20792
227 / 500 :: 5056 / 15539 - CLASS_LOSS : 0.17857
227 / 500 :: 5696 / 15539 - CLASS_LOSS : 0.10144
227 / 500 :: 6336 / 15539 - CLASS_LOSS : 0.16259
227 / 500 :: 6976 / 15539 - CLASS_LOSS : 0.16161
227 / 500 :: 7616 / 15539 - CLASS_LOSS : 0.17647
227 / 500 :: 8256 / 15539 - CLASS_LOSS : 0.10535
227 / 500 :: 8896 / 15539 - CLASS_LOSS : 0.18605
227 / 500 :: 9536 / 15539 - CLASS_LOSS : 0.12895
227 / 500 :: 10176 / 15539 - CLASS_LOSS : 0.29529
227 / 500 :: 10816 / 15539 - CLASS_LOSS : 0.17939
227 / 500 :: 11456 / 15539 - CLASS_LOSS : 0.08907
227 / 500 :: 12096 / 15539 - CLASS_LOSS : 0.14442
227 / 500 :: 12736 / 15539 - CLASS_LOSS : 0.12889
227 / 500 :: 13376 / 15539 - CLASS_LOSS : 0.17304
227 / 500 :: 14016 / 15539 - CLASS_LOSS : 0.19489
227 / 500 :: 14656 / 15539 - CLASS_LOSS : 0.24888
227 / 500 :: 15296 / 15539 - CLASS_LOSS : 0.33821
228 / 500 :: 384 / 15539 - CLASS_LOSS : 0.13911
228 / 500 :: 1024 / 15539 - CLASS_LOSS : 0.1568
228 / 500 :: 1664 / 15539 - CLASS_LOSS : 0.16174
228 / 500 :: 2304 / 15539 - CLASS_LOSS : 0.25471
228 / 500 :: 2944 / 15539 - CLASS_LOSS : 0.11994
228 / 500 :: 3584 / 15539 - CLASS_LOSS : 0.15818
228 / 500 :: 4224 / 15539 - CLASS_LOSS : 0.15119
228 / 500 :: 4864 / 15539 - CLASS_LOSS : 0.15971
228 / 500 :: 5504 / 15539 - CLASS_LOSS : 0.31729
228 / 500 :: 6144 / 15539 - CLASS_LOSS : 0.19645
228 / 500 :: 6784 / 15539 - CLASS_LOSS : 0.18078
228 / 500 :: 7424 / 15539 - CLASS_LOSS : 0.22763
228 / 500 :: 8064 / 15539 - CLASS_LOSS : 0.20772
228 / 500 :: 8704 / 15539 - CLASS_LOSS : 0.12876
228 / 500 :: 9344 / 15539 - CLASS_LOSS : 0.15555
228 / 500 :: 9984 / 15539 - CLASS_LOSS : 0.13151
228 / 500 :: 10624 / 15539 - CLASS_LOSS : 0.14598
228 / 500 :: 11264 / 15539 - CLASS_LOSS : 0.19465
228 / 500 :: 11904 / 15539 - CLASS_LOSS : 0.1551
228 / 500 :: 12544 / 15539 - CLASS_LOSS : 0.16052
228 / 500 :: 13184 / 15539 - CLASS_LOSS : 0.16322
228 / 500 :: 13824 / 15539 - CLASS_LOSS : 0.18108
228 / 500 :: 14464 / 15539 - CLASS_LOSS : 0.16856
228 / 500 :: 15104 / 15539 - CLASS_LOSS : 0.18062
229 / 500 :: 192 / 15539 - CLASS_LOSS : 0.18796
229 / 500 :: 832 / 15539 - CLASS_LOSS : 0.08376
229 / 500 :: 1472 / 15539 - CLASS_LOSS : 0.14505
229 / 500 :: 2112 / 15539 - CLASS_LOSS : 0.14574
229 / 500 :: 2752 / 15539 - CLASS_LOSS : 0.06162
229 / 500 :: 3392 / 15539 - CLASS_LOSS : 0.08941
229 / 500 :: 4032 / 15539 - CLASS_LOSS : 0.42162
229 / 500 :: 4672 / 15539 - CLASS_LOSS : 0.14345
229 / 500 :: 5312 / 15539 - CLASS_LOSS : 0.21423
229 / 500 :: 5952 / 15539 - CLASS_LOSS : 0.19284
229 / 500 :: 6592 / 15539 - CLASS_LOSS : 0.11938
229 / 500 :: 7232 / 15539 - CLASS_LOSS : 0.3308
229 / 500 :: 7872 / 15539 - CLASS_LOSS : 0.10591
229 / 500 :: 8512 / 15539 - CLASS_LOSS : 0.12615
229 / 500 :: 9152 / 15539 - CLASS_LOSS : 0.1142
229 / 500 :: 9792 / 15539 - CLASS_LOSS : 0.26906
229 / 500 :: 10432 / 15539 - CLASS_LOSS : 0.09481
229 / 500 :: 11072 / 15539 - CLASS_LOSS : 0.30438
229 / 500 :: 11712 / 15539 - CLASS_LOSS : 0.09639
229 / 500 :: 12352 / 15539 - CLASS_LOSS : 0.11599
229 / 500 :: 12992 / 15539 - CLASS_LOSS : 0.14327
229 / 500 :: 13632 / 15539 - CLASS_LOSS : 0.14621
229 / 500 :: 14272 / 15539 - CLASS_LOSS : 0.16812
229 / 500 :: 14912 / 15539 - CLASS_LOSS : 0.12274
229 / 500 :: 15539 / 15539 - CLASS_LOSS : 0.30372
230 / 500 :: 640 / 15539 - CLASS_LOSS : 0.1842
230 / 500 :: 1280 / 15539 - CLASS_LOSS : 0.13882
230 / 500 :: 1920 / 15539 - CLASS_LOSS : 0.131
230 / 500 :: 2560 / 15539 - CLASS_LOSS : 0.1775
230 / 500 :: 3200 / 15539 - CLASS_LOSS : 0.09885
230 / 500 :: 3840 / 15539 - CLASS_LOSS : 0.1557
230 / 500 :: 4480 / 15539 - CLASS_LOSS : 0.13182
230 / 500 :: 5120 / 15539 - CLASS_LOSS : 0.10242
230 / 500 :: 5760 / 15539 - CLASS_LOSS : 0.10403
230 / 500 :: 6400 / 15539 - CLASS_LOSS : 0.21949
230 / 500 :: 7040 / 15539 - CLASS_LOSS : 0.18165
230 / 500 :: 7680 / 15539 - CLASS_LOSS : 0.15418
230 / 500 :: 8320 / 15539 - CLASS_LOSS : 0.10156
230 / 500 :: 8960 / 15539 - CLASS_LOSS : 0.1989
230 / 500 :: 9600 / 15539 - CLASS_LOSS : 0.33156
230 / 500 :: 10240 / 15539 - CLASS_LOSS : 0.25919
230 / 500 :: 10880 / 15539 - CLASS_LOSS : 0.15605
230 / 500 :: 11520 / 15539 - CLASS_LOSS : 0.12366
230 / 500 :: 12160 / 15539 - CLASS_LOSS : 0.15905
230 / 500 :: 12800 / 15539 - CLASS_LOSS : 0.19237
230 / 500 :: 13440 / 15539 - CLASS_LOSS : 0.14199
230 / 500 :: 14080 / 15539 - CLASS_LOSS : 0.15831
230 / 500 :: 14720 / 15539 - CLASS_LOSS : 0.11743
230 / 500 :: 15360 / 15539 - CLASS_LOSS : 0.17799
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.5646437994722955 0.4712443958212669 0.4012484715876182
PSPrecision@1,3,5: 0.40605972144892927 0.4409505663377132 0.45919442396670335
testing....
Precision@1,3,5: 0.4746652664741402 0.3855780169773344 0.3290102389078498
PSPrecision@1,3,5: 0.280993320051513 0.30748489851030436 0.3280359824373768
231 / 500 :: 448 / 15539 - CLASS_LOSS : 0.18596
231 / 500 :: 1088 / 15539 - CLASS_LOSS : 0.15469
231 / 500 :: 1728 / 15539 - CLASS_LOSS : 0.2051
231 / 500 :: 2368 / 15539 - CLASS_LOSS : 0.11774
231 / 500 :: 3008 / 15539 - CLASS_LOSS : 0.19122
231 / 500 :: 3648 / 15539 - CLASS_LOSS : 0.16102
231 / 500 :: 4288 / 15539 - CLASS_LOSS : 0.12684
231 / 500 :: 4928 / 15539 - CLASS_LOSS : 0.15212
231 / 500 :: 5568 / 15539 - CLASS_LOSS : 0.21656
231 / 500 :: 6208 / 15539 - CLASS_LOSS : 0.209
231 / 500 :: 6848 / 15539 - CLASS_LOSS : 0.11171
231 / 500 :: 7488 / 15539 - CLASS_LOSS : 0.11279
231 / 500 :: 8128 / 15539 - CLASS_LOSS : 0.15454
231 / 500 :: 8768 / 15539 - CLASS_LOSS : 0.28338
231 / 500 :: 9408 / 15539 - CLASS_LOSS : 0.12119
231 / 500 :: 10048 / 15539 - CLASS_LOSS : 0.15833
231 / 500 :: 10688 / 15539 - CLASS_LOSS : 0.13709
231 / 500 :: 11328 / 15539 - CLASS_LOSS : 0.16735
231 / 500 :: 11968 / 15539 - CLASS_LOSS : 0.1603
231 / 500 :: 12608 / 15539 - CLASS_LOSS : 0.27896
231 / 500 :: 13248 / 15539 - CLASS_LOSS : 0.27718
231 / 500 :: 13888 / 15539 - CLASS_LOSS : 0.16375
231 / 500 :: 14528 / 15539 - CLASS_LOSS : 0.17761
231 / 500 :: 15168 / 15539 - CLASS_LOSS : 0.16736
232 / 500 :: 256 / 15539 - CLASS_LOSS : 0.13629
232 / 500 :: 896 / 15539 - CLASS_LOSS : 0.16948
232 / 500 :: 1536 / 15539 - CLASS_LOSS : 0.17739
232 / 500 :: 2176 / 15539 - CLASS_LOSS : 0.09351
232 / 500 :: 2816 / 15539 - CLASS_LOSS : 0.15796
232 / 500 :: 3456 / 15539 - CLASS_LOSS : 0.19509
232 / 500 :: 4096 / 15539 - CLASS_LOSS : 0.16057
232 / 500 :: 4736 / 15539 - CLASS_LOSS : 0.12797
232 / 500 :: 5376 / 15539 - CLASS_LOSS : 0.12207
232 / 500 :: 6016 / 15539 - CLASS_LOSS : 0.17863
232 / 500 :: 6656 / 15539 - CLASS_LOSS : 0.15623
232 / 500 :: 7296 / 15539 - CLASS_LOSS : 0.13891
232 / 500 :: 7936 / 15539 - CLASS_LOSS : 0.29198
232 / 500 :: 8576 / 15539 - CLASS_LOSS : 0.12478
232 / 500 :: 9216 / 15539 - CLASS_LOSS : 0.2122
232 / 500 :: 9856 / 15539 - CLASS_LOSS : 0.10735
232 / 500 :: 10496 / 15539 - CLASS_LOSS : 0.17978
232 / 500 :: 11136 / 15539 - CLASS_LOSS : 0.16035
232 / 500 :: 11776 / 15539 - CLASS_LOSS : 0.12215
232 / 500 :: 12416 / 15539 - CLASS_LOSS : 0.15215
232 / 500 :: 13056 / 15539 - CLASS_LOSS : 0.19356
232 / 500 :: 13696 / 15539 - CLASS_LOSS : 0.14193
232 / 500 :: 14336 / 15539 - CLASS_LOSS : 0.23322
232 / 500 :: 14976 / 15539 - CLASS_LOSS : 0.18031
233 / 500 :: 64 / 15539 - CLASS_LOSS : 0.12173
233 / 500 :: 704 / 15539 - CLASS_LOSS : 0.13213
233 / 500 :: 1344 / 15539 - CLASS_LOSS : 0.16943
233 / 500 :: 1984 / 15539 - CLASS_LOSS : 0.17845
233 / 500 :: 2624 / 15539 - CLASS_LOSS : 0.17448
233 / 500 :: 3264 / 15539 - CLASS_LOSS : 0.1513
233 / 500 :: 3904 / 15539 - CLASS_LOSS : 0.18266
233 / 500 :: 4544 / 15539 - CLASS_LOSS : 0.25914
233 / 500 :: 5184 / 15539 - CLASS_LOSS : 0.19834
233 / 500 :: 5824 / 15539 - CLASS_LOSS : 0.17434
233 / 500 :: 6464 / 15539 - CLASS_LOSS : 0.17742
233 / 500 :: 7104 / 15539 - CLASS_LOSS : 0.10797
233 / 500 :: 7744 / 15539 - CLASS_LOSS : 0.17277
233 / 500 :: 8384 / 15539 - CLASS_LOSS : 0.18514
233 / 500 :: 9024 / 15539 - CLASS_LOSS : 0.20208
233 / 500 :: 9664 / 15539 - CLASS_LOSS : 0.1775
233 / 500 :: 10304 / 15539 - CLASS_LOSS : 0.09849
233 / 500 :: 10944 / 15539 - CLASS_LOSS : 0.10922
233 / 500 :: 11584 / 15539 - CLASS_LOSS : 0.15886
233 / 500 :: 12224 / 15539 - CLASS_LOSS : 0.10677
233 / 500 :: 12864 / 15539 - CLASS_LOSS : 0.22199
233 / 500 :: 13504 / 15539 - CLASS_LOSS : 0.17733
233 / 500 :: 14144 / 15539 - CLASS_LOSS : 0.19647
233 / 500 :: 14784 / 15539 - CLASS_LOSS : 0.16562
233 / 500 :: 15424 / 15539 - CLASS_LOSS : 0.14967
234 / 500 :: 512 / 15539 - CLASS_LOSS : 0.166
234 / 500 :: 1152 / 15539 - CLASS_LOSS : 0.11902
234 / 500 :: 1792 / 15539 - CLASS_LOSS : 0.13862
234 / 500 :: 2432 / 15539 - CLASS_LOSS : 0.23409
234 / 500 :: 3072 / 15539 - CLASS_LOSS : 0.19601
234 / 500 :: 3712 / 15539 - CLASS_LOSS : 0.08417
234 / 500 :: 4352 / 15539 - CLASS_LOSS : 0.19862
234 / 500 :: 4992 / 15539 - CLASS_LOSS : 0.15514
234 / 500 :: 5632 / 15539 - CLASS_LOSS : 0.18821
234 / 500 :: 6272 / 15539 - CLASS_LOSS : 0.17325
234 / 500 :: 6912 / 15539 - CLASS_LOSS : 0.16721
234 / 500 :: 7552 / 15539 - CLASS_LOSS : 0.14033
234 / 500 :: 8192 / 15539 - CLASS_LOSS : 0.20198
234 / 500 :: 8832 / 15539 - CLASS_LOSS : 0.09344
234 / 500 :: 9472 / 15539 - CLASS_LOSS : 0.18257
234 / 500 :: 10112 / 15539 - CLASS_LOSS : 0.08453
234 / 500 :: 10752 / 15539 - CLASS_LOSS : 0.20641
234 / 500 :: 11392 / 15539 - CLASS_LOSS : 0.16281
234 / 500 :: 12032 / 15539 - CLASS_LOSS : 0.21194
234 / 500 :: 12672 / 15539 - CLASS_LOSS : 0.16571
234 / 500 :: 13312 / 15539 - CLASS_LOSS : 0.18103
234 / 500 :: 13952 / 15539 - CLASS_LOSS : 0.23286
234 / 500 :: 14592 / 15539 - CLASS_LOSS : 0.17127
234 / 500 :: 15232 / 15539 - CLASS_LOSS : 0.15602
235 / 500 :: 320 / 15539 - CLASS_LOSS : 0.17929
235 / 500 :: 960 / 15539 - CLASS_LOSS : 0.14634
235 / 500 :: 1600 / 15539 - CLASS_LOSS : 0.21072
235 / 500 :: 2240 / 15539 - CLASS_LOSS : 0.16411
235 / 500 :: 2880 / 15539 - CLASS_LOSS : 0.12101
235 / 500 :: 3520 / 15539 - CLASS_LOSS : 0.16215
235 / 500 :: 4160 / 15539 - CLASS_LOSS : 0.11782
235 / 500 :: 4800 / 15539 - CLASS_LOSS : 0.14604
235 / 500 :: 5440 / 15539 - CLASS_LOSS : 0.20316
235 / 500 :: 6080 / 15539 - CLASS_LOSS : 0.15086
235 / 500 :: 6720 / 15539 - CLASS_LOSS : 0.13602
235 / 500 :: 7360 / 15539 - CLASS_LOSS : 0.14376
235 / 500 :: 8000 / 15539 - CLASS_LOSS : 0.11531
235 / 500 :: 8640 / 15539 - CLASS_LOSS : 0.18694
235 / 500 :: 9280 / 15539 - CLASS_LOSS : 0.10461
235 / 500 :: 9920 / 15539 - CLASS_LOSS : 0.13545
235 / 500 :: 10560 / 15539 - CLASS_LOSS : 0.11632
235 / 500 :: 11200 / 15539 - CLASS_LOSS : 0.15372
235 / 500 :: 11840 / 15539 - CLASS_LOSS : 0.27746
235 / 500 :: 12480 / 15539 - CLASS_LOSS : 0.16307
235 / 500 :: 13120 / 15539 - CLASS_LOSS : 0.10862
235 / 500 :: 13760 / 15539 - CLASS_LOSS : 0.14283
235 / 500 :: 14400 / 15539 - CLASS_LOSS : 0.2109
235 / 500 :: 15040 / 15539 - CLASS_LOSS : 0.14761
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.5575004826565416 0.46618186498487674 0.40060492953214494
PSPrecision@1,3,5: 0.407034107942557 0.4378856659425957 0.4602189821769937
testing....
Precision@1,3,5: 0.4709897610921502 0.3822525597269625 0.3212391703859281
PSPrecision@1,3,5: 0.28615861949712623 0.3070810871650073 0.32121055960428174
236 / 500 :: 128 / 15539 - CLASS_LOSS : 0.19756
236 / 500 :: 768 / 15539 - CLASS_LOSS : 0.15613
236 / 500 :: 1408 / 15539 - CLASS_LOSS : 0.20279
236 / 500 :: 2048 / 15539 - CLASS_LOSS : 0.20712
236 / 500 :: 2688 / 15539 - CLASS_LOSS : 0.17223
236 / 500 :: 3328 / 15539 - CLASS_LOSS : 0.11173
236 / 500 :: 3968 / 15539 - CLASS_LOSS : 0.14302
236 / 500 :: 4608 / 15539 - CLASS_LOSS : 0.17674
236 / 500 :: 5248 / 15539 - CLASS_LOSS : 0.14421
236 / 500 :: 5888 / 15539 - CLASS_LOSS : 0.1436
236 / 500 :: 6528 / 15539 - CLASS_LOSS : 0.10819
236 / 500 :: 7168 / 15539 - CLASS_LOSS : 0.25743
236 / 500 :: 7808 / 15539 - CLASS_LOSS : 0.14225
236 / 500 :: 8448 / 15539 - CLASS_LOSS : 0.17846
236 / 500 :: 9088 / 15539 - CLASS_LOSS : 0.18211
236 / 500 :: 9728 / 15539 - CLASS_LOSS : 0.17438
236 / 500 :: 10368 / 15539 - CLASS_LOSS : 0.12735
236 / 500 :: 11008 / 15539 - CLASS_LOSS : 0.2515
236 / 500 :: 11648 / 15539 - CLASS_LOSS : 0.10849
236 / 500 :: 12288 / 15539 - CLASS_LOSS : 0.12846
236 / 500 :: 12928 / 15539 - CLASS_LOSS : 0.10667
236 / 500 :: 13568 / 15539 - CLASS_LOSS : 0.20351
236 / 500 :: 14208 / 15539 - CLASS_LOSS : 0.18601
236 / 500 :: 14848 / 15539 - CLASS_LOSS : 0.15772
236 / 500 :: 15488 / 15539 - CLASS_LOSS : 0.29212
237 / 500 :: 576 / 15539 - CLASS_LOSS : 0.19759
237 / 500 :: 1216 / 15539 - CLASS_LOSS : 0.19893
237 / 500 :: 1856 / 15539 - CLASS_LOSS : 0.10151
237 / 500 :: 2496 / 15539 - CLASS_LOSS : 0.23456
237 / 500 :: 3136 / 15539 - CLASS_LOSS : 0.12151
237 / 500 :: 3776 / 15539 - CLASS_LOSS : 0.18232
237 / 500 :: 4416 / 15539 - CLASS_LOSS : 0.18159
237 / 500 :: 5056 / 15539 - CLASS_LOSS : 0.16453
237 / 500 :: 5696 / 15539 - CLASS_LOSS : 0.18206
237 / 500 :: 6336 / 15539 - CLASS_LOSS : 0.19191
237 / 500 :: 6976 / 15539 - CLASS_LOSS : 0.17277
237 / 500 :: 7616 / 15539 - CLASS_LOSS : 0.33656
237 / 500 :: 8256 / 15539 - CLASS_LOSS : 0.20017
237 / 500 :: 8896 / 15539 - CLASS_LOSS : 0.20407
237 / 500 :: 9536 / 15539 - CLASS_LOSS : 0.14396
237 / 500 :: 10176 / 15539 - CLASS_LOSS : 0.17678
237 / 500 :: 10816 / 15539 - CLASS_LOSS : 0.23318
237 / 500 :: 11456 / 15539 - CLASS_LOSS : 0.17802
237 / 500 :: 12096 / 15539 - CLASS_LOSS : 0.18306
237 / 500 :: 12736 / 15539 - CLASS_LOSS : 0.13741
237 / 500 :: 13376 / 15539 - CLASS_LOSS : 0.17194
237 / 500 :: 14016 / 15539 - CLASS_LOSS : 0.11339
237 / 500 :: 14656 / 15539 - CLASS_LOSS : 0.12832
237 / 500 :: 15296 / 15539 - CLASS_LOSS : 0.22773
238 / 500 :: 384 / 15539 - CLASS_LOSS : 0.18267
238 / 500 :: 1024 / 15539 - CLASS_LOSS : 0.17021
238 / 500 :: 1664 / 15539 - CLASS_LOSS : 0.15435
238 / 500 :: 2304 / 15539 - CLASS_LOSS : 0.31738
238 / 500 :: 2944 / 15539 - CLASS_LOSS : 0.21893
238 / 500 :: 3584 / 15539 - CLASS_LOSS : 0.32376
238 / 500 :: 4224 / 15539 - CLASS_LOSS : 0.15747
238 / 500 :: 4864 / 15539 - CLASS_LOSS : 0.1482
238 / 500 :: 5504 / 15539 - CLASS_LOSS : 0.17351
238 / 500 :: 6144 / 15539 - CLASS_LOSS : 0.1373
238 / 500 :: 6784 / 15539 - CLASS_LOSS : 0.14961
238 / 500 :: 7424 / 15539 - CLASS_LOSS : 0.16533
238 / 500 :: 8064 / 15539 - CLASS_LOSS : 0.0912
238 / 500 :: 8704 / 15539 - CLASS_LOSS : 0.08647
238 / 500 :: 9344 / 15539 - CLASS_LOSS : 0.19716
238 / 500 :: 9984 / 15539 - CLASS_LOSS : 0.14804
238 / 500 :: 10624 / 15539 - CLASS_LOSS : 0.145
238 / 500 :: 11264 / 15539 - CLASS_LOSS : 0.13688
238 / 500 :: 11904 / 15539 - CLASS_LOSS : 0.20362
238 / 500 :: 12544 / 15539 - CLASS_LOSS : 0.10762
238 / 500 :: 13184 / 15539 - CLASS_LOSS : 0.10401
238 / 500 :: 13824 / 15539 - CLASS_LOSS : 0.14501
238 / 500 :: 14464 / 15539 - CLASS_LOSS : 0.19711
238 / 500 :: 15104 / 15539 - CLASS_LOSS : 0.17162
239 / 500 :: 192 / 15539 - CLASS_LOSS : 0.16996
239 / 500 :: 832 / 15539 - CLASS_LOSS : 0.13186
239 / 500 :: 1472 / 15539 - CLASS_LOSS : 0.08987
239 / 500 :: 2112 / 15539 - CLASS_LOSS : 0.19856
239 / 500 :: 2752 / 15539 - CLASS_LOSS : 0.09907
239 / 500 :: 3392 / 15539 - CLASS_LOSS : 0.12448
239 / 500 :: 4032 / 15539 - CLASS_LOSS : 0.16684
239 / 500 :: 4672 / 15539 - CLASS_LOSS : 0.18322
239 / 500 :: 5312 / 15539 - CLASS_LOSS : 0.16569
239 / 500 :: 5952 / 15539 - CLASS_LOSS : 0.19718
239 / 500 :: 6592 / 15539 - CLASS_LOSS : 0.20579
239 / 500 :: 7232 / 15539 - CLASS_LOSS : 0.15591
239 / 500 :: 7872 / 15539 - CLASS_LOSS : 0.29546
239 / 500 :: 8512 / 15539 - CLASS_LOSS : 0.17872
239 / 500 :: 9152 / 15539 - CLASS_LOSS : 0.14468
239 / 500 :: 9792 / 15539 - CLASS_LOSS : 0.21706
239 / 500 :: 10432 / 15539 - CLASS_LOSS : 0.16156
239 / 500 :: 11072 / 15539 - CLASS_LOSS : 0.08495
239 / 500 :: 11712 / 15539 - CLASS_LOSS : 0.21611
239 / 500 :: 12352 / 15539 - CLASS_LOSS : 0.14611
239 / 500 :: 12992 / 15539 - CLASS_LOSS : 0.10295
239 / 500 :: 13632 / 15539 - CLASS_LOSS : 0.2093
239 / 500 :: 14272 / 15539 - CLASS_LOSS : 0.14879
239 / 500 :: 14912 / 15539 - CLASS_LOSS : 0.12596
239 / 500 :: 15539 / 15539 - CLASS_LOSS : 0.17933
240 / 500 :: 640 / 15539 - CLASS_LOSS : 0.18906
240 / 500 :: 1280 / 15539 - CLASS_LOSS : 0.17262
240 / 500 :: 1920 / 15539 - CLASS_LOSS : 0.15439
240 / 500 :: 2560 / 15539 - CLASS_LOSS : 0.11269
240 / 500 :: 3200 / 15539 - CLASS_LOSS : 0.15471
240 / 500 :: 3840 / 15539 - CLASS_LOSS : 0.19718
240 / 500 :: 4480 / 15539 - CLASS_LOSS : 0.25473
240 / 500 :: 5120 / 15539 - CLASS_LOSS : 0.11521
240 / 500 :: 5760 / 15539 - CLASS_LOSS : 0.22019
240 / 500 :: 6400 / 15539 - CLASS_LOSS : 0.19715
240 / 500 :: 7040 / 15539 - CLASS_LOSS : 0.20601
240 / 500 :: 7680 / 15539 - CLASS_LOSS : 0.10694
240 / 500 :: 8320 / 15539 - CLASS_LOSS : 0.13894
240 / 500 :: 8960 / 15539 - CLASS_LOSS : 0.10392
240 / 500 :: 9600 / 15539 - CLASS_LOSS : 0.15286
240 / 500 :: 10240 / 15539 - CLASS_LOSS : 0.183
240 / 500 :: 10880 / 15539 - CLASS_LOSS : 0.10539
240 / 500 :: 11520 / 15539 - CLASS_LOSS : 0.16196
240 / 500 :: 12160 / 15539 - CLASS_LOSS : 0.11418
240 / 500 :: 12800 / 15539 - CLASS_LOSS : 0.13261
240 / 500 :: 13440 / 15539 - CLASS_LOSS : 0.19567
240 / 500 :: 14080 / 15539 - CLASS_LOSS : 0.13304
240 / 500 :: 14720 / 15539 - CLASS_LOSS : 0.08215
240 / 500 :: 15360 / 15539 - CLASS_LOSS : 0.15742
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.5576935452731836 0.46480897526653364 0.3968209022459618
PSPrecision@1,3,5: 0.4032713941343475 0.43530612844667577 0.45674180263457903
testing....
Precision@1,3,5: 0.46468889472302444 0.3793646626411131 0.32071409818850094
PSPrecision@1,3,5: 0.2795596383133919 0.30575484767918315 0.3203028965580626
241 / 500 :: 448 / 15539 - CLASS_LOSS : 0.11868
241 / 500 :: 1088 / 15539 - CLASS_LOSS : 0.16853
241 / 500 :: 1728 / 15539 - CLASS_LOSS : 0.12165
241 / 500 :: 2368 / 15539 - CLASS_LOSS : 0.16036
241 / 500 :: 3008 / 15539 - CLASS_LOSS : 0.21766
241 / 500 :: 3648 / 15539 - CLASS_LOSS : 0.1825
241 / 500 :: 4288 / 15539 - CLASS_LOSS : 0.19947
241 / 500 :: 4928 / 15539 - CLASS_LOSS : 0.17882
241 / 500 :: 5568 / 15539 - CLASS_LOSS : 0.31234
241 / 500 :: 6208 / 15539 - CLASS_LOSS : 0.16087
241 / 500 :: 6848 / 15539 - CLASS_LOSS : 0.14753
241 / 500 :: 7488 / 15539 - CLASS_LOSS : 0.17535
241 / 500 :: 8128 / 15539 - CLASS_LOSS : 0.19645
241 / 500 :: 8768 / 15539 - CLASS_LOSS : 0.18438
241 / 500 :: 9408 / 15539 - CLASS_LOSS : 0.15458
241 / 500 :: 10048 / 15539 - CLASS_LOSS : 0.11212
241 / 500 :: 10688 / 15539 - CLASS_LOSS : 0.2886
241 / 500 :: 11328 / 15539 - CLASS_LOSS : 0.25627
241 / 500 :: 11968 / 15539 - CLASS_LOSS : 0.21329
241 / 500 :: 12608 / 15539 - CLASS_LOSS : 0.17547
241 / 500 :: 13248 / 15539 - CLASS_LOSS : 0.19319
241 / 500 :: 13888 / 15539 - CLASS_LOSS : 0.18934
241 / 500 :: 14528 / 15539 - CLASS_LOSS : 0.15313
241 / 500 :: 15168 / 15539 - CLASS_LOSS : 0.15363
242 / 500 :: 256 / 15539 - CLASS_LOSS : 0.15361
242 / 500 :: 896 / 15539 - CLASS_LOSS : 0.17506
242 / 500 :: 1536 / 15539 - CLASS_LOSS : 0.23152
242 / 500 :: 2176 / 15539 - CLASS_LOSS : 0.26194
242 / 500 :: 2816 / 15539 - CLASS_LOSS : 0.10394
242 / 500 :: 3456 / 15539 - CLASS_LOSS : 0.17998
242 / 500 :: 4096 / 15539 - CLASS_LOSS : 0.15861
242 / 500 :: 4736 / 15539 - CLASS_LOSS : 0.14203
242 / 500 :: 5376 / 15539 - CLASS_LOSS : 0.09861
242 / 500 :: 6016 / 15539 - CLASS_LOSS : 0.10794
242 / 500 :: 6656 / 15539 - CLASS_LOSS : 0.17025
242 / 500 :: 7296 / 15539 - CLASS_LOSS : 0.17637
242 / 500 :: 7936 / 15539 - CLASS_LOSS : 0.0671
242 / 500 :: 8576 / 15539 - CLASS_LOSS : 0.26662
242 / 500 :: 9216 / 15539 - CLASS_LOSS : 0.17146
242 / 500 :: 9856 / 15539 - CLASS_LOSS : 0.30368
242 / 500 :: 10496 / 15539 - CLASS_LOSS : 0.14066
242 / 500 :: 11136 / 15539 - CLASS_LOSS : 0.19397
242 / 500 :: 11776 / 15539 - CLASS_LOSS : 0.14956
242 / 500 :: 12416 / 15539 - CLASS_LOSS : 0.14112
242 / 500 :: 13056 / 15539 - CLASS_LOSS : 0.15982
242 / 500 :: 13696 / 15539 - CLASS_LOSS : 0.21169
242 / 500 :: 14336 / 15539 - CLASS_LOSS : 0.17424
242 / 500 :: 14976 / 15539 - CLASS_LOSS : 0.18974
243 / 500 :: 64 / 15539 - CLASS_LOSS : 0.16355
243 / 500 :: 704 / 15539 - CLASS_LOSS : 0.1854
243 / 500 :: 1344 / 15539 - CLASS_LOSS : 0.10325
243 / 500 :: 1984 / 15539 - CLASS_LOSS : 0.25381
243 / 500 :: 2624 / 15539 - CLASS_LOSS : 0.19363
243 / 500 :: 3264 / 15539 - CLASS_LOSS : 0.12683
243 / 500 :: 3904 / 15539 - CLASS_LOSS : 0.15485
243 / 500 :: 4544 / 15539 - CLASS_LOSS : 0.18388
243 / 500 :: 5184 / 15539 - CLASS_LOSS : 0.10934
243 / 500 :: 5824 / 15539 - CLASS_LOSS : 0.20126
243 / 500 :: 6464 / 15539 - CLASS_LOSS : 0.20233
243 / 500 :: 7104 / 15539 - CLASS_LOSS : 0.15456
243 / 500 :: 7744 / 15539 - CLASS_LOSS : 0.12872
243 / 500 :: 8384 / 15539 - CLASS_LOSS : 0.19378
243 / 500 :: 9024 / 15539 - CLASS_LOSS : 0.17631
243 / 500 :: 9664 / 15539 - CLASS_LOSS : 0.1773
243 / 500 :: 10304 / 15539 - CLASS_LOSS : 0.16223
243 / 500 :: 10944 / 15539 - CLASS_LOSS : 0.14065
243 / 500 :: 11584 / 15539 - CLASS_LOSS : 0.10317
243 / 500 :: 12224 / 15539 - CLASS_LOSS : 0.16158
243 / 500 :: 12864 / 15539 - CLASS_LOSS : 0.20067
243 / 500 :: 13504 / 15539 - CLASS_LOSS : 0.21045
243 / 500 :: 14144 / 15539 - CLASS_LOSS : 0.28107
243 / 500 :: 14784 / 15539 - CLASS_LOSS : 0.2079
243 / 500 :: 15424 / 15539 - CLASS_LOSS : 0.18504
244 / 500 :: 512 / 15539 - CLASS_LOSS : 0.22923
244 / 500 :: 1152 / 15539 - CLASS_LOSS : 0.2522
244 / 500 :: 1792 / 15539 - CLASS_LOSS : 0.22135
244 / 500 :: 2432 / 15539 - CLASS_LOSS : 0.15816
244 / 500 :: 3072 / 15539 - CLASS_LOSS : 0.22995
244 / 500 :: 3712 / 15539 - CLASS_LOSS : 0.1523
244 / 500 :: 4352 / 15539 - CLASS_LOSS : 0.11394
244 / 500 :: 4992 / 15539 - CLASS_LOSS : 0.15677
244 / 500 :: 5632 / 15539 - CLASS_LOSS : 0.1488
244 / 500 :: 6272 / 15539 - CLASS_LOSS : 0.15617
244 / 500 :: 6912 / 15539 - CLASS_LOSS : 0.15107
244 / 500 :: 7552 / 15539 - CLASS_LOSS : 0.14908
244 / 500 :: 8192 / 15539 - CLASS_LOSS : 0.15199
244 / 500 :: 8832 / 15539 - CLASS_LOSS : 0.14026
244 / 500 :: 9472 / 15539 - CLASS_LOSS : 0.11084
244 / 500 :: 10112 / 15539 - CLASS_LOSS : 0.15571
244 / 500 :: 10752 / 15539 - CLASS_LOSS : 0.16471
244 / 500 :: 11392 / 15539 - CLASS_LOSS : 0.12793
244 / 500 :: 12032 / 15539 - CLASS_LOSS : 0.09566
244 / 500 :: 12672 / 15539 - CLASS_LOSS : 0.19946
244 / 500 :: 13312 / 15539 - CLASS_LOSS : 0.21912
244 / 500 :: 13952 / 15539 - CLASS_LOSS : 0.16717
244 / 500 :: 14592 / 15539 - CLASS_LOSS : 0.17806
244 / 500 :: 15232 / 15539 - CLASS_LOSS : 0.13795
245 / 500 :: 320 / 15539 - CLASS_LOSS : 0.15079
245 / 500 :: 960 / 15539 - CLASS_LOSS : 0.1757
245 / 500 :: 1600 / 15539 - CLASS_LOSS : 0.2005
245 / 500 :: 2240 / 15539 - CLASS_LOSS : 0.13106
245 / 500 :: 2880 / 15539 - CLASS_LOSS : 0.15831
245 / 500 :: 3520 / 15539 - CLASS_LOSS : 0.19107
245 / 500 :: 4160 / 15539 - CLASS_LOSS : 0.11867
245 / 500 :: 4800 / 15539 - CLASS_LOSS : 0.09892
245 / 500 :: 5440 / 15539 - CLASS_LOSS : 0.16807
245 / 500 :: 6080 / 15539 - CLASS_LOSS : 0.182
245 / 500 :: 6720 / 15539 - CLASS_LOSS : 0.17771
245 / 500 :: 7360 / 15539 - CLASS_LOSS : 0.19249
245 / 500 :: 8000 / 15539 - CLASS_LOSS : 0.10792
245 / 500 :: 8640 / 15539 - CLASS_LOSS : 0.18916
245 / 500 :: 9280 / 15539 - CLASS_LOSS : 0.19617
245 / 500 :: 9920 / 15539 - CLASS_LOSS : 0.10103
245 / 500 :: 10560 / 15539 - CLASS_LOSS : 0.11933
245 / 500 :: 11200 / 15539 - CLASS_LOSS : 0.15595
245 / 500 :: 11840 / 15539 - CLASS_LOSS : 0.12168
245 / 500 :: 12480 / 15539 - CLASS_LOSS : 0.13901
245 / 500 :: 13120 / 15539 - CLASS_LOSS : 0.12847
245 / 500 :: 13760 / 15539 - CLASS_LOSS : 0.17821
245 / 500 :: 14400 / 15539 - CLASS_LOSS : 0.17395
245 / 500 :: 15040 / 15539 - CLASS_LOSS : 0.28225
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.574232576098848 0.4758135444151275 0.4045691485938606
PSPrecision@1,3,5: 0.4110722796090306 0.4438532904772302 0.4633663839520337
testing....
Precision@1,3,5: 0.48017852454712523 0.39074122691870133 0.32465213966920453
PSPrecision@1,3,5: 0.2885153273188033 0.31340131734830334 0.3237020192114504
246 / 500 :: 128 / 15539 - CLASS_LOSS : 0.20738
246 / 500 :: 768 / 15539 - CLASS_LOSS : 0.18471
246 / 500 :: 1408 / 15539 - CLASS_LOSS : 0.17216
246 / 500 :: 2048 / 15539 - CLASS_LOSS : 0.14347
246 / 500 :: 2688 / 15539 - CLASS_LOSS : 0.12075
246 / 500 :: 3328 / 15539 - CLASS_LOSS : 0.1469
246 / 500 :: 3968 / 15539 - CLASS_LOSS : 0.15356
246 / 500 :: 4608 / 15539 - CLASS_LOSS : 0.19622
246 / 500 :: 5248 / 15539 - CLASS_LOSS : 0.15582
246 / 500 :: 5888 / 15539 - CLASS_LOSS : 0.2305
246 / 500 :: 6528 / 15539 - CLASS_LOSS : 0.19076
246 / 500 :: 7168 / 15539 - CLASS_LOSS : 0.12219
246 / 500 :: 7808 / 15539 - CLASS_LOSS : 0.23431
246 / 500 :: 8448 / 15539 - CLASS_LOSS : 0.12728
246 / 500 :: 9088 / 15539 - CLASS_LOSS : 0.1311
246 / 500 :: 9728 / 15539 - CLASS_LOSS : 0.13151
246 / 500 :: 10368 / 15539 - CLASS_LOSS : 0.21463
246 / 500 :: 11008 / 15539 - CLASS_LOSS : 0.19337
246 / 500 :: 11648 / 15539 - CLASS_LOSS : 0.1261
246 / 500 :: 12288 / 15539 - CLASS_LOSS : 0.17539
246 / 500 :: 12928 / 15539 - CLASS_LOSS : 0.16954
246 / 500 :: 13568 / 15539 - CLASS_LOSS : 0.20571
246 / 500 :: 14208 / 15539 - CLASS_LOSS : 0.15147
246 / 500 :: 14848 / 15539 - CLASS_LOSS : 0.072
246 / 500 :: 15488 / 15539 - CLASS_LOSS : 0.14056
247 / 500 :: 576 / 15539 - CLASS_LOSS : 0.1472
247 / 500 :: 1216 / 15539 - CLASS_LOSS : 0.11822
247 / 500 :: 1856 / 15539 - CLASS_LOSS : 0.13092
247 / 500 :: 2496 / 15539 - CLASS_LOSS : 0.23254
247 / 500 :: 3136 / 15539 - CLASS_LOSS : 0.16629
247 / 500 :: 3776 / 15539 - CLASS_LOSS : 0.20393
247 / 500 :: 4416 / 15539 - CLASS_LOSS : 0.17848
247 / 500 :: 5056 / 15539 - CLASS_LOSS : 0.17865
247 / 500 :: 5696 / 15539 - CLASS_LOSS : 0.20563
247 / 500 :: 6336 / 15539 - CLASS_LOSS : 0.12126
247 / 500 :: 6976 / 15539 - CLASS_LOSS : 0.26746
247 / 500 :: 7616 / 15539 - CLASS_LOSS : 0.16801
247 / 500 :: 8256 / 15539 - CLASS_LOSS : 0.12263
247 / 500 :: 8896 / 15539 - CLASS_LOSS : 0.10591
247 / 500 :: 9536 / 15539 - CLASS_LOSS : 0.10709
247 / 500 :: 10176 / 15539 - CLASS_LOSS : 0.20361
247 / 500 :: 10816 / 15539 - CLASS_LOSS : 0.10526
247 / 500 :: 11456 / 15539 - CLASS_LOSS : 0.18042
247 / 500 :: 12096 / 15539 - CLASS_LOSS : 0.08027
247 / 500 :: 12736 / 15539 - CLASS_LOSS : 0.14027
247 / 500 :: 13376 / 15539 - CLASS_LOSS : 0.15538
247 / 500 :: 14016 / 15539 - CLASS_LOSS : 0.15165
247 / 500 :: 14656 / 15539 - CLASS_LOSS : 0.2223
247 / 500 :: 15296 / 15539 - CLASS_LOSS : 0.16191
248 / 500 :: 384 / 15539 - CLASS_LOSS : 0.15415
248 / 500 :: 1024 / 15539 - CLASS_LOSS : 0.13284
248 / 500 :: 1664 / 15539 - CLASS_LOSS : 0.18788
248 / 500 :: 2304 / 15539 - CLASS_LOSS : 0.16495
248 / 500 :: 2944 / 15539 - CLASS_LOSS : 0.23344
248 / 500 :: 3584 / 15539 - CLASS_LOSS : 0.13433
248 / 500 :: 4224 / 15539 - CLASS_LOSS : 0.19789
248 / 500 :: 4864 / 15539 - CLASS_LOSS : 0.15688
248 / 500 :: 5504 / 15539 - CLASS_LOSS : 0.12602
248 / 500 :: 6144 / 15539 - CLASS_LOSS : 0.13356
248 / 500 :: 6784 / 15539 - CLASS_LOSS : 0.12546
248 / 500 :: 7424 / 15539 - CLASS_LOSS : 0.11337
248 / 500 :: 8064 / 15539 - CLASS_LOSS : 0.13796
248 / 500 :: 8704 / 15539 - CLASS_LOSS : 0.14574
248 / 500 :: 9344 / 15539 - CLASS_LOSS : 0.20596
248 / 500 :: 9984 / 15539 - CLASS_LOSS : 0.14765
248 / 500 :: 10624 / 15539 - CLASS_LOSS : 0.13324
248 / 500 :: 11264 / 15539 - CLASS_LOSS : 0.21634
248 / 500 :: 11904 / 15539 - CLASS_LOSS : 0.2085
248 / 500 :: 12544 / 15539 - CLASS_LOSS : 0.19776
248 / 500 :: 13184 / 15539 - CLASS_LOSS : 0.2517
248 / 500 :: 13824 / 15539 - CLASS_LOSS : 0.12879
248 / 500 :: 14464 / 15539 - CLASS_LOSS : 0.1616
248 / 500 :: 15104 / 15539 - CLASS_LOSS : 0.17229
249 / 500 :: 192 / 15539 - CLASS_LOSS : 0.0882
249 / 500 :: 832 / 15539 - CLASS_LOSS : 0.15741
249 / 500 :: 1472 / 15539 - CLASS_LOSS : 0.19862
249 / 500 :: 2112 / 15539 - CLASS_LOSS : 0.18373
249 / 500 :: 2752 / 15539 - CLASS_LOSS : 0.12496
249 / 500 :: 3392 / 15539 - CLASS_LOSS : 0.10962
249 / 500 :: 4032 / 15539 - CLASS_LOSS : 0.23497
249 / 500 :: 4672 / 15539 - CLASS_LOSS : 0.23773
249 / 500 :: 5312 / 15539 - CLASS_LOSS : 0.20444
249 / 500 :: 5952 / 15539 - CLASS_LOSS : 0.19364
249 / 500 :: 6592 / 15539 - CLASS_LOSS : 0.16007
249 / 500 :: 7232 / 15539 - CLASS_LOSS : 0.22033
249 / 500 :: 7872 / 15539 - CLASS_LOSS : 0.24752
249 / 500 :: 8512 / 15539 - CLASS_LOSS : 0.20465
249 / 500 :: 9152 / 15539 - CLASS_LOSS : 0.20403
249 / 500 :: 9792 / 15539 - CLASS_LOSS : 0.16036
249 / 500 :: 10432 / 15539 - CLASS_LOSS : 0.15412
249 / 500 :: 11072 / 15539 - CLASS_LOSS : 0.09073
249 / 500 :: 11712 / 15539 - CLASS_LOSS : 0.14887
249 / 500 :: 12352 / 15539 - CLASS_LOSS : 0.10852
249 / 500 :: 12992 / 15539 - CLASS_LOSS : 0.12801
249 / 500 :: 13632 / 15539 - CLASS_LOSS : 0.147
249 / 500 :: 14272 / 15539 - CLASS_LOSS : 0.12973
249 / 500 :: 14912 / 15539 - CLASS_LOSS : 0.13726
249 / 500 :: 15539 / 15539 - CLASS_LOSS : 0.2795
250 / 500 :: 640 / 15539 - CLASS_LOSS : 0.14109
250 / 500 :: 1280 / 15539 - CLASS_LOSS : 0.19594
250 / 500 :: 1920 / 15539 - CLASS_LOSS : 0.18385
250 / 500 :: 2560 / 15539 - CLASS_LOSS : 0.10125
250 / 500 :: 3200 / 15539 - CLASS_LOSS : 0.17074
250 / 500 :: 3840 / 15539 - CLASS_LOSS : 0.11776
250 / 500 :: 4480 / 15539 - CLASS_LOSS : 0.21859
250 / 500 :: 5120 / 15539 - CLASS_LOSS : 0.12246
250 / 500 :: 5760 / 15539 - CLASS_LOSS : 0.118
250 / 500 :: 6400 / 15539 - CLASS_LOSS : 0.15468
250 / 500 :: 7040 / 15539 - CLASS_LOSS : 0.16029
250 / 500 :: 7680 / 15539 - CLASS_LOSS : 0.16025
250 / 500 :: 8320 / 15539 - CLASS_LOSS : 0.16497
250 / 500 :: 8960 / 15539 - CLASS_LOSS : 0.15458
250 / 500 :: 9600 / 15539 - CLASS_LOSS : 0.26773
250 / 500 :: 10240 / 15539 - CLASS_LOSS : 0.11228
250 / 500 :: 10880 / 15539 - CLASS_LOSS : 0.10339
250 / 500 :: 11520 / 15539 - CLASS_LOSS : 0.21882
250 / 500 :: 12160 / 15539 - CLASS_LOSS : 0.1159
250 / 500 :: 12800 / 15539 - CLASS_LOSS : 0.10942
250 / 500 :: 13440 / 15539 - CLASS_LOSS : 0.18499
250 / 500 :: 14080 / 15539 - CLASS_LOSS : 0.14447
250 / 500 :: 14720 / 15539 - CLASS_LOSS : 0.19741
250 / 500 :: 15360 / 15539 - CLASS_LOSS : 0.10039
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.5626488191003282 0.4744192032949353 0.40728489606795804
PSPrecision@1,3,5: 0.4042983081694591 0.44473543338471117 0.4679581393858559
testing....
Precision@1,3,5: 0.47335258598057234 0.3851404568128118 0.32381202415332105
PSPrecision@1,3,5: 0.28308662796436823 0.3099577351687955 0.32357476312331407
251 / 500 :: 448 / 15539 - CLASS_LOSS : 0.16744
251 / 500 :: 1088 / 15539 - CLASS_LOSS : 0.19567
251 / 500 :: 1728 / 15539 - CLASS_LOSS : 0.11366
251 / 500 :: 2368 / 15539 - CLASS_LOSS : 0.19436
251 / 500 :: 3008 / 15539 - CLASS_LOSS : 0.26728
251 / 500 :: 3648 / 15539 - CLASS_LOSS : 0.19643
251 / 500 :: 4288 / 15539 - CLASS_LOSS : 0.15419
251 / 500 :: 4928 / 15539 - CLASS_LOSS : 0.17325
251 / 500 :: 5568 / 15539 - CLASS_LOSS : 0.10851
251 / 500 :: 6208 / 15539 - CLASS_LOSS : 0.12028
251 / 500 :: 6848 / 15539 - CLASS_LOSS : 0.11128
251 / 500 :: 7488 / 15539 - CLASS_LOSS : 0.13368
251 / 500 :: 8128 / 15539 - CLASS_LOSS : 0.09352
251 / 500 :: 8768 / 15539 - CLASS_LOSS : 0.19418
251 / 500 :: 9408 / 15539 - CLASS_LOSS : 0.16841
251 / 500 :: 10048 / 15539 - CLASS_LOSS : 0.09972
251 / 500 :: 10688 / 15539 - CLASS_LOSS : 0.12488
251 / 500 :: 11328 / 15539 - CLASS_LOSS : 0.10342
251 / 500 :: 11968 / 15539 - CLASS_LOSS : 0.13263
251 / 500 :: 12608 / 15539 - CLASS_LOSS : 0.20964
251 / 500 :: 13248 / 15539 - CLASS_LOSS : 0.20908
251 / 500 :: 13888 / 15539 - CLASS_LOSS : 0.11339
251 / 500 :: 14528 / 15539 - CLASS_LOSS : 0.15712
251 / 500 :: 15168 / 15539 - CLASS_LOSS : 0.17312
252 / 500 :: 256 / 15539 - CLASS_LOSS : 0.20372
252 / 500 :: 896 / 15539 - CLASS_LOSS : 0.13518
252 / 500 :: 1536 / 15539 - CLASS_LOSS : 0.18819
252 / 500 :: 2176 / 15539 - CLASS_LOSS : 0.16902
252 / 500 :: 2816 / 15539 - CLASS_LOSS : 0.19666
252 / 500 :: 3456 / 15539 - CLASS_LOSS : 0.20064
252 / 500 :: 4096 / 15539 - CLASS_LOSS : 0.07411
252 / 500 :: 4736 / 15539 - CLASS_LOSS : 0.21961
252 / 500 :: 5376 / 15539 - CLASS_LOSS : 0.21262
252 / 500 :: 6016 / 15539 - CLASS_LOSS : 0.13295
252 / 500 :: 6656 / 15539 - CLASS_LOSS : 0.29991
252 / 500 :: 7296 / 15539 - CLASS_LOSS : 0.13646
252 / 500 :: 7936 / 15539 - CLASS_LOSS : 0.18967
252 / 500 :: 8576 / 15539 - CLASS_LOSS : 0.1613
252 / 500 :: 9216 / 15539 - CLASS_LOSS : 0.16722
252 / 500 :: 9856 / 15539 - CLASS_LOSS : 0.1461
252 / 500 :: 10496 / 15539 - CLASS_LOSS : 0.12902
252 / 500 :: 11136 / 15539 - CLASS_LOSS : 0.18482
252 / 500 :: 11776 / 15539 - CLASS_LOSS : 0.10756
252 / 500 :: 12416 / 15539 - CLASS_LOSS : 0.12068
252 / 500 :: 13056 / 15539 - CLASS_LOSS : 0.1208
252 / 500 :: 13696 / 15539 - CLASS_LOSS : 0.16055
252 / 500 :: 14336 / 15539 - CLASS_LOSS : 0.15286
252 / 500 :: 14976 / 15539 - CLASS_LOSS : 0.21146
253 / 500 :: 64 / 15539 - CLASS_LOSS : 0.10731
253 / 500 :: 704 / 15539 - CLASS_LOSS : 0.20677
253 / 500 :: 1344 / 15539 - CLASS_LOSS : 0.18895
253 / 500 :: 1984 / 15539 - CLASS_LOSS : 0.15839
253 / 500 :: 2624 / 15539 - CLASS_LOSS : 0.18369
253 / 500 :: 3264 / 15539 - CLASS_LOSS : 0.16895
253 / 500 :: 3904 / 15539 - CLASS_LOSS : 0.08404
253 / 500 :: 4544 / 15539 - CLASS_LOSS : 0.13846
253 / 500 :: 5184 / 15539 - CLASS_LOSS : 0.21446
253 / 500 :: 5824 / 15539 - CLASS_LOSS : 0.15399
253 / 500 :: 6464 / 15539 - CLASS_LOSS : 0.14006
253 / 500 :: 7104 / 15539 - CLASS_LOSS : 0.2699
253 / 500 :: 7744 / 15539 - CLASS_LOSS : 0.11941
253 / 500 :: 8384 / 15539 - CLASS_LOSS : 0.10801
253 / 500 :: 9024 / 15539 - CLASS_LOSS : 0.23888
253 / 500 :: 9664 / 15539 - CLASS_LOSS : 0.24954
253 / 500 :: 10304 / 15539 - CLASS_LOSS : 0.14639
253 / 500 :: 10944 / 15539 - CLASS_LOSS : 0.17891
253 / 500 :: 11584 / 15539 - CLASS_LOSS : 0.11904
253 / 500 :: 12224 / 15539 - CLASS_LOSS : 0.21356
253 / 500 :: 12864 / 15539 - CLASS_LOSS : 0.15914
253 / 500 :: 13504 / 15539 - CLASS_LOSS : 0.15144
253 / 500 :: 14144 / 15539 - CLASS_LOSS : 0.14686
253 / 500 :: 14784 / 15539 - CLASS_LOSS : 0.14902
253 / 500 :: 15424 / 15539 - CLASS_LOSS : 0.18702
254 / 500 :: 512 / 15539 - CLASS_LOSS : 0.15438
254 / 500 :: 1152 / 15539 - CLASS_LOSS : 0.2373
254 / 500 :: 1792 / 15539 - CLASS_LOSS : 0.14207
254 / 500 :: 2432 / 15539 - CLASS_LOSS : 0.17351
254 / 500 :: 3072 / 15539 - CLASS_LOSS : 0.1747
254 / 500 :: 3712 / 15539 - CLASS_LOSS : 0.16998
254 / 500 :: 4352 / 15539 - CLASS_LOSS : 0.13702
254 / 500 :: 4992 / 15539 - CLASS_LOSS : 0.10654
254 / 500 :: 5632 / 15539 - CLASS_LOSS : 0.16164
254 / 500 :: 6272 / 15539 - CLASS_LOSS : 0.13164
254 / 500 :: 6912 / 15539 - CLASS_LOSS : 0.17871
254 / 500 :: 7552 / 15539 - CLASS_LOSS : 0.17998
254 / 500 :: 8192 / 15539 - CLASS_LOSS : 0.13262
254 / 500 :: 8832 / 15539 - CLASS_LOSS : 0.30978
254 / 500 :: 9472 / 15539 - CLASS_LOSS : 0.15545
254 / 500 :: 10112 / 15539 - CLASS_LOSS : 0.17378
254 / 500 :: 10752 / 15539 - CLASS_LOSS : 0.19863
254 / 500 :: 11392 / 15539 - CLASS_LOSS : 0.16684
254 / 500 :: 12032 / 15539 - CLASS_LOSS : 0.13377
254 / 500 :: 12672 / 15539 - CLASS_LOSS : 0.12527
254 / 500 :: 13312 / 15539 - CLASS_LOSS : 0.21468
254 / 500 :: 13952 / 15539 - CLASS_LOSS : 0.18626
254 / 500 :: 14592 / 15539 - CLASS_LOSS : 0.12444
254 / 500 :: 15232 / 15539 - CLASS_LOSS : 0.16243
255 / 500 :: 320 / 15539 - CLASS_LOSS : 0.13741
255 / 500 :: 960 / 15539 - CLASS_LOSS : 0.22717
255 / 500 :: 1600 / 15539 - CLASS_LOSS : 0.12244
255 / 500 :: 2240 / 15539 - CLASS_LOSS : 0.13464
255 / 500 :: 2880 / 15539 - CLASS_LOSS : 0.18833
255 / 500 :: 3520 / 15539 - CLASS_LOSS : 0.14235
255 / 500 :: 4160 / 15539 - CLASS_LOSS : 0.13047
255 / 500 :: 4800 / 15539 - CLASS_LOSS : 0.183
255 / 500 :: 5440 / 15539 - CLASS_LOSS : 0.13457
255 / 500 :: 6080 / 15539 - CLASS_LOSS : 0.19754
255 / 500 :: 6720 / 15539 - CLASS_LOSS : 0.15693
255 / 500 :: 7360 / 15539 - CLASS_LOSS : 0.11122
255 / 500 :: 8000 / 15539 - CLASS_LOSS : 0.21286
255 / 500 :: 8640 / 15539 - CLASS_LOSS : 0.17672
255 / 500 :: 9280 / 15539 - CLASS_LOSS : 0.21615
255 / 500 :: 9920 / 15539 - CLASS_LOSS : 0.0756
255 / 500 :: 10560 / 15539 - CLASS_LOSS : 0.13684
255 / 500 :: 11200 / 15539 - CLASS_LOSS : 0.13063
255 / 500 :: 11840 / 15539 - CLASS_LOSS : 0.18775
255 / 500 :: 12480 / 15539 - CLASS_LOSS : 0.12543
255 / 500 :: 13120 / 15539 - CLASS_LOSS : 0.33568
255 / 500 :: 13760 / 15539 - CLASS_LOSS : 0.18511
255 / 500 :: 14400 / 15539 - CLASS_LOSS : 0.235
255 / 500 :: 15040 / 15539 - CLASS_LOSS : 0.08556
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.579059141514898 0.4843082995473754 0.41301242036167063
PSPrecision@1,3,5: 0.41270197141504283 0.45077361923396825 0.472088533964631
testing....
Precision@1,3,5: 0.49041743239695457 0.3931040518071235 0.32748752953531113
PSPrecision@1,3,5: 0.2904120879059378 0.31411442333496314 0.32649084196798817
256 / 500 :: 128 / 15539 - CLASS_LOSS : 0.14607
256 / 500 :: 768 / 15539 - CLASS_LOSS : 0.26059
256 / 500 :: 1408 / 15539 - CLASS_LOSS : 0.13997
256 / 500 :: 2048 / 15539 - CLASS_LOSS : 0.19257
256 / 500 :: 2688 / 15539 - CLASS_LOSS : 0.07674
256 / 500 :: 3328 / 15539 - CLASS_LOSS : 0.13069
256 / 500 :: 3968 / 15539 - CLASS_LOSS : 0.19052
256 / 500 :: 4608 / 15539 - CLASS_LOSS : 0.19017
256 / 500 :: 5248 / 15539 - CLASS_LOSS : 0.21976
256 / 500 :: 5888 / 15539 - CLASS_LOSS : 0.21516
256 / 500 :: 6528 / 15539 - CLASS_LOSS : 0.18141
256 / 500 :: 7168 / 15539 - CLASS_LOSS : 0.14547
256 / 500 :: 7808 / 15539 - CLASS_LOSS : 0.14334
256 / 500 :: 8448 / 15539 - CLASS_LOSS : 0.1838
256 / 500 :: 9088 / 15539 - CLASS_LOSS : 0.14312
256 / 500 :: 9728 / 15539 - CLASS_LOSS : 0.16947
256 / 500 :: 10368 / 15539 - CLASS_LOSS : 0.15605
256 / 500 :: 11008 / 15539 - CLASS_LOSS : 0.14837
256 / 500 :: 11648 / 15539 - CLASS_LOSS : 0.12421
256 / 500 :: 12288 / 15539 - CLASS_LOSS : 0.11298
256 / 500 :: 12928 / 15539 - CLASS_LOSS : 0.12457
256 / 500 :: 13568 / 15539 - CLASS_LOSS : 0.21602
256 / 500 :: 14208 / 15539 - CLASS_LOSS : 0.12016
256 / 500 :: 14848 / 15539 - CLASS_LOSS : 0.09502
256 / 500 :: 15488 / 15539 - CLASS_LOSS : 0.22567
257 / 500 :: 576 / 15539 - CLASS_LOSS : 0.17439
257 / 500 :: 1216 / 15539 - CLASS_LOSS : 0.12155
257 / 500 :: 1856 / 15539 - CLASS_LOSS : 0.2173
257 / 500 :: 2496 / 15539 - CLASS_LOSS : 0.17899
257 / 500 :: 3136 / 15539 - CLASS_LOSS : 0.3119
257 / 500 :: 3776 / 15539 - CLASS_LOSS : 0.18677
257 / 500 :: 4416 / 15539 - CLASS_LOSS : 0.17649
257 / 500 :: 5056 / 15539 - CLASS_LOSS : 0.13447
257 / 500 :: 5696 / 15539 - CLASS_LOSS : 0.09592
257 / 500 :: 6336 / 15539 - CLASS_LOSS : 0.20593
257 / 500 :: 6976 / 15539 - CLASS_LOSS : 0.18286
257 / 500 :: 7616 / 15539 - CLASS_LOSS : 0.15452
257 / 500 :: 8256 / 15539 - CLASS_LOSS : 0.19007
257 / 500 :: 8896 / 15539 - CLASS_LOSS : 0.21568
257 / 500 :: 9536 / 15539 - CLASS_LOSS : 0.20306
257 / 500 :: 10176 / 15539 - CLASS_LOSS : 0.22189
257 / 500 :: 10816 / 15539 - CLASS_LOSS : 0.15182
257 / 500 :: 11456 / 15539 - CLASS_LOSS : 0.21089
257 / 500 :: 12096 / 15539 - CLASS_LOSS : 0.21832
257 / 500 :: 12736 / 15539 - CLASS_LOSS : 0.13943
257 / 500 :: 13376 / 15539 - CLASS_LOSS : 0.18339
257 / 500 :: 14016 / 15539 - CLASS_LOSS : 0.13919
257 / 500 :: 14656 / 15539 - CLASS_LOSS : 0.11124
257 / 500 :: 15296 / 15539 - CLASS_LOSS : 0.19856
258 / 500 :: 384 / 15539 - CLASS_LOSS : 0.1976
258 / 500 :: 1024 / 15539 - CLASS_LOSS : 0.13189
258 / 500 :: 1664 / 15539 - CLASS_LOSS : 0.17991
258 / 500 :: 2304 / 15539 - CLASS_LOSS : 0.13321
258 / 500 :: 2944 / 15539 - CLASS_LOSS : 0.15742
258 / 500 :: 3584 / 15539 - CLASS_LOSS : 0.17762
258 / 500 :: 4224 / 15539 - CLASS_LOSS : 0.14009
258 / 500 :: 4864 / 15539 - CLASS_LOSS : 0.27109
258 / 500 :: 5504 / 15539 - CLASS_LOSS : 0.26267
258 / 500 :: 6144 / 15539 - CLASS_LOSS : 0.20193
258 / 500 :: 6784 / 15539 - CLASS_LOSS : 0.20169
258 / 500 :: 7424 / 15539 - CLASS_LOSS : 0.07988
258 / 500 :: 8064 / 15539 - CLASS_LOSS : 0.2425
258 / 500 :: 8704 / 15539 - CLASS_LOSS : 0.10102
258 / 500 :: 9344 / 15539 - CLASS_LOSS : 0.12278
258 / 500 :: 9984 / 15539 - CLASS_LOSS : 0.19391
258 / 500 :: 10624 / 15539 - CLASS_LOSS : 0.15653
258 / 500 :: 11264 / 15539 - CLASS_LOSS : 0.15903
258 / 500 :: 11904 / 15539 - CLASS_LOSS : 0.19912
258 / 500 :: 12544 / 15539 - CLASS_LOSS : 0.14693
258 / 500 :: 13184 / 15539 - CLASS_LOSS : 0.12942
258 / 500 :: 13824 / 15539 - CLASS_LOSS : 0.05988
258 / 500 :: 14464 / 15539 - CLASS_LOSS : 0.28462
258 / 500 :: 15104 / 15539 - CLASS_LOSS : 0.1864
259 / 500 :: 192 / 15539 - CLASS_LOSS : 0.23778
259 / 500 :: 832 / 15539 - CLASS_LOSS : 0.20594
259 / 500 :: 1472 / 15539 - CLASS_LOSS : 0.07425
259 / 500 :: 2112 / 15539 - CLASS_LOSS : 0.12073
259 / 500 :: 2752 / 15539 - CLASS_LOSS : 0.15886
259 / 500 :: 3392 / 15539 - CLASS_LOSS : 0.20404
259 / 500 :: 4032 / 15539 - CLASS_LOSS : 0.14169
259 / 500 :: 4672 / 15539 - CLASS_LOSS : 0.21364
259 / 500 :: 5312 / 15539 - CLASS_LOSS : 0.21226
259 / 500 :: 5952 / 15539 - CLASS_LOSS : 0.16609
259 / 500 :: 6592 / 15539 - CLASS_LOSS : 0.25238
259 / 500 :: 7232 / 15539 - CLASS_LOSS : 0.25674
259 / 500 :: 7872 / 15539 - CLASS_LOSS : 0.2034
259 / 500 :: 8512 / 15539 - CLASS_LOSS : 0.2186
259 / 500 :: 9152 / 15539 - CLASS_LOSS : 0.17369
259 / 500 :: 9792 / 15539 - CLASS_LOSS : 0.08952
259 / 500 :: 10432 / 15539 - CLASS_LOSS : 0.13089
259 / 500 :: 11072 / 15539 - CLASS_LOSS : 0.16669
259 / 500 :: 11712 / 15539 - CLASS_LOSS : 0.19982
259 / 500 :: 12352 / 15539 - CLASS_LOSS : 0.15121
259 / 500 :: 12992 / 15539 - CLASS_LOSS : 0.16871
259 / 500 :: 13632 / 15539 - CLASS_LOSS : 0.16662
259 / 500 :: 14272 / 15539 - CLASS_LOSS : 0.18562
259 / 500 :: 14912 / 15539 - CLASS_LOSS : 0.14035
259 / 500 :: 15539 / 15539 - CLASS_LOSS : 0.68956
260 / 500 :: 640 / 15539 - CLASS_LOSS : 0.16496
260 / 500 :: 1280 / 15539 - CLASS_LOSS : 0.16684
260 / 500 :: 1920 / 15539 - CLASS_LOSS : 0.11239
260 / 500 :: 2560 / 15539 - CLASS_LOSS : 0.24162
260 / 500 :: 3200 / 15539 - CLASS_LOSS : 0.17985
260 / 500 :: 3840 / 15539 - CLASS_LOSS : 0.17195
260 / 500 :: 4480 / 15539 - CLASS_LOSS : 0.15172
260 / 500 :: 5120 / 15539 - CLASS_LOSS : 0.18426
260 / 500 :: 5760 / 15539 - CLASS_LOSS : 0.18653
260 / 500 :: 6400 / 15539 - CLASS_LOSS : 0.15401
260 / 500 :: 7040 / 15539 - CLASS_LOSS : 0.09024
260 / 500 :: 7680 / 15539 - CLASS_LOSS : 0.27076
260 / 500 :: 8320 / 15539 - CLASS_LOSS : 0.17047
260 / 500 :: 8960 / 15539 - CLASS_LOSS : 0.20631
260 / 500 :: 9600 / 15539 - CLASS_LOSS : 0.13902
260 / 500 :: 10240 / 15539 - CLASS_LOSS : 0.15881
260 / 500 :: 10880 / 15539 - CLASS_LOSS : 0.1433
260 / 500 :: 11520 / 15539 - CLASS_LOSS : 0.26118
260 / 500 :: 12160 / 15539 - CLASS_LOSS : 0.21788
260 / 500 :: 12800 / 15539 - CLASS_LOSS : 0.14218
260 / 500 :: 13440 / 15539 - CLASS_LOSS : 0.12435
260 / 500 :: 14080 / 15539 - CLASS_LOSS : 0.16027
260 / 500 :: 14720 / 15539 - CLASS_LOSS : 0.12843
260 / 500 :: 15360 / 15539 - CLASS_LOSS : 0.14097
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.5730098461934487 0.48501619580839606 0.41369457494047235
PSPrecision@1,3,5: 0.4132531264701486 0.45217258106545105 0.4733116052602734
testing....
Precision@1,3,5: 0.47991598844841166 0.3920539074122692 0.32559726962457336
PSPrecision@1,3,5: 0.2868094214101613 0.3145550330691667 0.32570330672299014
261 / 500 :: 448 / 15539 - CLASS_LOSS : 0.11435
261 / 500 :: 1088 / 15539 - CLASS_LOSS : 0.20512
261 / 500 :: 1728 / 15539 - CLASS_LOSS : 0.20813
261 / 500 :: 2368 / 15539 - CLASS_LOSS : 0.16828
261 / 500 :: 3008 / 15539 - CLASS_LOSS : 0.14915
261 / 500 :: 3648 / 15539 - CLASS_LOSS : 0.25087
261 / 500 :: 4288 / 15539 - CLASS_LOSS : 0.14355
261 / 500 :: 4928 / 15539 - CLASS_LOSS : 0.1017
261 / 500 :: 5568 / 15539 - CLASS_LOSS : 0.14367
261 / 500 :: 6208 / 15539 - CLASS_LOSS : 0.29055
261 / 500 :: 6848 / 15539 - CLASS_LOSS : 0.21546
261 / 500 :: 7488 / 15539 - CLASS_LOSS : 0.11926
261 / 500 :: 8128 / 15539 - CLASS_LOSS : 0.16686
261 / 500 :: 8768 / 15539 - CLASS_LOSS : 0.14198
261 / 500 :: 9408 / 15539 - CLASS_LOSS : 0.22659
261 / 500 :: 10048 / 15539 - CLASS_LOSS : 0.15748
261 / 500 :: 10688 / 15539 - CLASS_LOSS : 0.14102
261 / 500 :: 11328 / 15539 - CLASS_LOSS : 0.14421
261 / 500 :: 11968 / 15539 - CLASS_LOSS : 0.20755
261 / 500 :: 12608 / 15539 - CLASS_LOSS : 0.17589
261 / 500 :: 13248 / 15539 - CLASS_LOSS : 0.15803
261 / 500 :: 13888 / 15539 - CLASS_LOSS : 0.25874
261 / 500 :: 14528 / 15539 - CLASS_LOSS : 0.17875
261 / 500 :: 15168 / 15539 - CLASS_LOSS : 0.13512
262 / 500 :: 256 / 15539 - CLASS_LOSS : 0.12822
262 / 500 :: 896 / 15539 - CLASS_LOSS : 0.14893
262 / 500 :: 1536 / 15539 - CLASS_LOSS : 0.19492
262 / 500 :: 2176 / 15539 - CLASS_LOSS : 0.15118
262 / 500 :: 2816 / 15539 - CLASS_LOSS : 0.1407
262 / 500 :: 3456 / 15539 - CLASS_LOSS : 0.14344
262 / 500 :: 4096 / 15539 - CLASS_LOSS : 0.18374
262 / 500 :: 4736 / 15539 - CLASS_LOSS : 0.16973
262 / 500 :: 5376 / 15539 - CLASS_LOSS : 0.13949
262 / 500 :: 6016 / 15539 - CLASS_LOSS : 0.20412
262 / 500 :: 6656 / 15539 - CLASS_LOSS : 0.23741
262 / 500 :: 7296 / 15539 - CLASS_LOSS : 0.1639
262 / 500 :: 7936 / 15539 - CLASS_LOSS : 0.20753
262 / 500 :: 8576 / 15539 - CLASS_LOSS : 0.16355
262 / 500 :: 9216 / 15539 - CLASS_LOSS : 0.20108
262 / 500 :: 9856 / 15539 - CLASS_LOSS : 0.11723
262 / 500 :: 10496 / 15539 - CLASS_LOSS : 0.1527
262 / 500 :: 11136 / 15539 - CLASS_LOSS : 0.19632
262 / 500 :: 11776 / 15539 - CLASS_LOSS : 0.14059
262 / 500 :: 12416 / 15539 - CLASS_LOSS : 0.07508
262 / 500 :: 13056 / 15539 - CLASS_LOSS : 0.18031
262 / 500 :: 13696 / 15539 - CLASS_LOSS : 0.11592
262 / 500 :: 14336 / 15539 - CLASS_LOSS : 0.12492
262 / 500 :: 14976 / 15539 - CLASS_LOSS : 0.12242
263 / 500 :: 64 / 15539 - CLASS_LOSS : 0.16715
263 / 500 :: 704 / 15539 - CLASS_LOSS : 0.16534
263 / 500 :: 1344 / 15539 - CLASS_LOSS : 0.14795
263 / 500 :: 1984 / 15539 - CLASS_LOSS : 0.20234
263 / 500 :: 2624 / 15539 - CLASS_LOSS : 0.10443
263 / 500 :: 3264 / 15539 - CLASS_LOSS : 0.10272
263 / 500 :: 3904 / 15539 - CLASS_LOSS : 0.14534
263 / 500 :: 4544 / 15539 - CLASS_LOSS : 0.15126
263 / 500 :: 5184 / 15539 - CLASS_LOSS : 0.16102
263 / 500 :: 5824 / 15539 - CLASS_LOSS : 0.16999
263 / 500 :: 6464 / 15539 - CLASS_LOSS : 0.12087
263 / 500 :: 7104 / 15539 - CLASS_LOSS : 0.12478
263 / 500 :: 7744 / 15539 - CLASS_LOSS : 0.17984
263 / 500 :: 8384 / 15539 - CLASS_LOSS : 0.13765
263 / 500 :: 9024 / 15539 - CLASS_LOSS : 0.17424
263 / 500 :: 9664 / 15539 - CLASS_LOSS : 0.13538
263 / 500 :: 10304 / 15539 - CLASS_LOSS : 0.0822
263 / 500 :: 10944 / 15539 - CLASS_LOSS : 0.14697
263 / 500 :: 11584 / 15539 - CLASS_LOSS : 0.18636
263 / 500 :: 12224 / 15539 - CLASS_LOSS : 0.15158
263 / 500 :: 12864 / 15539 - CLASS_LOSS : 0.14314
263 / 500 :: 13504 / 15539 - CLASS_LOSS : 0.24455
263 / 500 :: 14144 / 15539 - CLASS_LOSS : 0.22273
263 / 500 :: 14784 / 15539 - CLASS_LOSS : 0.15515
263 / 500 :: 15424 / 15539 - CLASS_LOSS : 0.20963
264 / 500 :: 512 / 15539 - CLASS_LOSS : 0.09617
264 / 500 :: 1152 / 15539 - CLASS_LOSS : 0.18758
264 / 500 :: 1792 / 15539 - CLASS_LOSS : 0.15288
264 / 500 :: 2432 / 15539 - CLASS_LOSS : 0.194
264 / 500 :: 3072 / 15539 - CLASS_LOSS : 0.15644
264 / 500 :: 3712 / 15539 - CLASS_LOSS : 0.22071
264 / 500 :: 4352 / 15539 - CLASS_LOSS : 0.17056
264 / 500 :: 4992 / 15539 - CLASS_LOSS : 0.28472
264 / 500 :: 5632 / 15539 - CLASS_LOSS : 0.18416
264 / 500 :: 6272 / 15539 - CLASS_LOSS : 0.10803
264 / 500 :: 6912 / 15539 - CLASS_LOSS : 0.11959
264 / 500 :: 7552 / 15539 - CLASS_LOSS : 0.09822
264 / 500 :: 8192 / 15539 - CLASS_LOSS : 0.15478
264 / 500 :: 8832 / 15539 - CLASS_LOSS : 0.21483
264 / 500 :: 9472 / 15539 - CLASS_LOSS : 0.13858
264 / 500 :: 10112 / 15539 - CLASS_LOSS : 0.22045
264 / 500 :: 10752 / 15539 - CLASS_LOSS : 0.21151
264 / 500 :: 11392 / 15539 - CLASS_LOSS : 0.19816
264 / 500 :: 12032 / 15539 - CLASS_LOSS : 0.23117
264 / 500 :: 12672 / 15539 - CLASS_LOSS : 0.17082
264 / 500 :: 13312 / 15539 - CLASS_LOSS : 0.25112
264 / 500 :: 13952 / 15539 - CLASS_LOSS : 0.1865
264 / 500 :: 14592 / 15539 - CLASS_LOSS : 0.18976
264 / 500 :: 15232 / 15539 - CLASS_LOSS : 0.17731
265 / 500 :: 320 / 15539 - CLASS_LOSS : 0.12462
265 / 500 :: 960 / 15539 - CLASS_LOSS : 0.19131
265 / 500 :: 1600 / 15539 - CLASS_LOSS : 0.08418
265 / 500 :: 2240 / 15539 - CLASS_LOSS : 0.11257
265 / 500 :: 2880 / 15539 - CLASS_LOSS : 0.14186
265 / 500 :: 3520 / 15539 - CLASS_LOSS : 0.1294
265 / 500 :: 4160 / 15539 - CLASS_LOSS : 0.28357
265 / 500 :: 4800 / 15539 - CLASS_LOSS : 0.13482
265 / 500 :: 5440 / 15539 - CLASS_LOSS : 0.19806
265 / 500 :: 6080 / 15539 - CLASS_LOSS : 0.1623
265 / 500 :: 6720 / 15539 - CLASS_LOSS : 0.15965
265 / 500 :: 7360 / 15539 - CLASS_LOSS : 0.24356
265 / 500 :: 8000 / 15539 - CLASS_LOSS : 0.15754
265 / 500 :: 8640 / 15539 - CLASS_LOSS : 0.20407
265 / 500 :: 9280 / 15539 - CLASS_LOSS : 0.15265
265 / 500 :: 9920 / 15539 - CLASS_LOSS : 0.13836
265 / 500 :: 10560 / 15539 - CLASS_LOSS : 0.22845
265 / 500 :: 11200 / 15539 - CLASS_LOSS : 0.27487
265 / 500 :: 11840 / 15539 - CLASS_LOSS : 0.24999
265 / 500 :: 12480 / 15539 - CLASS_LOSS : 0.15784
265 / 500 :: 13120 / 15539 - CLASS_LOSS : 0.13087
265 / 500 :: 13760 / 15539 - CLASS_LOSS : 0.22857
265 / 500 :: 14400 / 15539 - CLASS_LOSS : 0.08589
265 / 500 :: 15040 / 15539 - CLASS_LOSS : 0.15232
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.5626488191003282 0.4789239976832486 0.41070853980307614
PSPrecision@1,3,5: 0.4041287413412648 0.44638034800431725 0.46912627081317554
testing....
Precision@1,3,5: 0.4778156996587031 0.3827776319243896 0.32186925702284064
PSPrecision@1,3,5: 0.28368441691276414 0.30733740713245766 0.3225716147198233
266 / 500 :: 128 / 15539 - CLASS_LOSS : 0.12158
266 / 500 :: 768 / 15539 - CLASS_LOSS : 0.20839
266 / 500 :: 1408 / 15539 - CLASS_LOSS : 0.15056
266 / 500 :: 2048 / 15539 - CLASS_LOSS : 0.2035
266 / 500 :: 2688 / 15539 - CLASS_LOSS : 0.09538
266 / 500 :: 3328 / 15539 - CLASS_LOSS : 0.17092
266 / 500 :: 3968 / 15539 - CLASS_LOSS : 0.1309
266 / 500 :: 4608 / 15539 - CLASS_LOSS : 0.19924
266 / 500 :: 5248 / 15539 - CLASS_LOSS : 0.14927
266 / 500 :: 5888 / 15539 - CLASS_LOSS : 0.10357
266 / 500 :: 6528 / 15539 - CLASS_LOSS : 0.18722
266 / 500 :: 7168 / 15539 - CLASS_LOSS : 0.15341
266 / 500 :: 7808 / 15539 - CLASS_LOSS : 0.15582
266 / 500 :: 8448 / 15539 - CLASS_LOSS : 0.18502
266 / 500 :: 9088 / 15539 - CLASS_LOSS : 0.09197
266 / 500 :: 9728 / 15539 - CLASS_LOSS : 0.12226
266 / 500 :: 10368 / 15539 - CLASS_LOSS : 0.14624
266 / 500 :: 11008 / 15539 - CLASS_LOSS : 0.14186
266 / 500 :: 11648 / 15539 - CLASS_LOSS : 0.10566
266 / 500 :: 12288 / 15539 - CLASS_LOSS : 0.21299
266 / 500 :: 12928 / 15539 - CLASS_LOSS : 0.25846
266 / 500 :: 13568 / 15539 - CLASS_LOSS : 0.14375
266 / 500 :: 14208 / 15539 - CLASS_LOSS : 0.14264
266 / 500 :: 14848 / 15539 - CLASS_LOSS : 0.21592
266 / 500 :: 15488 / 15539 - CLASS_LOSS : 0.19201
267 / 500 :: 576 / 15539 - CLASS_LOSS : 0.20361
267 / 500 :: 1216 / 15539 - CLASS_LOSS : 0.16338
267 / 500 :: 1856 / 15539 - CLASS_LOSS : 0.16825
267 / 500 :: 2496 / 15539 - CLASS_LOSS : 0.24977
267 / 500 :: 3136 / 15539 - CLASS_LOSS : 0.20035
267 / 500 :: 3776 / 15539 - CLASS_LOSS : 0.14162
267 / 500 :: 4416 / 15539 - CLASS_LOSS : 0.18019
267 / 500 :: 5056 / 15539 - CLASS_LOSS : 0.13276
267 / 500 :: 5696 / 15539 - CLASS_LOSS : 0.25731
267 / 500 :: 6336 / 15539 - CLASS_LOSS : 0.11559
267 / 500 :: 6976 / 15539 - CLASS_LOSS : 0.17536
267 / 500 :: 7616 / 15539 - CLASS_LOSS : 0.06815
267 / 500 :: 8256 / 15539 - CLASS_LOSS : 0.1015
267 / 500 :: 8896 / 15539 - CLASS_LOSS : 0.18362
267 / 500 :: 9536 / 15539 - CLASS_LOSS : 0.18826
267 / 500 :: 10176 / 15539 - CLASS_LOSS : 0.14785
267 / 500 :: 10816 / 15539 - CLASS_LOSS : 0.1227
267 / 500 :: 11456 / 15539 - CLASS_LOSS : 0.16577
267 / 500 :: 12096 / 15539 - CLASS_LOSS : 0.21429
267 / 500 :: 12736 / 15539 - CLASS_LOSS : 0.16336
267 / 500 :: 13376 / 15539 - CLASS_LOSS : 0.091
267 / 500 :: 14016 / 15539 - CLASS_LOSS : 0.20988
267 / 500 :: 14656 / 15539 - CLASS_LOSS : 0.16863
267 / 500 :: 15296 / 15539 - CLASS_LOSS : 0.1223
268 / 500 :: 384 / 15539 - CLASS_LOSS : 0.19639
268 / 500 :: 1024 / 15539 - CLASS_LOSS : 0.13691
268 / 500 :: 1664 / 15539 - CLASS_LOSS : 0.17215
268 / 500 :: 2304 / 15539 - CLASS_LOSS : 0.17751
268 / 500 :: 2944 / 15539 - CLASS_LOSS : 0.25872
268 / 500 :: 3584 / 15539 - CLASS_LOSS : 0.17656
268 / 500 :: 4224 / 15539 - CLASS_LOSS : 0.1702
268 / 500 :: 4864 / 15539 - CLASS_LOSS : 0.1707
268 / 500 :: 5504 / 15539 - CLASS_LOSS : 0.15219
268 / 500 :: 6144 / 15539 - CLASS_LOSS : 0.12842
268 / 500 :: 6784 / 15539 - CLASS_LOSS : 0.13825
268 / 500 :: 7424 / 15539 - CLASS_LOSS : 0.18757
268 / 500 :: 8064 / 15539 - CLASS_LOSS : 0.23474
268 / 500 :: 8704 / 15539 - CLASS_LOSS : 0.21362
268 / 500 :: 9344 / 15539 - CLASS_LOSS : 0.13935
268 / 500 :: 9984 / 15539 - CLASS_LOSS : 0.22144
268 / 500 :: 10624 / 15539 - CLASS_LOSS : 0.11906
268 / 500 :: 11264 / 15539 - CLASS_LOSS : 0.192
268 / 500 :: 11904 / 15539 - CLASS_LOSS : 0.11823
268 / 500 :: 12544 / 15539 - CLASS_LOSS : 0.28915
268 / 500 :: 13184 / 15539 - CLASS_LOSS : 0.19595
268 / 500 :: 13824 / 15539 - CLASS_LOSS : 0.08281
268 / 500 :: 14464 / 15539 - CLASS_LOSS : 0.17623
268 / 500 :: 15104 / 15539 - CLASS_LOSS : 0.13806
269 / 500 :: 192 / 15539 - CLASS_LOSS : 0.17333
269 / 500 :: 832 / 15539 - CLASS_LOSS : 0.33428
269 / 500 :: 1472 / 15539 - CLASS_LOSS : 0.17768
269 / 500 :: 2112 / 15539 - CLASS_LOSS : 0.24162
269 / 500 :: 2752 / 15539 - CLASS_LOSS : 0.16148
269 / 500 :: 3392 / 15539 - CLASS_LOSS : 0.13549
269 / 500 :: 4032 / 15539 - CLASS_LOSS : 0.10244
269 / 500 :: 4672 / 15539 - CLASS_LOSS : 0.18245
269 / 500 :: 5312 / 15539 - CLASS_LOSS : 0.24132
269 / 500 :: 5952 / 15539 - CLASS_LOSS : 0.2263
269 / 500 :: 6592 / 15539 - CLASS_LOSS : 0.15476
269 / 500 :: 7232 / 15539 - CLASS_LOSS : 0.14704
269 / 500 :: 7872 / 15539 - CLASS_LOSS : 0.08854
269 / 500 :: 8512 / 15539 - CLASS_LOSS : 0.13601
269 / 500 :: 9152 / 15539 - CLASS_LOSS : 0.14972
269 / 500 :: 9792 / 15539 - CLASS_LOSS : 0.22304
269 / 500 :: 10432 / 15539 - CLASS_LOSS : 0.14978
269 / 500 :: 11072 / 15539 - CLASS_LOSS : 0.29724
269 / 500 :: 11712 / 15539 - CLASS_LOSS : 0.19631
269 / 500 :: 12352 / 15539 - CLASS_LOSS : 0.14681
269 / 500 :: 12992 / 15539 - CLASS_LOSS : 0.1401
269 / 500 :: 13632 / 15539 - CLASS_LOSS : 0.11266
269 / 500 :: 14272 / 15539 - CLASS_LOSS : 0.13679
269 / 500 :: 14912 / 15539 - CLASS_LOSS : 0.13631
269 / 500 :: 15539 / 15539 - CLASS_LOSS : 0.13949
270 / 500 :: 640 / 15539 - CLASS_LOSS : 0.22713
270 / 500 :: 1280 / 15539 - CLASS_LOSS : 0.12257
270 / 500 :: 1920 / 15539 - CLASS_LOSS : 0.20662
270 / 500 :: 2560 / 15539 - CLASS_LOSS : 0.22052
270 / 500 :: 3200 / 15539 - CLASS_LOSS : 0.15095
270 / 500 :: 3840 / 15539 - CLASS_LOSS : 0.11969
270 / 500 :: 4480 / 15539 - CLASS_LOSS : 0.21589
270 / 500 :: 5120 / 15539 - CLASS_LOSS : 0.20556
270 / 500 :: 5760 / 15539 - CLASS_LOSS : 0.22606
270 / 500 :: 6400 / 15539 - CLASS_LOSS : 0.13092
270 / 500 :: 7040 / 15539 - CLASS_LOSS : 0.26021
270 / 500 :: 7680 / 15539 - CLASS_LOSS : 0.14246
270 / 500 :: 8320 / 15539 - CLASS_LOSS : 0.06816
270 / 500 :: 8960 / 15539 - CLASS_LOSS : 0.10359
270 / 500 :: 9600 / 15539 - CLASS_LOSS : 0.22982
270 / 500 :: 10240 / 15539 - CLASS_LOSS : 0.16234
270 / 500 :: 10880 / 15539 - CLASS_LOSS : 0.10925
270 / 500 :: 11520 / 15539 - CLASS_LOSS : 0.17831
270 / 500 :: 12160 / 15539 - CLASS_LOSS : 0.1199
270 / 500 :: 12800 / 15539 - CLASS_LOSS : 0.23734
270 / 500 :: 13440 / 15539 - CLASS_LOSS : 0.11864
270 / 500 :: 14080 / 15539 - CLASS_LOSS : 0.18658
270 / 500 :: 14720 / 15539 - CLASS_LOSS : 0.20043
270 / 500 :: 15360 / 15539 - CLASS_LOSS : 0.27101
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.5643220284445588 0.48064010983117744 0.4111204067185791
PSPrecision@1,3,5: 0.40687840450692786 0.44914901744903113 0.47133923343657375
testing....
Precision@1,3,5: 0.4833289577316881 0.39039117878708324 0.32838015227093725
PSPrecision@1,3,5: 0.28685344228820425 0.31385502903488666 0.32803024300722095
271 / 500 :: 448 / 15539 - CLASS_LOSS : 0.23662
271 / 500 :: 1088 / 15539 - CLASS_LOSS : 0.17027
271 / 500 :: 1728 / 15539 - CLASS_LOSS : 0.16063
271 / 500 :: 2368 / 15539 - CLASS_LOSS : 0.18165
271 / 500 :: 3008 / 15539 - CLASS_LOSS : 0.15688
271 / 500 :: 3648 / 15539 - CLASS_LOSS : 0.19371
271 / 500 :: 4288 / 15539 - CLASS_LOSS : 0.18068
271 / 500 :: 4928 / 15539 - CLASS_LOSS : 0.2593
271 / 500 :: 5568 / 15539 - CLASS_LOSS : 0.12073
271 / 500 :: 6208 / 15539 - CLASS_LOSS : 0.14082
271 / 500 :: 6848 / 15539 - CLASS_LOSS : 0.15228
271 / 500 :: 7488 / 15539 - CLASS_LOSS : 0.16726
271 / 500 :: 8128 / 15539 - CLASS_LOSS : 0.1376
271 / 500 :: 8768 / 15539 - CLASS_LOSS : 0.14394
271 / 500 :: 9408 / 15539 - CLASS_LOSS : 0.23356
271 / 500 :: 10048 / 15539 - CLASS_LOSS : 0.19235
271 / 500 :: 10688 / 15539 - CLASS_LOSS : 0.12625
271 / 500 :: 11328 / 15539 - CLASS_LOSS : 0.19148
271 / 500 :: 11968 / 15539 - CLASS_LOSS : 0.19253
271 / 500 :: 12608 / 15539 - CLASS_LOSS : 0.12073
271 / 500 :: 13248 / 15539 - CLASS_LOSS : 0.17442
271 / 500 :: 13888 / 15539 - CLASS_LOSS : 0.15277
271 / 500 :: 14528 / 15539 - CLASS_LOSS : 0.16008
271 / 500 :: 15168 / 15539 - CLASS_LOSS : 0.15598
272 / 500 :: 256 / 15539 - CLASS_LOSS : 0.1011
272 / 500 :: 896 / 15539 - CLASS_LOSS : 0.12237
272 / 500 :: 1536 / 15539 - CLASS_LOSS : 0.12482
272 / 500 :: 2176 / 15539 - CLASS_LOSS : 0.14999
272 / 500 :: 2816 / 15539 - CLASS_LOSS : 0.17373
272 / 500 :: 3456 / 15539 - CLASS_LOSS : 0.18069
272 / 500 :: 4096 / 15539 - CLASS_LOSS : 0.25042
272 / 500 :: 4736 / 15539 - CLASS_LOSS : 0.17724
272 / 500 :: 5376 / 15539 - CLASS_LOSS : 0.16419
272 / 500 :: 6016 / 15539 - CLASS_LOSS : 0.14861
272 / 500 :: 6656 / 15539 - CLASS_LOSS : 0.23679
272 / 500 :: 7296 / 15539 - CLASS_LOSS : 0.15717
272 / 500 :: 7936 / 15539 - CLASS_LOSS : 0.18243
272 / 500 :: 8576 / 15539 - CLASS_LOSS : 0.12004
272 / 500 :: 9216 / 15539 - CLASS_LOSS : 0.17323
272 / 500 :: 9856 / 15539 - CLASS_LOSS : 0.2007
272 / 500 :: 10496 / 15539 - CLASS_LOSS : 0.10042
272 / 500 :: 11136 / 15539 - CLASS_LOSS : 0.1265
272 / 500 :: 11776 / 15539 - CLASS_LOSS : 0.28456
272 / 500 :: 12416 / 15539 - CLASS_LOSS : 0.19765
272 / 500 :: 13056 / 15539 - CLASS_LOSS : 0.11001
272 / 500 :: 13696 / 15539 - CLASS_LOSS : 0.2423
272 / 500 :: 14336 / 15539 - CLASS_LOSS : 0.16492
272 / 500 :: 14976 / 15539 - CLASS_LOSS : 0.17074
273 / 500 :: 64 / 15539 - CLASS_LOSS : 0.13218
273 / 500 :: 704 / 15539 - CLASS_LOSS : 0.1448
273 / 500 :: 1344 / 15539 - CLASS_LOSS : 0.16313
273 / 500 :: 1984 / 15539 - CLASS_LOSS : 0.13678
273 / 500 :: 2624 / 15539 - CLASS_LOSS : 0.17119
273 / 500 :: 3264 / 15539 - CLASS_LOSS : 0.13232
273 / 500 :: 3904 / 15539 - CLASS_LOSS : 0.18292
273 / 500 :: 4544 / 15539 - CLASS_LOSS : 0.30456
273 / 500 :: 5184 / 15539 - CLASS_LOSS : 0.17511
273 / 500 :: 5824 / 15539 - CLASS_LOSS : 0.11735
273 / 500 :: 6464 / 15539 - CLASS_LOSS : 0.14502
273 / 500 :: 7104 / 15539 - CLASS_LOSS : 0.10953
273 / 500 :: 7744 / 15539 - CLASS_LOSS : 0.21833
273 / 500 :: 8384 / 15539 - CLASS_LOSS : 0.16283
273 / 500 :: 9024 / 15539 - CLASS_LOSS : 0.19694
273 / 500 :: 9664 / 15539 - CLASS_LOSS : 0.19237
273 / 500 :: 10304 / 15539 - CLASS_LOSS : 0.1751
273 / 500 :: 10944 / 15539 - CLASS_LOSS : 0.14701
273 / 500 :: 11584 / 15539 - CLASS_LOSS : 0.12375
273 / 500 :: 12224 / 15539 - CLASS_LOSS : 0.14989
273 / 500 :: 12864 / 15539 - CLASS_LOSS : 0.18104
273 / 500 :: 13504 / 15539 - CLASS_LOSS : 0.11166
273 / 500 :: 14144 / 15539 - CLASS_LOSS : 0.17888
273 / 500 :: 14784 / 15539 - CLASS_LOSS : 0.14183
273 / 500 :: 15424 / 15539 - CLASS_LOSS : 0.16843
274 / 500 :: 512 / 15539 - CLASS_LOSS : 0.12584
274 / 500 :: 1152 / 15539 - CLASS_LOSS : 0.22495
274 / 500 :: 1792 / 15539 - CLASS_LOSS : 0.15123
274 / 500 :: 2432 / 15539 - CLASS_LOSS : 0.16559
274 / 500 :: 3072 / 15539 - CLASS_LOSS : 0.16841
274 / 500 :: 3712 / 15539 - CLASS_LOSS : 0.11219
274 / 500 :: 4352 / 15539 - CLASS_LOSS : 0.14758
274 / 500 :: 4992 / 15539 - CLASS_LOSS : 0.2463
274 / 500 :: 5632 / 15539 - CLASS_LOSS : 0.07424
274 / 500 :: 6272 / 15539 - CLASS_LOSS : 0.16166
274 / 500 :: 6912 / 15539 - CLASS_LOSS : 0.23179
274 / 500 :: 7552 / 15539 - CLASS_LOSS : 0.10802
274 / 500 :: 8192 / 15539 - CLASS_LOSS : 0.13605
274 / 500 :: 8832 / 15539 - CLASS_LOSS : 0.15
274 / 500 :: 9472 / 15539 - CLASS_LOSS : 0.1724
274 / 500 :: 10112 / 15539 - CLASS_LOSS : 0.14952
274 / 500 :: 10752 / 15539 - CLASS_LOSS : 0.15952
274 / 500 :: 11392 / 15539 - CLASS_LOSS : 0.1483
274 / 500 :: 12032 / 15539 - CLASS_LOSS : 0.13041
274 / 500 :: 12672 / 15539 - CLASS_LOSS : 0.13197
274 / 500 :: 13312 / 15539 - CLASS_LOSS : 0.21744
274 / 500 :: 13952 / 15539 - CLASS_LOSS : 0.15814
274 / 500 :: 14592 / 15539 - CLASS_LOSS : 0.20919
274 / 500 :: 15232 / 15539 - CLASS_LOSS : 0.22748
275 / 500 :: 320 / 15539 - CLASS_LOSS : 0.21679
275 / 500 :: 960 / 15539 - CLASS_LOSS : 0.15623
275 / 500 :: 1600 / 15539 - CLASS_LOSS : 0.2398
275 / 500 :: 2240 / 15539 - CLASS_LOSS : 0.14503
275 / 500 :: 2880 / 15539 - CLASS_LOSS : 0.15587
275 / 500 :: 3520 / 15539 - CLASS_LOSS : 0.15321
275 / 500 :: 4160 / 15539 - CLASS_LOSS : 0.0845
275 / 500 :: 4800 / 15539 - CLASS_LOSS : 0.18079
275 / 500 :: 5440 / 15539 - CLASS_LOSS : 0.1231
275 / 500 :: 6080 / 15539 - CLASS_LOSS : 0.15164
275 / 500 :: 6720 / 15539 - CLASS_LOSS : 0.16323
275 / 500 :: 7360 / 15539 - CLASS_LOSS : 0.13164
275 / 500 :: 8000 / 15539 - CLASS_LOSS : 0.16604
275 / 500 :: 8640 / 15539 - CLASS_LOSS : 0.23305
275 / 500 :: 9280 / 15539 - CLASS_LOSS : 0.15614
275 / 500 :: 9920 / 15539 - CLASS_LOSS : 0.14994
275 / 500 :: 10560 / 15539 - CLASS_LOSS : 0.15025
275 / 500 :: 11200 / 15539 - CLASS_LOSS : 0.05147
275 / 500 :: 11840 / 15539 - CLASS_LOSS : 0.15878
275 / 500 :: 12480 / 15539 - CLASS_LOSS : 0.11813
275 / 500 :: 13120 / 15539 - CLASS_LOSS : 0.14495
275 / 500 :: 13760 / 15539 - CLASS_LOSS : 0.1911
275 / 500 :: 14400 / 15539 - CLASS_LOSS : 0.2862
275 / 500 :: 15040 / 15539 - CLASS_LOSS : 0.10935
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.5717227620825021 0.4862389257137954 0.4163459682090225
PSPrecision@1,3,5: 0.4105200021444158 0.45116494284591085 0.4755346137117081
testing....
Precision@1,3,5: 0.4793909162509845 0.3867156734050932 0.33053294828038854
PSPrecision@1,3,5: 0.2860137181435801 0.3091495179124258 0.32868422685404447
276 / 500 :: 128 / 15539 - CLASS_LOSS : 0.15598
276 / 500 :: 768 / 15539 - CLASS_LOSS : 0.25561
276 / 500 :: 1408 / 15539 - CLASS_LOSS : 0.20222
276 / 500 :: 2048 / 15539 - CLASS_LOSS : 0.23021
276 / 500 :: 2688 / 15539 - CLASS_LOSS : 0.09544
276 / 500 :: 3328 / 15539 - CLASS_LOSS : 0.16159
276 / 500 :: 3968 / 15539 - CLASS_LOSS : 0.19543
276 / 500 :: 4608 / 15539 - CLASS_LOSS : 0.15306
276 / 500 :: 5248 / 15539 - CLASS_LOSS : 0.16843
276 / 500 :: 5888 / 15539 - CLASS_LOSS : 0.16304
276 / 500 :: 6528 / 15539 - CLASS_LOSS : 0.1022
276 / 500 :: 7168 / 15539 - CLASS_LOSS : 0.12055
276 / 500 :: 7808 / 15539 - CLASS_LOSS : 0.18086
276 / 500 :: 8448 / 15539 - CLASS_LOSS : 0.15666
276 / 500 :: 9088 / 15539 - CLASS_LOSS : 0.16939
276 / 500 :: 9728 / 15539 - CLASS_LOSS : 0.2051
276 / 500 :: 10368 / 15539 - CLASS_LOSS : 0.11119
276 / 500 :: 11008 / 15539 - CLASS_LOSS : 0.22838
276 / 500 :: 11648 / 15539 - CLASS_LOSS : 0.20602
276 / 500 :: 12288 / 15539 - CLASS_LOSS : 0.16754
276 / 500 :: 12928 / 15539 - CLASS_LOSS : 0.17367
276 / 500 :: 13568 / 15539 - CLASS_LOSS : 0.14023
276 / 500 :: 14208 / 15539 - CLASS_LOSS : 0.1593
276 / 500 :: 14848 / 15539 - CLASS_LOSS : 0.13219
276 / 500 :: 15488 / 15539 - CLASS_LOSS : 0.24399
277 / 500 :: 576 / 15539 - CLASS_LOSS : 0.12307
277 / 500 :: 1216 / 15539 - CLASS_LOSS : 0.22026
277 / 500 :: 1856 / 15539 - CLASS_LOSS : 0.20461
277 / 500 :: 2496 / 15539 - CLASS_LOSS : 0.16733
277 / 500 :: 3136 / 15539 - CLASS_LOSS : 0.22305
277 / 500 :: 3776 / 15539 - CLASS_LOSS : 0.0849
277 / 500 :: 4416 / 15539 - CLASS_LOSS : 0.16322
277 / 500 :: 5056 / 15539 - CLASS_LOSS : 0.20581
277 / 500 :: 5696 / 15539 - CLASS_LOSS : 0.20692
277 / 500 :: 6336 / 15539 - CLASS_LOSS : 0.27285
277 / 500 :: 6976 / 15539 - CLASS_LOSS : 0.22368
277 / 500 :: 7616 / 15539 - CLASS_LOSS : 0.13762
277 / 500 :: 8256 / 15539 - CLASS_LOSS : 0.10527
277 / 500 :: 8896 / 15539 - CLASS_LOSS : 0.15164
277 / 500 :: 9536 / 15539 - CLASS_LOSS : 0.12207
277 / 500 :: 10176 / 15539 - CLASS_LOSS : 0.31393
277 / 500 :: 10816 / 15539 - CLASS_LOSS : 0.14272
277 / 500 :: 11456 / 15539 - CLASS_LOSS : 0.08166
277 / 500 :: 12096 / 15539 - CLASS_LOSS : 0.11372
277 / 500 :: 12736 / 15539 - CLASS_LOSS : 0.12624
277 / 500 :: 13376 / 15539 - CLASS_LOSS : 0.24601
277 / 500 :: 14016 / 15539 - CLASS_LOSS : 0.13563
277 / 500 :: 14656 / 15539 - CLASS_LOSS : 0.1404
277 / 500 :: 15296 / 15539 - CLASS_LOSS : 0.14285
278 / 500 :: 384 / 15539 - CLASS_LOSS : 0.13214
278 / 500 :: 1024 / 15539 - CLASS_LOSS : 0.16483
278 / 500 :: 1664 / 15539 - CLASS_LOSS : 0.21649
278 / 500 :: 2304 / 15539 - CLASS_LOSS : 0.18045
278 / 500 :: 2944 / 15539 - CLASS_LOSS : 0.30599
278 / 500 :: 3584 / 15539 - CLASS_LOSS : 0.13063
278 / 500 :: 4224 / 15539 - CLASS_LOSS : 0.12002
278 / 500 :: 4864 / 15539 - CLASS_LOSS : 0.15459
278 / 500 :: 5504 / 15539 - CLASS_LOSS : 0.19274
278 / 500 :: 6144 / 15539 - CLASS_LOSS : 0.23809
278 / 500 :: 6784 / 15539 - CLASS_LOSS : 0.14042
278 / 500 :: 7424 / 15539 - CLASS_LOSS : 0.1949
278 / 500 :: 8064 / 15539 - CLASS_LOSS : 0.2122
278 / 500 :: 8704 / 15539 - CLASS_LOSS : 0.14651
278 / 500 :: 9344 / 15539 - CLASS_LOSS : 0.12127
278 / 500 :: 9984 / 15539 - CLASS_LOSS : 0.17064
278 / 500 :: 10624 / 15539 - CLASS_LOSS : 0.18462
278 / 500 :: 11264 / 15539 - CLASS_LOSS : 0.18056
278 / 500 :: 11904 / 15539 - CLASS_LOSS : 0.17135
278 / 500 :: 12544 / 15539 - CLASS_LOSS : 0.17727
278 / 500 :: 13184 / 15539 - CLASS_LOSS : 0.18585
278 / 500 :: 13824 / 15539 - CLASS_LOSS : 0.14425
278 / 500 :: 14464 / 15539 - CLASS_LOSS : 0.13317
278 / 500 :: 15104 / 15539 - CLASS_LOSS : 0.22867
279 / 500 :: 192 / 15539 - CLASS_LOSS : 0.24658
279 / 500 :: 832 / 15539 - CLASS_LOSS : 0.11687
279 / 500 :: 1472 / 15539 - CLASS_LOSS : 0.16359
279 / 500 :: 2112 / 15539 - CLASS_LOSS : 0.20181
279 / 500 :: 2752 / 15539 - CLASS_LOSS : 0.19025
279 / 500 :: 3392 / 15539 - CLASS_LOSS : 0.09599
279 / 500 :: 4032 / 15539 - CLASS_LOSS : 0.17583
279 / 500 :: 4672 / 15539 - CLASS_LOSS : 0.13491
279 / 500 :: 5312 / 15539 - CLASS_LOSS : 0.08556
279 / 500 :: 5952 / 15539 - CLASS_LOSS : 0.1668
279 / 500 :: 6592 / 15539 - CLASS_LOSS : 0.20102
279 / 500 :: 7232 / 15539 - CLASS_LOSS : 0.19798
279 / 500 :: 7872 / 15539 - CLASS_LOSS : 0.24587
279 / 500 :: 8512 / 15539 - CLASS_LOSS : 0.07076
279 / 500 :: 9152 / 15539 - CLASS_LOSS : 0.23867
279 / 500 :: 9792 / 15539 - CLASS_LOSS : 0.14589
279 / 500 :: 10432 / 15539 - CLASS_LOSS : 0.19607
279 / 500 :: 11072 / 15539 - CLASS_LOSS : 0.13846
279 / 500 :: 11712 / 15539 - CLASS_LOSS : 0.23654
279 / 500 :: 12352 / 15539 - CLASS_LOSS : 0.16258
279 / 500 :: 12992 / 15539 - CLASS_LOSS : 0.111
279 / 500 :: 13632 / 15539 - CLASS_LOSS : 0.16122
279 / 500 :: 14272 / 15539 - CLASS_LOSS : 0.23449
279 / 500 :: 14912 / 15539 - CLASS_LOSS : 0.13614
279 / 500 :: 15539 / 15539 - CLASS_LOSS : 0.21782
280 / 500 :: 640 / 15539 - CLASS_LOSS : 0.19565
280 / 500 :: 1280 / 15539 - CLASS_LOSS : 0.11378
280 / 500 :: 1920 / 15539 - CLASS_LOSS : 0.12693
280 / 500 :: 2560 / 15539 - CLASS_LOSS : 0.19058
280 / 500 :: 3200 / 15539 - CLASS_LOSS : 0.14833
280 / 500 :: 3840 / 15539 - CLASS_LOSS : 0.16979
280 / 500 :: 4480 / 15539 - CLASS_LOSS : 0.24991
280 / 500 :: 5120 / 15539 - CLASS_LOSS : 0.15737
280 / 500 :: 5760 / 15539 - CLASS_LOSS : 0.18072
280 / 500 :: 6400 / 15539 - CLASS_LOSS : 0.11614
280 / 500 :: 7040 / 15539 - CLASS_LOSS : 0.09671
280 / 500 :: 7680 / 15539 - CLASS_LOSS : 0.15599
280 / 500 :: 8320 / 15539 - CLASS_LOSS : 0.15582
280 / 500 :: 8960 / 15539 - CLASS_LOSS : 0.17092
280 / 500 :: 9600 / 15539 - CLASS_LOSS : 0.1931
280 / 500 :: 10240 / 15539 - CLASS_LOSS : 0.1815
280 / 500 :: 10880 / 15539 - CLASS_LOSS : 0.23949
280 / 500 :: 11520 / 15539 - CLASS_LOSS : 0.17315
280 / 500 :: 12160 / 15539 - CLASS_LOSS : 0.18602
280 / 500 :: 12800 / 15539 - CLASS_LOSS : 0.15014
280 / 500 :: 13440 / 15539 - CLASS_LOSS : 0.19571
280 / 500 :: 14080 / 15539 - CLASS_LOSS : 0.15522
280 / 500 :: 14720 / 15539 - CLASS_LOSS : 0.19832
280 / 500 :: 15360 / 15539 - CLASS_LOSS : 0.18037
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.5820837891756226 0.49443336122015574 0.41934487418752814
PSPrecision@1,3,5: 0.41533277882090197 0.45764197023098624 0.4770578876855165
testing....
Precision@1,3,5: 0.48569178262011026 0.39835477378139494 0.3317931215542137
PSPrecision@1,3,5: 0.2876719009563977 0.31721168524412185 0.32995665206123165
281 / 500 :: 448 / 15539 - CLASS_LOSS : 0.16312
281 / 500 :: 1088 / 15539 - CLASS_LOSS : 0.25706
281 / 500 :: 1728 / 15539 - CLASS_LOSS : 0.14183
281 / 500 :: 2368 / 15539 - CLASS_LOSS : 0.22859
281 / 500 :: 3008 / 15539 - CLASS_LOSS : 0.11402
281 / 500 :: 3648 / 15539 - CLASS_LOSS : 0.13933
281 / 500 :: 4288 / 15539 - CLASS_LOSS : 0.13709
281 / 500 :: 4928 / 15539 - CLASS_LOSS : 0.19187
281 / 500 :: 5568 / 15539 - CLASS_LOSS : 0.11292
281 / 500 :: 6208 / 15539 - CLASS_LOSS : 0.10228
281 / 500 :: 6848 / 15539 - CLASS_LOSS : 0.23105
281 / 500 :: 7488 / 15539 - CLASS_LOSS : 0.17082
281 / 500 :: 8128 / 15539 - CLASS_LOSS : 0.16809
281 / 500 :: 8768 / 15539 - CLASS_LOSS : 0.20673
281 / 500 :: 9408 / 15539 - CLASS_LOSS : 0.19777
281 / 500 :: 10048 / 15539 - CLASS_LOSS : 0.11862
281 / 500 :: 10688 / 15539 - CLASS_LOSS : 0.12399
281 / 500 :: 11328 / 15539 - CLASS_LOSS : 0.16717
281 / 500 :: 11968 / 15539 - CLASS_LOSS : 0.18317
281 / 500 :: 12608 / 15539 - CLASS_LOSS : 0.19842
281 / 500 :: 13248 / 15539 - CLASS_LOSS : 0.18908
281 / 500 :: 13888 / 15539 - CLASS_LOSS : 0.1554
281 / 500 :: 14528 / 15539 - CLASS_LOSS : 0.141
281 / 500 :: 15168 / 15539 - CLASS_LOSS : 0.18203
282 / 500 :: 256 / 15539 - CLASS_LOSS : 0.20164
282 / 500 :: 896 / 15539 - CLASS_LOSS : 0.11019
282 / 500 :: 1536 / 15539 - CLASS_LOSS : 0.09169
282 / 500 :: 2176 / 15539 - CLASS_LOSS : 0.1297
282 / 500 :: 2816 / 15539 - CLASS_LOSS : 0.12749
282 / 500 :: 3456 / 15539 - CLASS_LOSS : 0.16249
282 / 500 :: 4096 / 15539 - CLASS_LOSS : 0.17943
282 / 500 :: 4736 / 15539 - CLASS_LOSS : 0.17275
282 / 500 :: 5376 / 15539 - CLASS_LOSS : 0.19187
282 / 500 :: 6016 / 15539 - CLASS_LOSS : 0.18966
282 / 500 :: 6656 / 15539 - CLASS_LOSS : 0.15707
282 / 500 :: 7296 / 15539 - CLASS_LOSS : 0.18974
282 / 500 :: 7936 / 15539 - CLASS_LOSS : 0.25982
282 / 500 :: 8576 / 15539 - CLASS_LOSS : 0.11061
282 / 500 :: 9216 / 15539 - CLASS_LOSS : 0.11466
282 / 500 :: 9856 / 15539 - CLASS_LOSS : 0.26395
282 / 500 :: 10496 / 15539 - CLASS_LOSS : 0.17704
282 / 500 :: 11136 / 15539 - CLASS_LOSS : 0.09781
282 / 500 :: 11776 / 15539 - CLASS_LOSS : 0.2308
282 / 500 :: 12416 / 15539 - CLASS_LOSS : 0.18277
282 / 500 :: 13056 / 15539 - CLASS_LOSS : 0.12435
282 / 500 :: 13696 / 15539 - CLASS_LOSS : 0.15922
282 / 500 :: 14336 / 15539 - CLASS_LOSS : 0.20813
282 / 500 :: 14976 / 15539 - CLASS_LOSS : 0.22293
283 / 500 :: 64 / 15539 - CLASS_LOSS : 0.1758
283 / 500 :: 704 / 15539 - CLASS_LOSS : 0.08543
283 / 500 :: 1344 / 15539 - CLASS_LOSS : 0.0895
283 / 500 :: 1984 / 15539 - CLASS_LOSS : 0.1357
283 / 500 :: 2624 / 15539 - CLASS_LOSS : 0.18632
283 / 500 :: 3264 / 15539 - CLASS_LOSS : 0.1922
283 / 500 :: 3904 / 15539 - CLASS_LOSS : 0.18283
283 / 500 :: 4544 / 15539 - CLASS_LOSS : 0.13996
283 / 500 :: 5184 / 15539 - CLASS_LOSS : 0.1969
283 / 500 :: 5824 / 15539 - CLASS_LOSS : 0.14462
283 / 500 :: 6464 / 15539 - CLASS_LOSS : 0.16308
283 / 500 :: 7104 / 15539 - CLASS_LOSS : 0.17422
283 / 500 :: 7744 / 15539 - CLASS_LOSS : 0.14253
283 / 500 :: 8384 / 15539 - CLASS_LOSS : 0.10041
283 / 500 :: 9024 / 15539 - CLASS_LOSS : 0.15047
283 / 500 :: 9664 / 15539 - CLASS_LOSS : 0.21171
283 / 500 :: 10304 / 15539 - CLASS_LOSS : 0.10569
283 / 500 :: 10944 / 15539 - CLASS_LOSS : 0.22541
283 / 500 :: 11584 / 15539 - CLASS_LOSS : 0.12277
283 / 500 :: 12224 / 15539 - CLASS_LOSS : 0.13278
283 / 500 :: 12864 / 15539 - CLASS_LOSS : 0.22154
283 / 500 :: 13504 / 15539 - CLASS_LOSS : 0.18031
283 / 500 :: 14144 / 15539 - CLASS_LOSS : 0.20233
283 / 500 :: 14784 / 15539 - CLASS_LOSS : 0.19208
283 / 500 :: 15424 / 15539 - CLASS_LOSS : 0.25593
284 / 500 :: 512 / 15539 - CLASS_LOSS : 0.28645
284 / 500 :: 1152 / 15539 - CLASS_LOSS : 0.16338
284 / 500 :: 1792 / 15539 - CLASS_LOSS : 0.17835
284 / 500 :: 2432 / 15539 - CLASS_LOSS : 0.12607
284 / 500 :: 3072 / 15539 - CLASS_LOSS : 0.12872
284 / 500 :: 3712 / 15539 - CLASS_LOSS : 0.12315
284 / 500 :: 4352 / 15539 - CLASS_LOSS : 0.33608
284 / 500 :: 4992 / 15539 - CLASS_LOSS : 0.17226
284 / 500 :: 5632 / 15539 - CLASS_LOSS : 0.08969
284 / 500 :: 6272 / 15539 - CLASS_LOSS : 0.20449
284 / 500 :: 6912 / 15539 - CLASS_LOSS : 0.15444
284 / 500 :: 7552 / 15539 - CLASS_LOSS : 0.25939
284 / 500 :: 8192 / 15539 - CLASS_LOSS : 0.10603
284 / 500 :: 8832 / 15539 - CLASS_LOSS : 0.1489
284 / 500 :: 9472 / 15539 - CLASS_LOSS : 0.15421
284 / 500 :: 10112 / 15539 - CLASS_LOSS : 0.15585
284 / 500 :: 10752 / 15539 - CLASS_LOSS : 0.21063
284 / 500 :: 11392 / 15539 - CLASS_LOSS : 0.18407
284 / 500 :: 12032 / 15539 - CLASS_LOSS : 0.29396
284 / 500 :: 12672 / 15539 - CLASS_LOSS : 0.15549
284 / 500 :: 13312 / 15539 - CLASS_LOSS : 0.12366
284 / 500 :: 13952 / 15539 - CLASS_LOSS : 0.17942
284 / 500 :: 14592 / 15539 - CLASS_LOSS : 0.14882
284 / 500 :: 15232 / 15539 - CLASS_LOSS : 0.22735
285 / 500 :: 320 / 15539 - CLASS_LOSS : 0.2304
285 / 500 :: 960 / 15539 - CLASS_LOSS : 0.21361
285 / 500 :: 1600 / 15539 - CLASS_LOSS : 0.17179
285 / 500 :: 2240 / 15539 - CLASS_LOSS : 0.19061
285 / 500 :: 2880 / 15539 - CLASS_LOSS : 0.16891
285 / 500 :: 3520 / 15539 - CLASS_LOSS : 0.12516
285 / 500 :: 4160 / 15539 - CLASS_LOSS : 0.19805
285 / 500 :: 4800 / 15539 - CLASS_LOSS : 0.13231
285 / 500 :: 5440 / 15539 - CLASS_LOSS : 0.1254
285 / 500 :: 6080 / 15539 - CLASS_LOSS : 0.13677
285 / 500 :: 6720 / 15539 - CLASS_LOSS : 0.11016
285 / 500 :: 7360 / 15539 - CLASS_LOSS : 0.13142
285 / 500 :: 8000 / 15539 - CLASS_LOSS : 0.16134
285 / 500 :: 8640 / 15539 - CLASS_LOSS : 0.1641
285 / 500 :: 9280 / 15539 - CLASS_LOSS : 0.20163
285 / 500 :: 9920 / 15539 - CLASS_LOSS : 0.13161
285 / 500 :: 10560 / 15539 - CLASS_LOSS : 0.21476
285 / 500 :: 11200 / 15539 - CLASS_LOSS : 0.11611
285 / 500 :: 11840 / 15539 - CLASS_LOSS : 0.17153
285 / 500 :: 12480 / 15539 - CLASS_LOSS : 0.16445
285 / 500 :: 13120 / 15539 - CLASS_LOSS : 0.13182
285 / 500 :: 13760 / 15539 - CLASS_LOSS : 0.16377
285 / 500 :: 14400 / 15539 - CLASS_LOSS : 0.13146
285 / 500 :: 15040 / 15539 - CLASS_LOSS : 0.18976
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.5918012742132699 0.4961923761717828 0.42249823025934746
PSPrecision@1,3,5: 0.41820241511113354 0.45909741572366075 0.48038356982637126
testing....
Precision@1,3,5: 0.49173011289052243 0.39257897960969634 0.333210816487267
PSPrecision@1,3,5: 0.29066245606246793 0.3133114351810468 0.33223617592265314
286 / 500 :: 128 / 15539 - CLASS_LOSS : 0.15895
286 / 500 :: 768 / 15539 - CLASS_LOSS : 0.18193
286 / 500 :: 1408 / 15539 - CLASS_LOSS : 0.1633
286 / 500 :: 2048 / 15539 - CLASS_LOSS : 0.1688
286 / 500 :: 2688 / 15539 - CLASS_LOSS : 0.12032
286 / 500 :: 3328 / 15539 - CLASS_LOSS : 0.1454
286 / 500 :: 3968 / 15539 - CLASS_LOSS : 0.16705
286 / 500 :: 4608 / 15539 - CLASS_LOSS : 0.13936
286 / 500 :: 5248 / 15539 - CLASS_LOSS : 0.15007
286 / 500 :: 5888 / 15539 - CLASS_LOSS : 0.10687
286 / 500 :: 6528 / 15539 - CLASS_LOSS : 0.10494
286 / 500 :: 7168 / 15539 - CLASS_LOSS : 0.11217
286 / 500 :: 7808 / 15539 - CLASS_LOSS : 0.20702
286 / 500 :: 8448 / 15539 - CLASS_LOSS : 0.13901
286 / 500 :: 9088 / 15539 - CLASS_LOSS : 0.2
286 / 500 :: 9728 / 15539 - CLASS_LOSS : 0.10794
286 / 500 :: 10368 / 15539 - CLASS_LOSS : 0.18812
286 / 500 :: 11008 / 15539 - CLASS_LOSS : 0.14042
286 / 500 :: 11648 / 15539 - CLASS_LOSS : 0.16628
286 / 500 :: 12288 / 15539 - CLASS_LOSS : 0.18218
286 / 500 :: 12928 / 15539 - CLASS_LOSS : 0.25219
286 / 500 :: 13568 / 15539 - CLASS_LOSS : 0.16732
286 / 500 :: 14208 / 15539 - CLASS_LOSS : 0.13109
286 / 500 :: 14848 / 15539 - CLASS_LOSS : 0.16264
286 / 500 :: 15488 / 15539 - CLASS_LOSS : 0.17434
287 / 500 :: 576 / 15539 - CLASS_LOSS : 0.12566
287 / 500 :: 1216 / 15539 - CLASS_LOSS : 0.12466
287 / 500 :: 1856 / 15539 - CLASS_LOSS : 0.16346
287 / 500 :: 2496 / 15539 - CLASS_LOSS : 0.10295
287 / 500 :: 3136 / 15539 - CLASS_LOSS : 0.11153
287 / 500 :: 3776 / 15539 - CLASS_LOSS : 0.21712
287 / 500 :: 4416 / 15539 - CLASS_LOSS : 0.15842
287 / 500 :: 5056 / 15539 - CLASS_LOSS : 0.12564
287 / 500 :: 5696 / 15539 - CLASS_LOSS : 0.17191
287 / 500 :: 6336 / 15539 - CLASS_LOSS : 0.20771
287 / 500 :: 6976 / 15539 - CLASS_LOSS : 0.30254
287 / 500 :: 7616 / 15539 - CLASS_LOSS : 0.13393
287 / 500 :: 8256 / 15539 - CLASS_LOSS : 0.15215
287 / 500 :: 8896 / 15539 - CLASS_LOSS : 0.24057
287 / 500 :: 9536 / 15539 - CLASS_LOSS : 0.18884
287 / 500 :: 10176 / 15539 - CLASS_LOSS : 0.19479
287 / 500 :: 10816 / 15539 - CLASS_LOSS : 0.19902
287 / 500 :: 11456 / 15539 - CLASS_LOSS : 0.11971
287 / 500 :: 12096 / 15539 - CLASS_LOSS : 0.08124
287 / 500 :: 12736 / 15539 - CLASS_LOSS : 0.1506
287 / 500 :: 13376 / 15539 - CLASS_LOSS : 0.1643
287 / 500 :: 14016 / 15539 - CLASS_LOSS : 0.1623
287 / 500 :: 14656 / 15539 - CLASS_LOSS : 0.18005
287 / 500 :: 15296 / 15539 - CLASS_LOSS : 0.17415
288 / 500 :: 384 / 15539 - CLASS_LOSS : 0.14604
288 / 500 :: 1024 / 15539 - CLASS_LOSS : 0.28146
288 / 500 :: 1664 / 15539 - CLASS_LOSS : 0.23055
288 / 500 :: 2304 / 15539 - CLASS_LOSS : 0.19106
288 / 500 :: 2944 / 15539 - CLASS_LOSS : 0.17974
288 / 500 :: 3584 / 15539 - CLASS_LOSS : 0.11689
288 / 500 :: 4224 / 15539 - CLASS_LOSS : 0.1229
288 / 500 :: 4864 / 15539 - CLASS_LOSS : 0.21786
288 / 500 :: 5504 / 15539 - CLASS_LOSS : 0.09476
288 / 500 :: 6144 / 15539 - CLASS_LOSS : 0.11683
288 / 500 :: 6784 / 15539 - CLASS_LOSS : 0.10126
288 / 500 :: 7424 / 15539 - CLASS_LOSS : 0.24348
288 / 500 :: 8064 / 15539 - CLASS_LOSS : 0.12122
288 / 500 :: 8704 / 15539 - CLASS_LOSS : 0.11216
288 / 500 :: 9344 / 15539 - CLASS_LOSS : 0.16834
288 / 500 :: 9984 / 15539 - CLASS_LOSS : 0.10687
288 / 500 :: 10624 / 15539 - CLASS_LOSS : 0.16637
288 / 500 :: 11264 / 15539 - CLASS_LOSS : 0.20594
288 / 500 :: 11904 / 15539 - CLASS_LOSS : 0.15188
288 / 500 :: 12544 / 15539 - CLASS_LOSS : 0.14238
288 / 500 :: 13184 / 15539 - CLASS_LOSS : 0.17871
288 / 500 :: 13824 / 15539 - CLASS_LOSS : 0.1266
288 / 500 :: 14464 / 15539 - CLASS_LOSS : 0.10645
288 / 500 :: 15104 / 15539 - CLASS_LOSS : 0.1537
289 / 500 :: 192 / 15539 - CLASS_LOSS : 0.14303
289 / 500 :: 832 / 15539 - CLASS_LOSS : 0.11898
289 / 500 :: 1472 / 15539 - CLASS_LOSS : 0.16089
289 / 500 :: 2112 / 15539 - CLASS_LOSS : 0.22198
289 / 500 :: 2752 / 15539 - CLASS_LOSS : 0.12901
289 / 500 :: 3392 / 15539 - CLASS_LOSS : 0.20128
289 / 500 :: 4032 / 15539 - CLASS_LOSS : 0.24002
289 / 500 :: 4672 / 15539 - CLASS_LOSS : 0.12051
289 / 500 :: 5312 / 15539 - CLASS_LOSS : 0.18421
289 / 500 :: 5952 / 15539 - CLASS_LOSS : 0.12699
289 / 500 :: 6592 / 15539 - CLASS_LOSS : 0.19168
289 / 500 :: 7232 / 15539 - CLASS_LOSS : 0.13983
289 / 500 :: 7872 / 15539 - CLASS_LOSS : 0.25273
289 / 500 :: 8512 / 15539 - CLASS_LOSS : 0.09345
289 / 500 :: 9152 / 15539 - CLASS_LOSS : 0.13991
289 / 500 :: 9792 / 15539 - CLASS_LOSS : 0.14705
289 / 500 :: 10432 / 15539 - CLASS_LOSS : 0.22535
289 / 500 :: 11072 / 15539 - CLASS_LOSS : 0.17169
289 / 500 :: 11712 / 15539 - CLASS_LOSS : 0.24665
289 / 500 :: 12352 / 15539 - CLASS_LOSS : 0.11614
289 / 500 :: 12992 / 15539 - CLASS_LOSS : 0.13661
289 / 500 :: 13632 / 15539 - CLASS_LOSS : 0.2176
289 / 500 :: 14272 / 15539 - CLASS_LOSS : 0.16022
289 / 500 :: 14912 / 15539 - CLASS_LOSS : 0.17391
289 / 500 :: 15539 / 15539 - CLASS_LOSS : 0.19821
290 / 500 :: 640 / 15539 - CLASS_LOSS : 0.22796
290 / 500 :: 1280 / 15539 - CLASS_LOSS : 0.1464
290 / 500 :: 1920 / 15539 - CLASS_LOSS : 0.11282
290 / 500 :: 2560 / 15539 - CLASS_LOSS : 0.18857
290 / 500 :: 3200 / 15539 - CLASS_LOSS : 0.13055
290 / 500 :: 3840 / 15539 - CLASS_LOSS : 0.28221
290 / 500 :: 4480 / 15539 - CLASS_LOSS : 0.15811
290 / 500 :: 5120 / 15539 - CLASS_LOSS : 0.15211
290 / 500 :: 5760 / 15539 - CLASS_LOSS : 0.19478
290 / 500 :: 6400 / 15539 - CLASS_LOSS : 0.29247
290 / 500 :: 7040 / 15539 - CLASS_LOSS : 0.15703
290 / 500 :: 7680 / 15539 - CLASS_LOSS : 0.17299
290 / 500 :: 8320 / 15539 - CLASS_LOSS : 0.18795
290 / 500 :: 8960 / 15539 - CLASS_LOSS : 0.10728
290 / 500 :: 9600 / 15539 - CLASS_LOSS : 0.11849
290 / 500 :: 10240 / 15539 - CLASS_LOSS : 0.1704
290 / 500 :: 10880 / 15539 - CLASS_LOSS : 0.22484
290 / 500 :: 11520 / 15539 - CLASS_LOSS : 0.13084
290 / 500 :: 12160 / 15539 - CLASS_LOSS : 0.1173
290 / 500 :: 12800 / 15539 - CLASS_LOSS : 0.16537
290 / 500 :: 13440 / 15539 - CLASS_LOSS : 0.13339
290 / 500 :: 14080 / 15539 - CLASS_LOSS : 0.10169
290 / 500 :: 14720 / 15539 - CLASS_LOSS : 0.1332
290 / 500 :: 15360 / 15539 - CLASS_LOSS : 0.12302
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.5726237209601648 0.48720423879700536 0.41759443979664074
PSPrecision@1,3,5: 0.4169844108422144 0.45297627358640485 0.4770891502896145
testing....
Precision@1,3,5: 0.48096613284326595 0.3891660103264199 0.33163559989498553
PSPrecision@1,3,5: 0.2898284463471895 0.313053921413986 0.33133540416197477
291 / 500 :: 448 / 15539 - CLASS_LOSS : 0.16921
291 / 500 :: 1088 / 15539 - CLASS_LOSS : 0.28622
291 / 500 :: 1728 / 15539 - CLASS_LOSS : 0.23997
291 / 500 :: 2368 / 15539 - CLASS_LOSS : 0.27079
291 / 500 :: 3008 / 15539 - CLASS_LOSS : 0.15878
291 / 500 :: 3648 / 15539 - CLASS_LOSS : 0.2163
291 / 500 :: 4288 / 15539 - CLASS_LOSS : 0.16722
291 / 500 :: 4928 / 15539 - CLASS_LOSS : 0.18407
291 / 500 :: 5568 / 15539 - CLASS_LOSS : 0.05763
291 / 500 :: 6208 / 15539 - CLASS_LOSS : 0.17959
291 / 500 :: 6848 / 15539 - CLASS_LOSS : 0.12249
291 / 500 :: 7488 / 15539 - CLASS_LOSS : 0.13104
291 / 500 :: 8128 / 15539 - CLASS_LOSS : 0.18119
291 / 500 :: 8768 / 15539 - CLASS_LOSS : 0.24506
291 / 500 :: 9408 / 15539 - CLASS_LOSS : 0.13081
291 / 500 :: 10048 / 15539 - CLASS_LOSS : 0.17022
291 / 500 :: 10688 / 15539 - CLASS_LOSS : 0.05869
291 / 500 :: 11328 / 15539 - CLASS_LOSS : 0.16577
291 / 500 :: 11968 / 15539 - CLASS_LOSS : 0.18362
291 / 500 :: 12608 / 15539 - CLASS_LOSS : 0.15755
291 / 500 :: 13248 / 15539 - CLASS_LOSS : 0.14027
291 / 500 :: 13888 / 15539 - CLASS_LOSS : 0.16192
291 / 500 :: 14528 / 15539 - CLASS_LOSS : 0.11328
291 / 500 :: 15168 / 15539 - CLASS_LOSS : 0.17357
292 / 500 :: 256 / 15539 - CLASS_LOSS : 0.19865
292 / 500 :: 896 / 15539 - CLASS_LOSS : 0.16137
292 / 500 :: 1536 / 15539 - CLASS_LOSS : 0.20388
292 / 500 :: 2176 / 15539 - CLASS_LOSS : 0.15733
292 / 500 :: 2816 / 15539 - CLASS_LOSS : 0.21701
292 / 500 :: 3456 / 15539 - CLASS_LOSS : 0.1138
292 / 500 :: 4096 / 15539 - CLASS_LOSS : 0.16901
292 / 500 :: 4736 / 15539 - CLASS_LOSS : 0.19047
292 / 500 :: 5376 / 15539 - CLASS_LOSS : 0.1186
292 / 500 :: 6016 / 15539 - CLASS_LOSS : 0.18537
292 / 500 :: 6656 / 15539 - CLASS_LOSS : 0.14786
292 / 500 :: 7296 / 15539 - CLASS_LOSS : 0.14309
292 / 500 :: 7936 / 15539 - CLASS_LOSS : 0.19404
292 / 500 :: 8576 / 15539 - CLASS_LOSS : 0.13049
292 / 500 :: 9216 / 15539 - CLASS_LOSS : 0.22466
292 / 500 :: 9856 / 15539 - CLASS_LOSS : 0.13473
292 / 500 :: 10496 / 15539 - CLASS_LOSS : 0.12102
292 / 500 :: 11136 / 15539 - CLASS_LOSS : 0.10776
292 / 500 :: 11776 / 15539 - CLASS_LOSS : 0.17662
292 / 500 :: 12416 / 15539 - CLASS_LOSS : 0.12589
292 / 500 :: 13056 / 15539 - CLASS_LOSS : 0.16647
292 / 500 :: 13696 / 15539 - CLASS_LOSS : 0.14705
292 / 500 :: 14336 / 15539 - CLASS_LOSS : 0.11688
292 / 500 :: 14976 / 15539 - CLASS_LOSS : 0.16452
293 / 500 :: 64 / 15539 - CLASS_LOSS : 0.21082
293 / 500 :: 704 / 15539 - CLASS_LOSS : 0.09023
293 / 500 :: 1344 / 15539 - CLASS_LOSS : 0.19397
293 / 500 :: 1984 / 15539 - CLASS_LOSS : 0.17427
293 / 500 :: 2624 / 15539 - CLASS_LOSS : 0.16991
293 / 500 :: 3264 / 15539 - CLASS_LOSS : 0.13399
293 / 500 :: 3904 / 15539 - CLASS_LOSS : 0.13667
293 / 500 :: 4544 / 15539 - CLASS_LOSS : 0.13193
293 / 500 :: 5184 / 15539 - CLASS_LOSS : 0.30736
293 / 500 :: 5824 / 15539 - CLASS_LOSS : 0.07806
293 / 500 :: 6464 / 15539 - CLASS_LOSS : 0.10343
293 / 500 :: 7104 / 15539 - CLASS_LOSS : 0.2058
293 / 500 :: 7744 / 15539 - CLASS_LOSS : 0.16983
293 / 500 :: 8384 / 15539 - CLASS_LOSS : 0.17512
293 / 500 :: 9024 / 15539 - CLASS_LOSS : 0.19186
293 / 500 :: 9664 / 15539 - CLASS_LOSS : 0.13468
293 / 500 :: 10304 / 15539 - CLASS_LOSS : 0.10467
293 / 500 :: 10944 / 15539 - CLASS_LOSS : 0.22287
293 / 500 :: 11584 / 15539 - CLASS_LOSS : 0.16451
293 / 500 :: 12224 / 15539 - CLASS_LOSS : 0.29732
293 / 500 :: 12864 / 15539 - CLASS_LOSS : 0.13025
293 / 500 :: 13504 / 15539 - CLASS_LOSS : 0.18847
293 / 500 :: 14144 / 15539 - CLASS_LOSS : 0.18924
293 / 500 :: 14784 / 15539 - CLASS_LOSS : 0.22709
293 / 500 :: 15424 / 15539 - CLASS_LOSS : 0.14618
294 / 500 :: 512 / 15539 - CLASS_LOSS : 0.11434
294 / 500 :: 1152 / 15539 - CLASS_LOSS : 0.21288
294 / 500 :: 1792 / 15539 - CLASS_LOSS : 0.19064
294 / 500 :: 2432 / 15539 - CLASS_LOSS : 0.11228
294 / 500 :: 3072 / 15539 - CLASS_LOSS : 0.24623
294 / 500 :: 3712 / 15539 - CLASS_LOSS : 0.16008
294 / 500 :: 4352 / 15539 - CLASS_LOSS : 0.15836
294 / 500 :: 4992 / 15539 - CLASS_LOSS : 0.2103
294 / 500 :: 5632 / 15539 - CLASS_LOSS : 0.11452
294 / 500 :: 6272 / 15539 - CLASS_LOSS : 0.14247
294 / 500 :: 6912 / 15539 - CLASS_LOSS : 0.04893
294 / 500 :: 7552 / 15539 - CLASS_LOSS : 0.13185
294 / 500 :: 8192 / 15539 - CLASS_LOSS : 0.17674
294 / 500 :: 8832 / 15539 - CLASS_LOSS : 0.18408
294 / 500 :: 9472 / 15539 - CLASS_LOSS : 0.22319
294 / 500 :: 10112 / 15539 - CLASS_LOSS : 0.11271
294 / 500 :: 10752 / 15539 - CLASS_LOSS : 0.21781
294 / 500 :: 11392 / 15539 - CLASS_LOSS : 0.20545
294 / 500 :: 12032 / 15539 - CLASS_LOSS : 0.31266
294 / 500 :: 12672 / 15539 - CLASS_LOSS : 0.18974
294 / 500 :: 13312 / 15539 - CLASS_LOSS : 0.1685
294 / 500 :: 13952 / 15539 - CLASS_LOSS : 0.25668
294 / 500 :: 14592 / 15539 - CLASS_LOSS : 0.14844
294 / 500 :: 15232 / 15539 - CLASS_LOSS : 0.10263
295 / 500 :: 320 / 15539 - CLASS_LOSS : 0.21942
295 / 500 :: 960 / 15539 - CLASS_LOSS : 0.19285
295 / 500 :: 1600 / 15539 - CLASS_LOSS : 0.13567
295 / 500 :: 2240 / 15539 - CLASS_LOSS : 0.18351
295 / 500 :: 2880 / 15539 - CLASS_LOSS : 0.17356
295 / 500 :: 3520 / 15539 - CLASS_LOSS : 0.25358
295 / 500 :: 4160 / 15539 - CLASS_LOSS : 0.09986
295 / 500 :: 4800 / 15539 - CLASS_LOSS : 0.11317
295 / 500 :: 5440 / 15539 - CLASS_LOSS : 0.13673
295 / 500 :: 6080 / 15539 - CLASS_LOSS : 0.1273
295 / 500 :: 6720 / 15539 - CLASS_LOSS : 0.11691
295 / 500 :: 7360 / 15539 - CLASS_LOSS : 0.14209
295 / 500 :: 8000 / 15539 - CLASS_LOSS : 0.14663
295 / 500 :: 8640 / 15539 - CLASS_LOSS : 0.18598
295 / 500 :: 9280 / 15539 - CLASS_LOSS : 0.23259
295 / 500 :: 9920 / 15539 - CLASS_LOSS : 0.14028
295 / 500 :: 10560 / 15539 - CLASS_LOSS : 0.20507
295 / 500 :: 11200 / 15539 - CLASS_LOSS : 0.12599
295 / 500 :: 11840 / 15539 - CLASS_LOSS : 0.18171
295 / 500 :: 12480 / 15539 - CLASS_LOSS : 0.22568
295 / 500 :: 13120 / 15539 - CLASS_LOSS : 0.26814
295 / 500 :: 13760 / 15539 - CLASS_LOSS : 0.2312
295 / 500 :: 14400 / 15539 - CLASS_LOSS : 0.16039
295 / 500 :: 15040 / 15539 - CLASS_LOSS : 0.12064
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.57925220413154 0.49063646309286313 0.42060621661625586
PSPrecision@1,3,5: 0.41432270282939476 0.45636816404434066 0.4793491700597277
testing....
Precision@1,3,5: 0.4977684431609346 0.4002800385052945 0.33525859805723285
PSPrecision@1,3,5: 0.2972126888104424 0.32187455772753926 0.33355662170732747
296 / 500 :: 128 / 15539 - CLASS_LOSS : 0.21393
296 / 500 :: 768 / 15539 - CLASS_LOSS : 0.20766
296 / 500 :: 1408 / 15539 - CLASS_LOSS : 0.12214
296 / 500 :: 2048 / 15539 - CLASS_LOSS : 0.23021
296 / 500 :: 2688 / 15539 - CLASS_LOSS : 0.173
296 / 500 :: 3328 / 15539 - CLASS_LOSS : 0.23525
296 / 500 :: 3968 / 15539 - CLASS_LOSS : 0.108
296 / 500 :: 4608 / 15539 - CLASS_LOSS : 0.13624
296 / 500 :: 5248 / 15539 - CLASS_LOSS : 0.17779
296 / 500 :: 5888 / 15539 - CLASS_LOSS : 0.17403
296 / 500 :: 6528 / 15539 - CLASS_LOSS : 0.18193
296 / 500 :: 7168 / 15539 - CLASS_LOSS : 0.15032
296 / 500 :: 7808 / 15539 - CLASS_LOSS : 0.1839
296 / 500 :: 8448 / 15539 - CLASS_LOSS : 0.13794
296 / 500 :: 9088 / 15539 - CLASS_LOSS : 0.08646
296 / 500 :: 9728 / 15539 - CLASS_LOSS : 0.1555
296 / 500 :: 10368 / 15539 - CLASS_LOSS : 0.16551
296 / 500 :: 11008 / 15539 - CLASS_LOSS : 0.14482
296 / 500 :: 11648 / 15539 - CLASS_LOSS : 0.14564
296 / 500 :: 12288 / 15539 - CLASS_LOSS : 0.16156
296 / 500 :: 12928 / 15539 - CLASS_LOSS : 0.15653
296 / 500 :: 13568 / 15539 - CLASS_LOSS : 0.20951
296 / 500 :: 14208 / 15539 - CLASS_LOSS : 0.20015
296 / 500 :: 14848 / 15539 - CLASS_LOSS : 0.19718
296 / 500 :: 15488 / 15539 - CLASS_LOSS : 0.21479
297 / 500 :: 576 / 15539 - CLASS_LOSS : 0.16504
297 / 500 :: 1216 / 15539 - CLASS_LOSS : 0.15069
297 / 500 :: 1856 / 15539 - CLASS_LOSS : 0.18801
297 / 500 :: 2496 / 15539 - CLASS_LOSS : 0.14451
297 / 500 :: 3136 / 15539 - CLASS_LOSS : 0.16134
297 / 500 :: 3776 / 15539 - CLASS_LOSS : 0.26084
297 / 500 :: 4416 / 15539 - CLASS_LOSS : 0.18647
297 / 500 :: 5056 / 15539 - CLASS_LOSS : 0.10943
297 / 500 :: 5696 / 15539 - CLASS_LOSS : 0.18391
297 / 500 :: 6336 / 15539 - CLASS_LOSS : 0.20931
297 / 500 :: 6976 / 15539 - CLASS_LOSS : 0.18052
297 / 500 :: 7616 / 15539 - CLASS_LOSS : 0.13157
297 / 500 :: 8256 / 15539 - CLASS_LOSS : 0.17177
297 / 500 :: 8896 / 15539 - CLASS_LOSS : 0.16797
297 / 500 :: 9536 / 15539 - CLASS_LOSS : 0.13034
297 / 500 :: 10176 / 15539 - CLASS_LOSS : 0.0861
297 / 500 :: 10816 / 15539 - CLASS_LOSS : 0.17996
297 / 500 :: 11456 / 15539 - CLASS_LOSS : 0.18183
297 / 500 :: 12096 / 15539 - CLASS_LOSS : 0.13059
297 / 500 :: 12736 / 15539 - CLASS_LOSS : 0.15044
297 / 500 :: 13376 / 15539 - CLASS_LOSS : 0.24552
297 / 500 :: 14016 / 15539 - CLASS_LOSS : 0.16494
297 / 500 :: 14656 / 15539 - CLASS_LOSS : 0.13538
297 / 500 :: 15296 / 15539 - CLASS_LOSS : 0.08983
298 / 500 :: 384 / 15539 - CLASS_LOSS : 0.14964
298 / 500 :: 1024 / 15539 - CLASS_LOSS : 0.16552
298 / 500 :: 1664 / 15539 - CLASS_LOSS : 0.11355
298 / 500 :: 2304 / 15539 - CLASS_LOSS : 0.33094
298 / 500 :: 2944 / 15539 - CLASS_LOSS : 0.13291
298 / 500 :: 3584 / 15539 - CLASS_LOSS : 0.13155
298 / 500 :: 4224 / 15539 - CLASS_LOSS : 0.09375
298 / 500 :: 4864 / 15539 - CLASS_LOSS : 0.17511
298 / 500 :: 5504 / 15539 - CLASS_LOSS : 0.22244
298 / 500 :: 6144 / 15539 - CLASS_LOSS : 0.24532
298 / 500 :: 6784 / 15539 - CLASS_LOSS : 0.18946
298 / 500 :: 7424 / 15539 - CLASS_LOSS : 0.12029
298 / 500 :: 8064 / 15539 - CLASS_LOSS : 0.20975
298 / 500 :: 8704 / 15539 - CLASS_LOSS : 0.1371
298 / 500 :: 9344 / 15539 - CLASS_LOSS : 0.2404
298 / 500 :: 9984 / 15539 - CLASS_LOSS : 0.28068
298 / 500 :: 10624 / 15539 - CLASS_LOSS : 0.15024
298 / 500 :: 11264 / 15539 - CLASS_LOSS : 0.16001
298 / 500 :: 11904 / 15539 - CLASS_LOSS : 0.16865
298 / 500 :: 12544 / 15539 - CLASS_LOSS : 0.16626
298 / 500 :: 13184 / 15539 - CLASS_LOSS : 0.19957
298 / 500 :: 13824 / 15539 - CLASS_LOSS : 0.14689
298 / 500 :: 14464 / 15539 - CLASS_LOSS : 0.11001
298 / 500 :: 15104 / 15539 - CLASS_LOSS : 0.10559
299 / 500 :: 192 / 15539 - CLASS_LOSS : 0.13258
299 / 500 :: 832 / 15539 - CLASS_LOSS : 0.2111
299 / 500 :: 1472 / 15539 - CLASS_LOSS : 0.17677
299 / 500 :: 2112 / 15539 - CLASS_LOSS : 0.13266
299 / 500 :: 2752 / 15539 - CLASS_LOSS : 0.20253
299 / 500 :: 3392 / 15539 - CLASS_LOSS : 0.20159
299 / 500 :: 4032 / 15539 - CLASS_LOSS : 0.13167
299 / 500 :: 4672 / 15539 - CLASS_LOSS : 0.1443
299 / 500 :: 5312 / 15539 - CLASS_LOSS : 0.05913
299 / 500 :: 5952 / 15539 - CLASS_LOSS : 0.17874
299 / 500 :: 6592 / 15539 - CLASS_LOSS : 0.15392
299 / 500 :: 7232 / 15539 - CLASS_LOSS : 0.18642
299 / 500 :: 7872 / 15539 - CLASS_LOSS : 0.24759
299 / 500 :: 8512 / 15539 - CLASS_LOSS : 0.22178
299 / 500 :: 9152 / 15539 - CLASS_LOSS : 0.14495
299 / 500 :: 9792 / 15539 - CLASS_LOSS : 0.0979
299 / 500 :: 10432 / 15539 - CLASS_LOSS : 0.16119
299 / 500 :: 11072 / 15539 - CLASS_LOSS : 0.20353
299 / 500 :: 11712 / 15539 - CLASS_LOSS : 0.18731
299 / 500 :: 12352 / 15539 - CLASS_LOSS : 0.19155
299 / 500 :: 12992 / 15539 - CLASS_LOSS : 0.11562
299 / 500 :: 13632 / 15539 - CLASS_LOSS : 0.1395
299 / 500 :: 14272 / 15539 - CLASS_LOSS : 0.12545
299 / 500 :: 14912 / 15539 - CLASS_LOSS : 0.12867
299 / 500 :: 15539 / 15539 - CLASS_LOSS : 0.20412
300 / 500 :: 640 / 15539 - CLASS_LOSS : 0.11986
300 / 500 :: 1280 / 15539 - CLASS_LOSS : 0.16348
300 / 500 :: 1920 / 15539 - CLASS_LOSS : 0.13955
300 / 500 :: 2560 / 15539 - CLASS_LOSS : 0.18492
300 / 500 :: 3200 / 15539 - CLASS_LOSS : 0.12537
300 / 500 :: 3840 / 15539 - CLASS_LOSS : 0.19138
300 / 500 :: 4480 / 15539 - CLASS_LOSS : 0.18002
300 / 500 :: 5120 / 15539 - CLASS_LOSS : 0.2102
300 / 500 :: 5760 / 15539 - CLASS_LOSS : 0.12078
300 / 500 :: 6400 / 15539 - CLASS_LOSS : 0.19197
300 / 500 :: 7040 / 15539 - CLASS_LOSS : 0.17884
300 / 500 :: 7680 / 15539 - CLASS_LOSS : 0.22685
300 / 500 :: 8320 / 15539 - CLASS_LOSS : 0.19537
300 / 500 :: 8960 / 15539 - CLASS_LOSS : 0.22058
300 / 500 :: 9600 / 15539 - CLASS_LOSS : 0.10051
300 / 500 :: 10240 / 15539 - CLASS_LOSS : 0.20005
300 / 500 :: 10880 / 15539 - CLASS_LOSS : 0.15887
300 / 500 :: 11520 / 15539 - CLASS_LOSS : 0.14676
300 / 500 :: 12160 / 15539 - CLASS_LOSS : 0.20645
300 / 500 :: 12800 / 15539 - CLASS_LOSS : 0.09204
300 / 500 :: 13440 / 15539 - CLASS_LOSS : 0.23013
300 / 500 :: 14080 / 15539 - CLASS_LOSS : 0.14896
300 / 500 :: 14720 / 15539 - CLASS_LOSS : 0.12614
300 / 500 :: 15360 / 15539 - CLASS_LOSS : 0.12558
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.5699208443271768 0.48675375935817405 0.4181092734410194
PSPrecision@1,3,5: 0.4082889269381717 0.45400626876433775 0.4782262902124357
testing....
Precision@1,3,5: 0.495668154371226 0.3979172136168723 0.3375689157259123
PSPrecision@1,3,5: 0.29633578010522865 0.319414328951996 0.3362763842525744
301 / 500 :: 448 / 15539 - CLASS_LOSS : 0.20325
301 / 500 :: 1088 / 15539 - CLASS_LOSS : 0.1998
301 / 500 :: 1728 / 15539 - CLASS_LOSS : 0.1399
301 / 500 :: 2368 / 15539 - CLASS_LOSS : 0.18354
301 / 500 :: 3008 / 15539 - CLASS_LOSS : 0.15141
301 / 500 :: 3648 / 15539 - CLASS_LOSS : 0.17183
301 / 500 :: 4288 / 15539 - CLASS_LOSS : 0.23432
301 / 500 :: 4928 / 15539 - CLASS_LOSS : 0.15027
301 / 500 :: 5568 / 15539 - CLASS_LOSS : 0.22088
301 / 500 :: 6208 / 15539 - CLASS_LOSS : 0.20737
301 / 500 :: 6848 / 15539 - CLASS_LOSS : 0.15974
301 / 500 :: 7488 / 15539 - CLASS_LOSS : 0.17234
301 / 500 :: 8128 / 15539 - CLASS_LOSS : 0.23127
301 / 500 :: 8768 / 15539 - CLASS_LOSS : 0.21402
301 / 500 :: 9408 / 15539 - CLASS_LOSS : 0.15074
301 / 500 :: 10048 / 15539 - CLASS_LOSS : 0.27847
301 / 500 :: 10688 / 15539 - CLASS_LOSS : 0.1291
301 / 500 :: 11328 / 15539 - CLASS_LOSS : 0.23785
301 / 500 :: 11968 / 15539 - CLASS_LOSS : 0.17041
301 / 500 :: 12608 / 15539 - CLASS_LOSS : 0.21838
301 / 500 :: 13248 / 15539 - CLASS_LOSS : 0.20522
301 / 500 :: 13888 / 15539 - CLASS_LOSS : 0.1739
301 / 500 :: 14528 / 15539 - CLASS_LOSS : 0.17278
301 / 500 :: 15168 / 15539 - CLASS_LOSS : 0.10771
302 / 500 :: 256 / 15539 - CLASS_LOSS : 0.1136
302 / 500 :: 896 / 15539 - CLASS_LOSS : 0.22786
302 / 500 :: 1536 / 15539 - CLASS_LOSS : 0.18702
302 / 500 :: 2176 / 15539 - CLASS_LOSS : 0.1128
302 / 500 :: 2816 / 15539 - CLASS_LOSS : 0.16338
302 / 500 :: 3456 / 15539 - CLASS_LOSS : 0.20157
302 / 500 :: 4096 / 15539 - CLASS_LOSS : 0.1567
302 / 500 :: 4736 / 15539 - CLASS_LOSS : 0.15997
302 / 500 :: 5376 / 15539 - CLASS_LOSS : 0.12016
302 / 500 :: 6016 / 15539 - CLASS_LOSS : 0.16772
302 / 500 :: 6656 / 15539 - CLASS_LOSS : 0.26983
302 / 500 :: 7296 / 15539 - CLASS_LOSS : 0.17551
302 / 500 :: 7936 / 15539 - CLASS_LOSS : 0.18372
302 / 500 :: 8576 / 15539 - CLASS_LOSS : 0.13461
302 / 500 :: 9216 / 15539 - CLASS_LOSS : 0.22002
302 / 500 :: 9856 / 15539 - CLASS_LOSS : 0.17585
302 / 500 :: 10496 / 15539 - CLASS_LOSS : 0.0887
302 / 500 :: 11136 / 15539 - CLASS_LOSS : 0.155
302 / 500 :: 11776 / 15539 - CLASS_LOSS : 0.18651
302 / 500 :: 12416 / 15539 - CLASS_LOSS : 0.21542
302 / 500 :: 13056 / 15539 - CLASS_LOSS : 0.135
302 / 500 :: 13696 / 15539 - CLASS_LOSS : 0.19964
302 / 500 :: 14336 / 15539 - CLASS_LOSS : 0.10693
302 / 500 :: 14976 / 15539 - CLASS_LOSS : 0.08989
303 / 500 :: 64 / 15539 - CLASS_LOSS : 0.16743
303 / 500 :: 704 / 15539 - CLASS_LOSS : 0.15403
303 / 500 :: 1344 / 15539 - CLASS_LOSS : 0.14582
303 / 500 :: 1984 / 15539 - CLASS_LOSS : 0.16087
303 / 500 :: 2624 / 15539 - CLASS_LOSS : 0.16941
303 / 500 :: 3264 / 15539 - CLASS_LOSS : 0.20208
303 / 500 :: 3904 / 15539 - CLASS_LOSS : 0.17175
303 / 500 :: 4544 / 15539 - CLASS_LOSS : 0.16221
303 / 500 :: 5184 / 15539 - CLASS_LOSS : 0.14751
303 / 500 :: 5824 / 15539 - CLASS_LOSS : 0.15684
303 / 500 :: 6464 / 15539 - CLASS_LOSS : 0.11943
303 / 500 :: 7104 / 15539 - CLASS_LOSS : 0.11335
303 / 500 :: 7744 / 15539 - CLASS_LOSS : 0.24406
303 / 500 :: 8384 / 15539 - CLASS_LOSS : 0.11895
303 / 500 :: 9024 / 15539 - CLASS_LOSS : 0.16133
303 / 500 :: 9664 / 15539 - CLASS_LOSS : 0.18741
303 / 500 :: 10304 / 15539 - CLASS_LOSS : 0.16679
303 / 500 :: 10944 / 15539 - CLASS_LOSS : 0.10668
303 / 500 :: 11584 / 15539 - CLASS_LOSS : 0.21855
303 / 500 :: 12224 / 15539 - CLASS_LOSS : 0.14582
303 / 500 :: 12864 / 15539 - CLASS_LOSS : 0.2382
303 / 500 :: 13504 / 15539 - CLASS_LOSS : 0.13945
303 / 500 :: 14144 / 15539 - CLASS_LOSS : 0.205
303 / 500 :: 14784 / 15539 - CLASS_LOSS : 0.34598
303 / 500 :: 15424 / 15539 - CLASS_LOSS : 0.23116
304 / 500 :: 512 / 15539 - CLASS_LOSS : 0.18497
304 / 500 :: 1152 / 15539 - CLASS_LOSS : 0.09821
304 / 500 :: 1792 / 15539 - CLASS_LOSS : 0.27259
304 / 500 :: 2432 / 15539 - CLASS_LOSS : 0.14559
304 / 500 :: 3072 / 15539 - CLASS_LOSS : 0.17119
304 / 500 :: 3712 / 15539 - CLASS_LOSS : 0.1242
304 / 500 :: 4352 / 15539 - CLASS_LOSS : 0.09917
304 / 500 :: 4992 / 15539 - CLASS_LOSS : 0.08958
304 / 500 :: 5632 / 15539 - CLASS_LOSS : 0.15796
304 / 500 :: 6272 / 15539 - CLASS_LOSS : 0.20741
304 / 500 :: 6912 / 15539 - CLASS_LOSS : 0.17885
304 / 500 :: 7552 / 15539 - CLASS_LOSS : 0.16013
304 / 500 :: 8192 / 15539 - CLASS_LOSS : 0.18875
304 / 500 :: 8832 / 15539 - CLASS_LOSS : 0.16885
304 / 500 :: 9472 / 15539 - CLASS_LOSS : 0.13835
304 / 500 :: 10112 / 15539 - CLASS_LOSS : 0.15317
304 / 500 :: 10752 / 15539 - CLASS_LOSS : 0.16356
304 / 500 :: 11392 / 15539 - CLASS_LOSS : 0.12846
304 / 500 :: 12032 / 15539 - CLASS_LOSS : 0.14196
304 / 500 :: 12672 / 15539 - CLASS_LOSS : 0.14357
304 / 500 :: 13312 / 15539 - CLASS_LOSS : 0.1011
304 / 500 :: 13952 / 15539 - CLASS_LOSS : 0.14606
304 / 500 :: 14592 / 15539 - CLASS_LOSS : 0.20114
304 / 500 :: 15232 / 15539 - CLASS_LOSS : 0.2031
305 / 500 :: 320 / 15539 - CLASS_LOSS : 0.17042
305 / 500 :: 960 / 15539 - CLASS_LOSS : 0.17755
305 / 500 :: 1600 / 15539 - CLASS_LOSS : 0.24687
305 / 500 :: 2240 / 15539 - CLASS_LOSS : 0.27459
305 / 500 :: 2880 / 15539 - CLASS_LOSS : 0.18705
305 / 500 :: 3520 / 15539 - CLASS_LOSS : 0.11979
305 / 500 :: 4160 / 15539 - CLASS_LOSS : 0.22664
305 / 500 :: 4800 / 15539 - CLASS_LOSS : 0.16763
305 / 500 :: 5440 / 15539 - CLASS_LOSS : 0.25178
305 / 500 :: 6080 / 15539 - CLASS_LOSS : 0.0919
305 / 500 :: 6720 / 15539 - CLASS_LOSS : 0.19341
305 / 500 :: 7360 / 15539 - CLASS_LOSS : 0.22085
305 / 500 :: 8000 / 15539 - CLASS_LOSS : 0.14793
305 / 500 :: 8640 / 15539 - CLASS_LOSS : 0.21385
305 / 500 :: 9280 / 15539 - CLASS_LOSS : 0.15816
305 / 500 :: 9920 / 15539 - CLASS_LOSS : 0.23352
305 / 500 :: 10560 / 15539 - CLASS_LOSS : 0.17192
305 / 500 :: 11200 / 15539 - CLASS_LOSS : 0.16008
305 / 500 :: 11840 / 15539 - CLASS_LOSS : 0.1692
305 / 500 :: 12480 / 15539 - CLASS_LOSS : 0.12171
305 / 500 :: 13120 / 15539 - CLASS_LOSS : 0.17442
305 / 500 :: 13760 / 15539 - CLASS_LOSS : 0.17152
305 / 500 :: 14400 / 15539 - CLASS_LOSS : 0.14008
305 / 500 :: 15040 / 15539 - CLASS_LOSS : 0.16216
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.5847866658086106 0.49786558551601345 0.423811056052513
PSPrecision@1,3,5: 0.4177762043735336 0.46111730839054627 0.4811912385873683
testing....
Precision@1,3,5: 0.4940929377789446 0.39721711735363613 0.33688632186925704
PSPrecision@1,3,5: 0.295092071252537 0.31889051393529105 0.3367921463737503
306 / 500 :: 128 / 15539 - CLASS_LOSS : 0.19692
306 / 500 :: 768 / 15539 - CLASS_LOSS : 0.14395
306 / 500 :: 1408 / 15539 - CLASS_LOSS : 0.2279
306 / 500 :: 2048 / 15539 - CLASS_LOSS : 0.15356
306 / 500 :: 2688 / 15539 - CLASS_LOSS : 0.18326
306 / 500 :: 3328 / 15539 - CLASS_LOSS : 0.17524
306 / 500 :: 3968 / 15539 - CLASS_LOSS : 0.15669
306 / 500 :: 4608 / 15539 - CLASS_LOSS : 0.17396
306 / 500 :: 5248 / 15539 - CLASS_LOSS : 0.08127
306 / 500 :: 5888 / 15539 - CLASS_LOSS : 0.2101
306 / 500 :: 6528 / 15539 - CLASS_LOSS : 0.20004
306 / 500 :: 7168 / 15539 - CLASS_LOSS : 0.1778
306 / 500 :: 7808 / 15539 - CLASS_LOSS : 0.12853
306 / 500 :: 8448 / 15539 - CLASS_LOSS : 0.16392
306 / 500 :: 9088 / 15539 - CLASS_LOSS : 0.32011
306 / 500 :: 9728 / 15539 - CLASS_LOSS : 0.19012
306 / 500 :: 10368 / 15539 - CLASS_LOSS : 0.23385
306 / 500 :: 11008 / 15539 - CLASS_LOSS : 0.14267
306 / 500 :: 11648 / 15539 - CLASS_LOSS : 0.22319
306 / 500 :: 12288 / 15539 - CLASS_LOSS : 0.21805
306 / 500 :: 12928 / 15539 - CLASS_LOSS : 0.20079
306 / 500 :: 13568 / 15539 - CLASS_LOSS : 0.19484
306 / 500 :: 14208 / 15539 - CLASS_LOSS : 0.1921
306 / 500 :: 14848 / 15539 - CLASS_LOSS : 0.14485
306 / 500 :: 15488 / 15539 - CLASS_LOSS : 0.15318
307 / 500 :: 576 / 15539 - CLASS_LOSS : 0.15286
307 / 500 :: 1216 / 15539 - CLASS_LOSS : 0.10908
307 / 500 :: 1856 / 15539 - CLASS_LOSS : 0.09594
307 / 500 :: 2496 / 15539 - CLASS_LOSS : 0.15585
307 / 500 :: 3136 / 15539 - CLASS_LOSS : 0.15865
307 / 500 :: 3776 / 15539 - CLASS_LOSS : 0.09065
307 / 500 :: 4416 / 15539 - CLASS_LOSS : 0.16619
307 / 500 :: 5056 / 15539 - CLASS_LOSS : 0.19764
307 / 500 :: 5696 / 15539 - CLASS_LOSS : 0.11519
307 / 500 :: 6336 / 15539 - CLASS_LOSS : 0.16946
307 / 500 :: 6976 / 15539 - CLASS_LOSS : 0.17601
307 / 500 :: 7616 / 15539 - CLASS_LOSS : 0.18528
307 / 500 :: 8256 / 15539 - CLASS_LOSS : 0.16495
307 / 500 :: 8896 / 15539 - CLASS_LOSS : 0.18889
307 / 500 :: 9536 / 15539 - CLASS_LOSS : 0.12852
307 / 500 :: 10176 / 15539 - CLASS_LOSS : 0.17521
307 / 500 :: 10816 / 15539 - CLASS_LOSS : 0.19968
307 / 500 :: 11456 / 15539 - CLASS_LOSS : 0.22744
307 / 500 :: 12096 / 15539 - CLASS_LOSS : 0.12418
307 / 500 :: 12736 / 15539 - CLASS_LOSS : 0.22325
307 / 500 :: 13376 / 15539 - CLASS_LOSS : 0.28412
307 / 500 :: 14016 / 15539 - CLASS_LOSS : 0.18175
307 / 500 :: 14656 / 15539 - CLASS_LOSS : 0.20094
307 / 500 :: 15296 / 15539 - CLASS_LOSS : 0.1945
308 / 500 :: 384 / 15539 - CLASS_LOSS : 0.17967
308 / 500 :: 1024 / 15539 - CLASS_LOSS : 0.14163
308 / 500 :: 1664 / 15539 - CLASS_LOSS : 0.2044
308 / 500 :: 2304 / 15539 - CLASS_LOSS : 0.19882
308 / 500 :: 2944 / 15539 - CLASS_LOSS : 0.09273
308 / 500 :: 3584 / 15539 - CLASS_LOSS : 0.1919
308 / 500 :: 4224 / 15539 - CLASS_LOSS : 0.20709
308 / 500 :: 4864 / 15539 - CLASS_LOSS : 0.19597
308 / 500 :: 5504 / 15539 - CLASS_LOSS : 0.21659
308 / 500 :: 6144 / 15539 - CLASS_LOSS : 0.15971
308 / 500 :: 6784 / 15539 - CLASS_LOSS : 0.12304
308 / 500 :: 7424 / 15539 - CLASS_LOSS : 0.18467
308 / 500 :: 8064 / 15539 - CLASS_LOSS : 0.19032
308 / 500 :: 8704 / 15539 - CLASS_LOSS : 0.1556
308 / 500 :: 9344 / 15539 - CLASS_LOSS : 0.17747
308 / 500 :: 9984 / 15539 - CLASS_LOSS : 0.19778
308 / 500 :: 10624 / 15539 - CLASS_LOSS : 0.08378
308 / 500 :: 11264 / 15539 - CLASS_LOSS : 0.1845
308 / 500 :: 11904 / 15539 - CLASS_LOSS : 0.15579
308 / 500 :: 12544 / 15539 - CLASS_LOSS : 0.15288
308 / 500 :: 13184 / 15539 - CLASS_LOSS : 0.13257
308 / 500 :: 13824 / 15539 - CLASS_LOSS : 0.19335
308 / 500 :: 14464 / 15539 - CLASS_LOSS : 0.15957
308 / 500 :: 15104 / 15539 - CLASS_LOSS : 0.27384
309 / 500 :: 192 / 15539 - CLASS_LOSS : 0.16332
309 / 500 :: 832 / 15539 - CLASS_LOSS : 0.11106
309 / 500 :: 1472 / 15539 - CLASS_LOSS : 0.13648
309 / 500 :: 2112 / 15539 - CLASS_LOSS : 0.07727
309 / 500 :: 2752 / 15539 - CLASS_LOSS : 0.13361
309 / 500 :: 3392 / 15539 - CLASS_LOSS : 0.18261
309 / 500 :: 4032 / 15539 - CLASS_LOSS : 0.06567
309 / 500 :: 4672 / 15539 - CLASS_LOSS : 0.16341
309 / 500 :: 5312 / 15539 - CLASS_LOSS : 0.33209
309 / 500 :: 5952 / 15539 - CLASS_LOSS : 0.14266
309 / 500 :: 6592 / 15539 - CLASS_LOSS : 0.09258
309 / 500 :: 7232 / 15539 - CLASS_LOSS : 0.19055
309 / 500 :: 7872 / 15539 - CLASS_LOSS : 0.11303
309 / 500 :: 8512 / 15539 - CLASS_LOSS : 0.13643
309 / 500 :: 9152 / 15539 - CLASS_LOSS : 0.18424
309 / 500 :: 9792 / 15539 - CLASS_LOSS : 0.22636
309 / 500 :: 10432 / 15539 - CLASS_LOSS : 0.12738
309 / 500 :: 11072 / 15539 - CLASS_LOSS : 0.14261
309 / 500 :: 11712 / 15539 - CLASS_LOSS : 0.14375
309 / 500 :: 12352 / 15539 - CLASS_LOSS : 0.21929
309 / 500 :: 12992 / 15539 - CLASS_LOSS : 0.13193
309 / 500 :: 13632 / 15539 - CLASS_LOSS : 0.14717
309 / 500 :: 14272 / 15539 - CLASS_LOSS : 0.10881
309 / 500 :: 14912 / 15539 - CLASS_LOSS : 0.21126
309 / 500 :: 15539 / 15539 - CLASS_LOSS : 0.30642
310 / 500 :: 640 / 15539 - CLASS_LOSS : 0.18356
310 / 500 :: 1280 / 15539 - CLASS_LOSS : 0.09859
310 / 500 :: 1920 / 15539 - CLASS_LOSS : 0.1063
310 / 500 :: 2560 / 15539 - CLASS_LOSS : 0.20112
310 / 500 :: 3200 / 15539 - CLASS_LOSS : 0.14628
310 / 500 :: 3840 / 15539 - CLASS_LOSS : 0.09441
310 / 500 :: 4480 / 15539 - CLASS_LOSS : 0.14649
310 / 500 :: 5120 / 15539 - CLASS_LOSS : 0.17861
310 / 500 :: 5760 / 15539 - CLASS_LOSS : 0.09779
310 / 500 :: 6400 / 15539 - CLASS_LOSS : 0.11022
310 / 500 :: 7040 / 15539 - CLASS_LOSS : 0.1632
310 / 500 :: 7680 / 15539 - CLASS_LOSS : 0.15836
310 / 500 :: 8320 / 15539 - CLASS_LOSS : 0.16608
310 / 500 :: 8960 / 15539 - CLASS_LOSS : 0.16819
310 / 500 :: 9600 / 15539 - CLASS_LOSS : 0.16515
310 / 500 :: 10240 / 15539 - CLASS_LOSS : 0.24095
310 / 500 :: 10880 / 15539 - CLASS_LOSS : 0.20175
310 / 500 :: 11520 / 15539 - CLASS_LOSS : 0.18443
310 / 500 :: 12160 / 15539 - CLASS_LOSS : 0.20807
310 / 500 :: 12800 / 15539 - CLASS_LOSS : 0.20675
310 / 500 :: 13440 / 15539 - CLASS_LOSS : 0.16426
310 / 500 :: 14080 / 15539 - CLASS_LOSS : 0.21575
310 / 500 :: 14720 / 15539 - CLASS_LOSS : 0.17096
310 / 500 :: 15360 / 15539 - CLASS_LOSS : 0.1227
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.5665100714331681 0.49010017804663536 0.4216744964283416
PSPrecision@1,3,5: 0.4057172845763357 0.4537793904154848 0.47866934063342437
testing....
Precision@1,3,5: 0.49067996849566814 0.3982672617484904 0.33525859805723285
PSPrecision@1,3,5: 0.2944950811232578 0.31952865946087505 0.3332703758161131
311 / 500 :: 448 / 15539 - CLASS_LOSS : 0.21888
311 / 500 :: 1088 / 15539 - CLASS_LOSS : 0.09351
311 / 500 :: 1728 / 15539 - CLASS_LOSS : 0.16933
311 / 500 :: 2368 / 15539 - CLASS_LOSS : 0.15085
311 / 500 :: 3008 / 15539 - CLASS_LOSS : 0.22097
311 / 500 :: 3648 / 15539 - CLASS_LOSS : 0.13024
311 / 500 :: 4288 / 15539 - CLASS_LOSS : 0.17292
311 / 500 :: 4928 / 15539 - CLASS_LOSS : 0.15587
311 / 500 :: 5568 / 15539 - CLASS_LOSS : 0.15924
311 / 500 :: 6208 / 15539 - CLASS_LOSS : 0.19006
311 / 500 :: 6848 / 15539 - CLASS_LOSS : 0.2041
311 / 500 :: 7488 / 15539 - CLASS_LOSS : 0.09252
311 / 500 :: 8128 / 15539 - CLASS_LOSS : 0.16038
311 / 500 :: 8768 / 15539 - CLASS_LOSS : 0.08785
311 / 500 :: 9408 / 15539 - CLASS_LOSS : 0.17475
311 / 500 :: 10048 / 15539 - CLASS_LOSS : 0.21801
311 / 500 :: 10688 / 15539 - CLASS_LOSS : 0.11175
311 / 500 :: 11328 / 15539 - CLASS_LOSS : 0.10258
311 / 500 :: 11968 / 15539 - CLASS_LOSS : 0.14355
311 / 500 :: 12608 / 15539 - CLASS_LOSS : 0.23891
311 / 500 :: 13248 / 15539 - CLASS_LOSS : 0.15446
311 / 500 :: 13888 / 15539 - CLASS_LOSS : 0.19867
311 / 500 :: 14528 / 15539 - CLASS_LOSS : 0.12994
311 / 500 :: 15168 / 15539 - CLASS_LOSS : 0.10637
312 / 500 :: 256 / 15539 - CLASS_LOSS : 0.15556
312 / 500 :: 896 / 15539 - CLASS_LOSS : 0.26324
312 / 500 :: 1536 / 15539 - CLASS_LOSS : 0.11832
312 / 500 :: 2176 / 15539 - CLASS_LOSS : 0.25455
312 / 500 :: 2816 / 15539 - CLASS_LOSS : 0.22393
312 / 500 :: 3456 / 15539 - CLASS_LOSS : 0.16763
312 / 500 :: 4096 / 15539 - CLASS_LOSS : 0.15303
312 / 500 :: 4736 / 15539 - CLASS_LOSS : 0.11072
312 / 500 :: 5376 / 15539 - CLASS_LOSS : 0.13636
312 / 500 :: 6016 / 15539 - CLASS_LOSS : 0.18444
312 / 500 :: 6656 / 15539 - CLASS_LOSS : 0.19471
312 / 500 :: 7296 / 15539 - CLASS_LOSS : 0.16823
312 / 500 :: 7936 / 15539 - CLASS_LOSS : 0.2003
312 / 500 :: 8576 / 15539 - CLASS_LOSS : 0.2123
312 / 500 :: 9216 / 15539 - CLASS_LOSS : 0.2522
312 / 500 :: 9856 / 15539 - CLASS_LOSS : 0.24852
312 / 500 :: 10496 / 15539 - CLASS_LOSS : 0.17257
312 / 500 :: 11136 / 15539 - CLASS_LOSS : 0.25236
312 / 500 :: 11776 / 15539 - CLASS_LOSS : 0.12214
312 / 500 :: 12416 / 15539 - CLASS_LOSS : 0.34227
312 / 500 :: 13056 / 15539 - CLASS_LOSS : 0.15208
312 / 500 :: 13696 / 15539 - CLASS_LOSS : 0.24069
312 / 500 :: 14336 / 15539 - CLASS_LOSS : 0.12628
312 / 500 :: 14976 / 15539 - CLASS_LOSS : 0.19483
313 / 500 :: 64 / 15539 - CLASS_LOSS : 0.20408
313 / 500 :: 704 / 15539 - CLASS_LOSS : 0.12887
313 / 500 :: 1344 / 15539 - CLASS_LOSS : 0.27092
313 / 500 :: 1984 / 15539 - CLASS_LOSS : 0.14762
313 / 500 :: 2624 / 15539 - CLASS_LOSS : 0.14142
313 / 500 :: 3264 / 15539 - CLASS_LOSS : 0.28271
313 / 500 :: 3904 / 15539 - CLASS_LOSS : 0.13519
313 / 500 :: 4544 / 15539 - CLASS_LOSS : 0.133
313 / 500 :: 5184 / 15539 - CLASS_LOSS : 0.07381
313 / 500 :: 5824 / 15539 - CLASS_LOSS : 0.1838
313 / 500 :: 6464 / 15539 - CLASS_LOSS : 0.17759
313 / 500 :: 7104 / 15539 - CLASS_LOSS : 0.14568
313 / 500 :: 7744 / 15539 - CLASS_LOSS : 0.13704
313 / 500 :: 8384 / 15539 - CLASS_LOSS : 0.12852
313 / 500 :: 9024 / 15539 - CLASS_LOSS : 0.15337
313 / 500 :: 9664 / 15539 - CLASS_LOSS : 0.1028
313 / 500 :: 10304 / 15539 - CLASS_LOSS : 0.18607
313 / 500 :: 10944 / 15539 - CLASS_LOSS : 0.25568
313 / 500 :: 11584 / 15539 - CLASS_LOSS : 0.10578
313 / 500 :: 12224 / 15539 - CLASS_LOSS : 0.13504
313 / 500 :: 12864 / 15539 - CLASS_LOSS : 0.21628
313 / 500 :: 13504 / 15539 - CLASS_LOSS : 0.11962
313 / 500 :: 14144 / 15539 - CLASS_LOSS : 0.22513
313 / 500 :: 14784 / 15539 - CLASS_LOSS : 0.17975
313 / 500 :: 15424 / 15539 - CLASS_LOSS : 0.27286
314 / 500 :: 512 / 15539 - CLASS_LOSS : 0.1234
314 / 500 :: 1152 / 15539 - CLASS_LOSS : 0.13376
314 / 500 :: 1792 / 15539 - CLASS_LOSS : 0.15785
314 / 500 :: 2432 / 15539 - CLASS_LOSS : 0.18232
314 / 500 :: 3072 / 15539 - CLASS_LOSS : 0.18758
314 / 500 :: 3712 / 15539 - CLASS_LOSS : 0.13141
314 / 500 :: 4352 / 15539 - CLASS_LOSS : 0.15454
314 / 500 :: 4992 / 15539 - CLASS_LOSS : 0.1742
314 / 500 :: 5632 / 15539 - CLASS_LOSS : 0.10743
314 / 500 :: 6272 / 15539 - CLASS_LOSS : 0.08527
314 / 500 :: 6912 / 15539 - CLASS_LOSS : 0.14777
314 / 500 :: 7552 / 15539 - CLASS_LOSS : 0.16101
314 / 500 :: 8192 / 15539 - CLASS_LOSS : 0.1745
314 / 500 :: 8832 / 15539 - CLASS_LOSS : 0.14139
314 / 500 :: 9472 / 15539 - CLASS_LOSS : 0.10242
314 / 500 :: 10112 / 15539 - CLASS_LOSS : 0.19435
314 / 500 :: 10752 / 15539 - CLASS_LOSS : 0.16286
314 / 500 :: 11392 / 15539 - CLASS_LOSS : 0.1726
314 / 500 :: 12032 / 15539 - CLASS_LOSS : 0.18134
314 / 500 :: 12672 / 15539 - CLASS_LOSS : 0.22159
314 / 500 :: 13312 / 15539 - CLASS_LOSS : 0.24312
314 / 500 :: 13952 / 15539 - CLASS_LOSS : 0.17519
314 / 500 :: 14592 / 15539 - CLASS_LOSS : 0.15079
314 / 500 :: 15232 / 15539 - CLASS_LOSS : 0.14701
315 / 500 :: 320 / 15539 - CLASS_LOSS : 0.14006
315 / 500 :: 960 / 15539 - CLASS_LOSS : 0.21778
315 / 500 :: 1600 / 15539 - CLASS_LOSS : 0.25396
315 / 500 :: 2240 / 15539 - CLASS_LOSS : 0.15824
315 / 500 :: 2880 / 15539 - CLASS_LOSS : 0.14343
315 / 500 :: 3520 / 15539 - CLASS_LOSS : 0.12179
315 / 500 :: 4160 / 15539 - CLASS_LOSS : 0.15598
315 / 500 :: 4800 / 15539 - CLASS_LOSS : 0.16552
315 / 500 :: 5440 / 15539 - CLASS_LOSS : 0.24082
315 / 500 :: 6080 / 15539 - CLASS_LOSS : 0.09888
315 / 500 :: 6720 / 15539 - CLASS_LOSS : 0.09876
315 / 500 :: 7360 / 15539 - CLASS_LOSS : 0.10862
315 / 500 :: 8000 / 15539 - CLASS_LOSS : 0.2362
315 / 500 :: 8640 / 15539 - CLASS_LOSS : 0.11485
315 / 500 :: 9280 / 15539 - CLASS_LOSS : 0.16991
315 / 500 :: 9920 / 15539 - CLASS_LOSS : 0.19255
315 / 500 :: 10560 / 15539 - CLASS_LOSS : 0.15045
315 / 500 :: 11200 / 15539 - CLASS_LOSS : 0.19607
315 / 500 :: 11840 / 15539 - CLASS_LOSS : 0.09237
315 / 500 :: 12480 / 15539 - CLASS_LOSS : 0.08615
315 / 500 :: 13120 / 15539 - CLASS_LOSS : 0.11428
315 / 500 :: 13760 / 15539 - CLASS_LOSS : 0.3356
315 / 500 :: 14400 / 15539 - CLASS_LOSS : 0.14784
315 / 500 :: 15040 / 15539 - CLASS_LOSS : 0.19203
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.5834352274921166 0.49638543878842484 0.4257931655833709
PSPrecision@1,3,5: 0.41576604951555063 0.45916062056638435 0.48428745559263453
testing....
Precision@1,3,5: 0.49173011289052243 0.39581692482716374 0.3367288002100289
PSPrecision@1,3,5: 0.296022191633741 0.3182694910395896 0.3360849679690004
316 / 500 :: 128 / 15539 - CLASS_LOSS : 0.20905
316 / 500 :: 768 / 15539 - CLASS_LOSS : 0.1654
316 / 500 :: 1408 / 15539 - CLASS_LOSS : 0.14094
316 / 500 :: 2048 / 15539 - CLASS_LOSS : 0.1618
316 / 500 :: 2688 / 15539 - CLASS_LOSS : 0.08303
316 / 500 :: 3328 / 15539 - CLASS_LOSS : 0.18472
316 / 500 :: 3968 / 15539 - CLASS_LOSS : 0.12294
316 / 500 :: 4608 / 15539 - CLASS_LOSS : 0.18977
316 / 500 :: 5248 / 15539 - CLASS_LOSS : 0.09908
316 / 500 :: 5888 / 15539 - CLASS_LOSS : 0.19106
316 / 500 :: 6528 / 15539 - CLASS_LOSS : 0.20642
316 / 500 :: 7168 / 15539 - CLASS_LOSS : 0.17425
316 / 500 :: 7808 / 15539 - CLASS_LOSS : 0.12971
316 / 500 :: 8448 / 15539 - CLASS_LOSS : 0.15296
316 / 500 :: 9088 / 15539 - CLASS_LOSS : 0.17669
316 / 500 :: 9728 / 15539 - CLASS_LOSS : 0.07292
316 / 500 :: 10368 / 15539 - CLASS_LOSS : 0.17388
316 / 500 :: 11008 / 15539 - CLASS_LOSS : 0.20072
316 / 500 :: 11648 / 15539 - CLASS_LOSS : 0.12359
316 / 500 :: 12288 / 15539 - CLASS_LOSS : 0.1108
316 / 500 :: 12928 / 15539 - CLASS_LOSS : 0.17414
316 / 500 :: 13568 / 15539 - CLASS_LOSS : 0.1746
316 / 500 :: 14208 / 15539 - CLASS_LOSS : 0.12138
316 / 500 :: 14848 / 15539 - CLASS_LOSS : 0.14708
316 / 500 :: 15488 / 15539 - CLASS_LOSS : 0.20887
317 / 500 :: 576 / 15539 - CLASS_LOSS : 0.09696
317 / 500 :: 1216 / 15539 - CLASS_LOSS : 0.18396
317 / 500 :: 1856 / 15539 - CLASS_LOSS : 0.19156
317 / 500 :: 2496 / 15539 - CLASS_LOSS : 0.12699
317 / 500 :: 3136 / 15539 - CLASS_LOSS : 0.18084
317 / 500 :: 3776 / 15539 - CLASS_LOSS : 0.1413
317 / 500 :: 4416 / 15539 - CLASS_LOSS : 0.11314
317 / 500 :: 5056 / 15539 - CLASS_LOSS : 0.17567
317 / 500 :: 5696 / 15539 - CLASS_LOSS : 0.23044
317 / 500 :: 6336 / 15539 - CLASS_LOSS : 0.21987
317 / 500 :: 6976 / 15539 - CLASS_LOSS : 0.25697
317 / 500 :: 7616 / 15539 - CLASS_LOSS : 0.17437
317 / 500 :: 8256 / 15539 - CLASS_LOSS : 0.10346
317 / 500 :: 8896 / 15539 - CLASS_LOSS : 0.25264
317 / 500 :: 9536 / 15539 - CLASS_LOSS : 0.1017
317 / 500 :: 10176 / 15539 - CLASS_LOSS : 0.12735
317 / 500 :: 10816 / 15539 - CLASS_LOSS : 0.16532
317 / 500 :: 11456 / 15539 - CLASS_LOSS : 0.26931
317 / 500 :: 12096 / 15539 - CLASS_LOSS : 0.22306
317 / 500 :: 12736 / 15539 - CLASS_LOSS : 0.13712
317 / 500 :: 13376 / 15539 - CLASS_LOSS : 0.13719
317 / 500 :: 14016 / 15539 - CLASS_LOSS : 0.1502
317 / 500 :: 14656 / 15539 - CLASS_LOSS : 0.18362
317 / 500 :: 15296 / 15539 - CLASS_LOSS : 0.16609
318 / 500 :: 384 / 15539 - CLASS_LOSS : 0.16618
318 / 500 :: 1024 / 15539 - CLASS_LOSS : 0.17013
318 / 500 :: 1664 / 15539 - CLASS_LOSS : 0.20021
318 / 500 :: 2304 / 15539 - CLASS_LOSS : 0.15785
318 / 500 :: 2944 / 15539 - CLASS_LOSS : 0.17624
318 / 500 :: 3584 / 15539 - CLASS_LOSS : 0.13703
318 / 500 :: 4224 / 15539 - CLASS_LOSS : 0.13325
318 / 500 :: 4864 / 15539 - CLASS_LOSS : 0.14426
318 / 500 :: 5504 / 15539 - CLASS_LOSS : 0.17551
318 / 500 :: 6144 / 15539 - CLASS_LOSS : 0.17976
318 / 500 :: 6784 / 15539 - CLASS_LOSS : 0.09468
318 / 500 :: 7424 / 15539 - CLASS_LOSS : 0.18446
318 / 500 :: 8064 / 15539 - CLASS_LOSS : 0.17481
318 / 500 :: 8704 / 15539 - CLASS_LOSS : 0.23306
318 / 500 :: 9344 / 15539 - CLASS_LOSS : 0.12552
318 / 500 :: 9984 / 15539 - CLASS_LOSS : 0.09865
318 / 500 :: 10624 / 15539 - CLASS_LOSS : 0.19332
318 / 500 :: 11264 / 15539 - CLASS_LOSS : 0.15077
318 / 500 :: 11904 / 15539 - CLASS_LOSS : 0.15093
318 / 500 :: 12544 / 15539 - CLASS_LOSS : 0.18171
318 / 500 :: 13184 / 15539 - CLASS_LOSS : 0.19323
318 / 500 :: 13824 / 15539 - CLASS_LOSS : 0.11081
318 / 500 :: 14464 / 15539 - CLASS_LOSS : 0.16289
318 / 500 :: 15104 / 15539 - CLASS_LOSS : 0.1095
319 / 500 :: 192 / 15539 - CLASS_LOSS : 0.22814
319 / 500 :: 832 / 15539 - CLASS_LOSS : 0.18525
319 / 500 :: 1472 / 15539 - CLASS_LOSS : 0.16086
319 / 500 :: 2112 / 15539 - CLASS_LOSS : 0.16771
319 / 500 :: 2752 / 15539 - CLASS_LOSS : 0.21954
319 / 500 :: 3392 / 15539 - CLASS_LOSS : 0.22036
319 / 500 :: 4032 / 15539 - CLASS_LOSS : 0.17545
319 / 500 :: 4672 / 15539 - CLASS_LOSS : 0.19615
319 / 500 :: 5312 / 15539 - CLASS_LOSS : 0.19197
319 / 500 :: 5952 / 15539 - CLASS_LOSS : 0.13183
319 / 500 :: 6592 / 15539 - CLASS_LOSS : 0.1546
319 / 500 :: 7232 / 15539 - CLASS_LOSS : 0.21813
319 / 500 :: 7872 / 15539 - CLASS_LOSS : 0.10374
319 / 500 :: 8512 / 15539 - CLASS_LOSS : 0.1852
319 / 500 :: 9152 / 15539 - CLASS_LOSS : 0.18242
319 / 500 :: 9792 / 15539 - CLASS_LOSS : 0.11103
319 / 500 :: 10432 / 15539 - CLASS_LOSS : 0.12878
319 / 500 :: 11072 / 15539 - CLASS_LOSS : 0.08174
319 / 500 :: 11712 / 15539 - CLASS_LOSS : 0.20188
319 / 500 :: 12352 / 15539 - CLASS_LOSS : 0.1575
319 / 500 :: 12992 / 15539 - CLASS_LOSS : 0.13694
319 / 500 :: 13632 / 15539 - CLASS_LOSS : 0.09214
319 / 500 :: 14272 / 15539 - CLASS_LOSS : 0.12654
319 / 500 :: 14912 / 15539 - CLASS_LOSS : 0.14935
319 / 500 :: 15539 / 15539 - CLASS_LOSS : 0.1324
320 / 500 :: 640 / 15539 - CLASS_LOSS : 0.12236
320 / 500 :: 1280 / 15539 - CLASS_LOSS : 0.15885
320 / 500 :: 1920 / 15539 - CLASS_LOSS : 0.14736
320 / 500 :: 2560 / 15539 - CLASS_LOSS : 0.15425
320 / 500 :: 3200 / 15539 - CLASS_LOSS : 0.15471
320 / 500 :: 3840 / 15539 - CLASS_LOSS : 0.13727
320 / 500 :: 4480 / 15539 - CLASS_LOSS : 0.10548
320 / 500 :: 5120 / 15539 - CLASS_LOSS : 0.22946
320 / 500 :: 5760 / 15539 - CLASS_LOSS : 0.18444
320 / 500 :: 6400 / 15539 - CLASS_LOSS : 0.23421
320 / 500 :: 7040 / 15539 - CLASS_LOSS : 0.12563
320 / 500 :: 7680 / 15539 - CLASS_LOSS : 0.16385
320 / 500 :: 8320 / 15539 - CLASS_LOSS : 0.17128
320 / 500 :: 8960 / 15539 - CLASS_LOSS : 0.14895
320 / 500 :: 9600 / 15539 - CLASS_LOSS : 0.1341
320 / 500 :: 10240 / 15539 - CLASS_LOSS : 0.19144
320 / 500 :: 10880 / 15539 - CLASS_LOSS : 0.20568
320 / 500 :: 11520 / 15539 - CLASS_LOSS : 0.16988
320 / 500 :: 12160 / 15539 - CLASS_LOSS : 0.08308
320 / 500 :: 12800 / 15539 - CLASS_LOSS : 0.15112
320 / 500 :: 13440 / 15539 - CLASS_LOSS : 0.15898
320 / 500 :: 14080 / 15539 - CLASS_LOSS : 0.18942
320 / 500 :: 14720 / 15539 - CLASS_LOSS : 0.27568
320 / 500 :: 15360 / 15539 - CLASS_LOSS : 0.10531
/root/.local/lib/python3.7/site-packages/scikit_learn-0.23.1-py3.7-linux-x86_64.egg/sklearn/utils/validation.py:71: FutureWarning: Pass classes=range(0, 3993) as keyword args. From version 0.25 passing these as positional arguments will result in an error
  FutureWarning)
Precision@1,3,5: 0.5862024583306519 0.4973722032734839 0.4250852693223502
PSPrecision@1,3,5: 0.41911721772616745 0.45949784149885264 0.4824682886941931
testing....
Precision@1,3,5: 0.48884221580467313 0.39660453312330446 0.334313468101864
PSPrecision@1,3,5: 0.2918467051709136 0.3179763705883516 0.3339316456297748
321 / 500 :: 448 / 15539 - CLASS_LOSS : 0.10253
321 / 500 :: 1088 / 15539 - CLASS_LOSS : 0.11231
321 / 500 :: 1728 / 15539 - CLASS_LOSS : 0.14662
321 / 500 :: 2368 / 15539 - CLASS_LOSS : 0.16537
321 / 500 :: 3008 / 15539 - CLASS_LOSS : 0.17711
321 / 500 :: 3648 / 15539 - CLASS_LOSS : 0.22393
321 / 500 :: 4288 / 15539 - CLASS_LOSS : 0.18953
321 / 500 :: 4928 / 15539 - CLASS_LOSS : 0.10301
321 / 500 :: 5568 / 15539 - CLASS_LOSS : 0.18278
321 / 500 :: 6208 / 15539 - CLASS_LOSS : 0.23481
321 / 500 :: 6848 / 15539 - CLASS_LOSS : 0.20991
321 / 500 :: 7488 / 15539 - CLASS_LOSS : 0.13778
321 / 500 :: 8128 / 15539 - CLASS_LOSS : 0.21205
321 / 500 :: 8768 / 15539 - CLASS_LOSS : 0.10049
321 / 500 :: 9408 / 15539 - CLASS_LOSS : 0.13022
321 / 500 :: 10048 / 15539 - CLASS_LOSS : 0.16039
321 / 500 :: 10688 / 15539 - CLASS_LOSS : 0.1376
321 / 500 :: 11328 / 15539 - CLASS_LOSS : 0.11563
321 / 500 :: 11968 / 15539 - CLASS_LOSS : 0.19492
321 / 500 :: 12608 / 15539 - CLASS_LOSS : 0.15696
321 / 500 :: 13248 / 15539 - CLASS_LOSS : 0.12633
321 / 500 :: 13888 / 15539 - CLASS_LOSS : 0.16068
321 / 500 :: 14528 / 15539 - CLASS_LOSS : 0.18948
321 / 500 :: 15168 / 15539 - CLASS_LOSS : 0.27492
322 / 500 :: 256 / 15539 - CLASS_LOSS : 0.28589
322 / 500 :: 896 / 15539 - CLASS_LOSS : 0.19806
322 / 500 :: 1536 / 15539 - CLASS_LOSS : 0.18085
322 / 500 :: 2176 / 15539 - CLASS_LOSS : 0.14369
322 / 500 :: 2816 / 15539 - CLASS_LOSS : 0.21514
322 / 500 :: 3456 / 15539 - CLASS_LOSS : 0.11643
322 / 500 :: 4096 / 15539 - CLASS_LOSS : 0.15916
322 / 500 :: 4736 / 15539 - CLASS_LOSS : 0.20643
322 / 500 :: 5376 / 15539 - CLASS_LOSS : 0.24823
322 / 500 :: 6016 / 15539 - CLASS_LOSS : 0.14559
322 / 500 :: 6656 / 15539 - CLASS_LOSS : 0.21947
322 / 500 :: 7296 / 15539 - CLASS_LOSS : 0.27471
322 / 500 :: 7936 / 15539 - CLASS_LOSS : 0.22399
322 / 500 :: 8576 / 15539 - CLASS_LOSS : 0.11876
322 / 500 :: 9216 / 15539 - CLASS_LOSS : 0.16685
322 / 500 :: 9856 / 15539 - CLASS_LOSS : 0.22223
322 / 500 :: 10496 / 15539 - CLASS_LOSS : 0.17668
322 / 500 :: 11136 / 15539 - CLASS_LOSS : 0.18505
322 / 500 :: 11776 / 15539 - CLASS_LOSS : 0.07859
322 / 500 :: 12416 / 15539 - CLASS_LOSS : 0.17865
322 / 500 :: 13056 / 15539 - CLASS_LOSS : 0.13145
322 / 500 :: 13696 / 15539 - CLASS_LOSS : 0.14652
322 / 500 :: 14336 / 15539 - CLASS_LOSS : 0.19819
Terminated
